{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ff77134-8f32-443d-9c3e-57eaf9773aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffbc9fe-f902-4691-93d9-4ea563920388",
   "metadata": {},
   "source": [
    "[MRI Scans Alzeimer Detection Dataset (via Hugging Face)](https://huggingface.co/datasets/yogitamakkar178/mri_scans_alzeimer_detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0e4be46-df8c-4392-9212-ced26926344d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "147750ec240a4c1fa83ac3ccca911d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/9552 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1df8184be39468fb8f02c42e43cfac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"yogitamakkar178/mri_scans_alzeimer_detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e72055d-8c6f-4e53-9e58-3c362cba17a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "def preprocess(data):\n",
    "    data[\"image\"] = [transform(image) for image in data[\"image\"]]\n",
    "    return data\n",
    "ds = ds.with_format(\"torch\") # ds = ds.with_format(\"torch\", device=device)\n",
    "ds = ds.with_transform(preprocess)\n",
    "\n",
    "ds = concatenate_datasets([ds[\"train\"], ds[\"test\"]]).shuffle()\n",
    "ds = ds.train_test_split(train_size=0.8, stratify_by_column=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "557dae90-cc84-4ed0-aede-f8cfc4dcd1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(ds[\"train\"], shuffle=True, batch_size=32)\n",
    "test_loader = DataLoader(ds[\"test\"], shuffle=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5947806-e816-4351-a1ca-43ff3f40c977",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlzeimersModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1) # 1x(128x128) -> 32x(128x128)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)# 32x(128x128) -> 32x(64x64)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) # 32x(64x64) -> 64x(64x64)\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # 64x(64x64) -> 64x(32x32)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1) # 64x(32x32) -> 128x(32x32)\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2) # 128x(32x32) -> 128x(16x16)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1) # 128x(16x16) -> 256x(16x16)\n",
    "        self.relu4 = nn.LeakyReLU()\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2) # 256x(16x16) -> 256x(8x8)\n",
    "\n",
    "        self.fc1   = nn.Linear(256 * 8 * 8, 256 * 8) # flatten\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2   = nn.Linear(256 * 8, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # first pass\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # second pass\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # third pass\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        # fourth pass\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7a88843-a898-4a2a-8795-2e225259105a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlzeimersModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e1a0e75-fb87-4e20-9fad-b89188af2060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, criterion, device, train_loader, epoch):\n",
    "    model.train()\n",
    "    for idx, batch in enumerate(train_loader):\n",
    "        image = batch[\"image\"].to(device)\n",
    "        target = batch[\"label\"].to(device)\n",
    "        outputs = model(image)\n",
    "        loss = criterion(outputs, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if idx % 25 == 0:\n",
    "            print(f\"Epoch [{epoch}].[{idx}] Loss: {loss}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        num_correct = 0\n",
    "        num_total = 0\n",
    "        for batch in train_loader:\n",
    "            image = batch[\"image\"].to(device)\n",
    "            target = batch[\"label\"].to(device)\n",
    "            outputs = model(image)\n",
    "            output = outputs.argmax(dim=1)\n",
    "            num_correct += (output == target).sum().item()\n",
    "            num_total += target.size(0)\n",
    "    accuracy = num_correct / num_total\n",
    "    print(\"\")\n",
    "    print(f\"Epoch [{epoch}] Train accuracy: {accuracy}\")\n",
    "\n",
    "def test_model(model, device, test_loader, epoch):\n",
    "    with torch.no_grad():\n",
    "        num_correct = 0\n",
    "        num_total = 0\n",
    "        for batch in test_loader:\n",
    "            image = batch[\"image\"].to(device)\n",
    "            target = batch[\"label\"].to(device)\n",
    "            outputs = model(image)\n",
    "            output = outputs.argmax(dim=1)\n",
    "            num_correct += (output == target).sum().item()\n",
    "            num_total += target.size(0)\n",
    "        accuracy = num_correct / num_total\n",
    "        print(\"\")\n",
    "        print(f\"Epoch [{epoch}] Test accuracy: {accuracy}\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1066cdf2-62b2-482e-a508-eeffb1e89bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1].[0] Loss: 1.388413667678833\n",
      "Epoch [1].[25] Loss: 1.3148045539855957\n",
      "Epoch [1].[50] Loss: 1.301229476928711\n",
      "Epoch [1].[75] Loss: 1.0306642055511475\n",
      "Epoch [1].[100] Loss: 0.8602398633956909\n",
      "Epoch [1].[125] Loss: 0.5962968468666077\n",
      "Epoch [1].[150] Loss: 0.7730485200881958\n",
      "Epoch [1].[175] Loss: 0.6946854591369629\n",
      "Epoch [1].[200] Loss: 0.5444226264953613\n",
      "Epoch [1].[225] Loss: 0.5708288550376892\n",
      "Epoch [1].[250] Loss: 0.5623915791511536\n",
      "\n",
      "Epoch [1] Train accuracy: 0.769275161588181\n",
      "\n",
      "Epoch [1] Test accuracy: 0.755883710198431\n",
      "\n",
      "Epoch [2].[0] Loss: 0.730221152305603\n",
      "Epoch [2].[25] Loss: 0.787966787815094\n",
      "Epoch [2].[50] Loss: 0.5564850568771362\n",
      "Epoch [2].[75] Loss: 0.49152088165283203\n",
      "Epoch [2].[100] Loss: 0.4877294600009918\n",
      "Epoch [2].[125] Loss: 0.3151075839996338\n",
      "Epoch [2].[150] Loss: 0.5321158170700073\n",
      "Epoch [2].[175] Loss: 0.5344568490982056\n",
      "Epoch [2].[200] Loss: 0.31880009174346924\n",
      "Epoch [2].[225] Loss: 0.46383291482925415\n",
      "Epoch [2].[250] Loss: 0.3517451584339142\n",
      "\n",
      "Epoch [2] Train accuracy: 0.8533010156971376\n",
      "\n",
      "Epoch [2] Test accuracy: 0.8241808952468851\n",
      "\n",
      "Epoch [3].[0] Loss: 0.3037846088409424\n",
      "Epoch [3].[25] Loss: 0.21313929557800293\n",
      "Epoch [3].[50] Loss: 0.2196243703365326\n",
      "Epoch [3].[75] Loss: 0.2914675176143646\n",
      "Epoch [3].[100] Loss: 0.3344607949256897\n",
      "Epoch [3].[125] Loss: 0.24797585606575012\n",
      "Epoch [3].[150] Loss: 0.3861362934112549\n",
      "Epoch [3].[175] Loss: 0.37393486499786377\n",
      "Epoch [3].[200] Loss: 0.382310688495636\n",
      "Epoch [3].[225] Loss: 0.2353833168745041\n",
      "Epoch [3].[250] Loss: 0.26410818099975586\n",
      "\n",
      "Epoch [3] Train accuracy: 0.9241689750692521\n",
      "\n",
      "Epoch [3] Test accuracy: 0.8818643285648362\n",
      "\n",
      "Epoch [4].[0] Loss: 0.16244292259216309\n",
      "Epoch [4].[25] Loss: 0.22034747898578644\n",
      "Epoch [4].[50] Loss: 0.2023296058177948\n",
      "Epoch [4].[75] Loss: 0.1459614634513855\n",
      "Epoch [4].[100] Loss: 0.1299370378255844\n",
      "Epoch [4].[125] Loss: 0.2769361734390259\n",
      "Epoch [4].[150] Loss: 0.24627190828323364\n",
      "Epoch [4].[175] Loss: 0.27567481994628906\n",
      "Epoch [4].[200] Loss: 0.27245667576789856\n",
      "Epoch [4].[225] Loss: 0.2917032241821289\n",
      "Epoch [4].[250] Loss: 0.22106564044952393\n",
      "\n",
      "Epoch [4] Train accuracy: 0.9493305632502308\n",
      "\n",
      "Epoch [4] Test accuracy: 0.9197046608214121\n",
      "\n",
      "Epoch [5].[0] Loss: 0.11753571033477783\n",
      "Epoch [5].[25] Loss: 0.11363135278224945\n",
      "Epoch [5].[50] Loss: 0.21140076220035553\n",
      "Epoch [5].[75] Loss: 0.27068284153938293\n",
      "Epoch [5].[100] Loss: 0.21826323866844177\n",
      "Epoch [5].[125] Loss: 0.34867388010025024\n",
      "Epoch [5].[150] Loss: 0.09019388258457184\n",
      "Epoch [5].[175] Loss: 0.048113491386175156\n",
      "Epoch [5].[200] Loss: 0.10751040279865265\n",
      "Epoch [5].[225] Loss: 0.10675975680351257\n",
      "Epoch [5].[250] Loss: 0.13369262218475342\n",
      "\n",
      "Epoch [5] Train accuracy: 0.9764542936288089\n",
      "\n",
      "Epoch [5] Test accuracy: 0.9404706968158745\n",
      "\n",
      "Epoch [6].[0] Loss: 0.01917225494980812\n",
      "Epoch [6].[25] Loss: 0.02733154222369194\n",
      "Epoch [6].[50] Loss: 0.06379855424165726\n",
      "Epoch [6].[75] Loss: 0.032012343406677246\n",
      "Epoch [6].[100] Loss: 0.02931598573923111\n",
      "Epoch [6].[125] Loss: 0.05716358870267868\n",
      "Epoch [6].[150] Loss: 0.04879923164844513\n",
      "Epoch [6].[175] Loss: 0.05792953446507454\n",
      "Epoch [6].[200] Loss: 0.059386685490608215\n",
      "Epoch [6].[225] Loss: 0.0608261376619339\n",
      "Epoch [6].[250] Loss: 0.035259321331977844\n",
      "\n",
      "Epoch [6] Train accuracy: 0.9669898430286242\n",
      "\n",
      "Epoch [6] Test accuracy: 0.934010152284264\n",
      "\n",
      "Epoch [7].[0] Loss: 0.0434851348400116\n",
      "Epoch [7].[25] Loss: 0.03197097033262253\n",
      "Epoch [7].[50] Loss: 0.016433371230959892\n",
      "Epoch [7].[75] Loss: 0.09736375510692596\n",
      "Epoch [7].[100] Loss: 0.021542109549045563\n",
      "Epoch [7].[125] Loss: 0.02244427055120468\n",
      "Epoch [7].[150] Loss: 0.015002734959125519\n",
      "Epoch [7].[175] Loss: 0.1076456606388092\n",
      "Epoch [7].[200] Loss: 0.04069977253675461\n",
      "Epoch [7].[225] Loss: 0.04197300598025322\n",
      "Epoch [7].[250] Loss: 0.03873573988676071\n",
      "\n",
      "Epoch [7] Train accuracy: 0.9868421052631579\n",
      "\n",
      "Epoch [7] Test accuracy: 0.9506229810798339\n",
      "\n",
      "Epoch [8].[0] Loss: 0.017071085050702095\n",
      "Epoch [8].[25] Loss: 0.03674788028001785\n",
      "Epoch [8].[50] Loss: 0.17107120156288147\n",
      "Epoch [8].[75] Loss: 0.05062375217676163\n",
      "Epoch [8].[100] Loss: 0.03126802667975426\n",
      "Epoch [8].[125] Loss: 0.027896404266357422\n",
      "Epoch [8].[150] Loss: 0.05777354538440704\n",
      "Epoch [8].[175] Loss: 0.01893230713903904\n",
      "Epoch [8].[200] Loss: 0.011139461770653725\n",
      "Epoch [8].[225] Loss: 0.007545928005129099\n",
      "Epoch [8].[250] Loss: 0.03182918205857277\n",
      "\n",
      "Epoch [8] Train accuracy: 0.9941135734072022\n",
      "\n",
      "Epoch [8] Test accuracy: 0.9663128749423165\n",
      "\n",
      "Epoch [9].[0] Loss: 0.005742702167481184\n",
      "Epoch [9].[25] Loss: 0.008638186380267143\n",
      "Epoch [9].[50] Loss: 0.007520110346376896\n",
      "Epoch [9].[75] Loss: 0.0033904369920492172\n",
      "Epoch [9].[100] Loss: 0.006197702139616013\n",
      "Epoch [9].[125] Loss: 0.009030673652887344\n",
      "Epoch [9].[150] Loss: 0.06166236475110054\n",
      "Epoch [9].[175] Loss: 0.031445495784282684\n",
      "Epoch [9].[200] Loss: 0.0045785075053572655\n",
      "Epoch [9].[225] Loss: 0.010048698633909225\n",
      "Epoch [9].[250] Loss: 0.0020736372098326683\n",
      "\n",
      "Epoch [9] Train accuracy: 0.9983841181902123\n",
      "\n",
      "Epoch [9] Test accuracy: 0.9796954314720813\n",
      "\n",
      "Epoch [10].[0] Loss: 0.00786922313272953\n",
      "Epoch [10].[25] Loss: 0.0028860652819275856\n",
      "Epoch [10].[50] Loss: 0.012558729387819767\n",
      "Epoch [10].[75] Loss: 0.04027322307229042\n",
      "Epoch [10].[100] Loss: 0.012887046672403812\n",
      "Epoch [10].[125] Loss: 0.035020653158426285\n",
      "Epoch [10].[150] Loss: 0.0009149737888947129\n",
      "Epoch [10].[175] Loss: 0.009774034842848778\n",
      "Epoch [10].[200] Loss: 0.0009450116194784641\n",
      "Epoch [10].[225] Loss: 0.0046583302319049835\n",
      "Epoch [10].[250] Loss: 0.00166099495254457\n",
      "\n",
      "Epoch [10] Train accuracy: 0.9996537396121884\n",
      "\n",
      "Epoch [10] Test accuracy: 0.9741578218735579\n",
      "\n",
      "Epoch [11].[0] Loss: 0.0005642980104312301\n",
      "Epoch [11].[25] Loss: 0.004190970212221146\n",
      "Epoch [11].[50] Loss: 0.0010918359039351344\n",
      "Epoch [11].[75] Loss: 0.0008174522081390023\n",
      "Epoch [11].[100] Loss: 0.00048649217933416367\n",
      "Epoch [11].[125] Loss: 0.0026340859476476908\n",
      "Epoch [11].[150] Loss: 0.0007139932131394744\n",
      "Epoch [11].[175] Loss: 0.008995125070214272\n",
      "Epoch [11].[200] Loss: 0.0017983779544010758\n",
      "Epoch [11].[225] Loss: 0.002563590882346034\n",
      "Epoch [11].[250] Loss: 0.000738440197892487\n",
      "\n",
      "Epoch [11] Train accuracy: 1.0\n",
      "\n",
      "Epoch [11] Test accuracy: 0.9833871712044301\n",
      "\n",
      "Epoch [12].[0] Loss: 0.0023416792973876\n",
      "Epoch [12].[25] Loss: 0.0014828701969236135\n",
      "Epoch [12].[50] Loss: 0.011561410501599312\n",
      "Epoch [12].[75] Loss: 0.0016209001187235117\n",
      "Epoch [12].[100] Loss: 0.004796471446752548\n",
      "Epoch [12].[125] Loss: 0.002899229060858488\n",
      "Epoch [12].[150] Loss: 0.00113242631778121\n",
      "Epoch [12].[175] Loss: 0.0005624371115118265\n",
      "Epoch [12].[200] Loss: 0.0016373631078749895\n",
      "Epoch [12].[225] Loss: 0.004784844815731049\n",
      "Epoch [12].[250] Loss: 0.0028247626032680273\n",
      "\n",
      "Epoch [12] Train accuracy: 0.9969990766389658\n",
      "\n",
      "Epoch [12] Test accuracy: 0.9718504845408399\n",
      "\n",
      "Epoch [13].[0] Loss: 0.017715375870466232\n",
      "Epoch [13].[25] Loss: 0.012104662135243416\n",
      "Epoch [13].[50] Loss: 0.02006971836090088\n",
      "Epoch [13].[75] Loss: 0.015139850787818432\n",
      "Epoch [13].[100] Loss: 0.1708216518163681\n",
      "Epoch [13].[125] Loss: 0.008744639344513416\n",
      "Epoch [13].[150] Loss: 0.02403736487030983\n",
      "Epoch [13].[175] Loss: 0.008610371500253677\n",
      "Epoch [13].[200] Loss: 0.01251931581646204\n",
      "Epoch [13].[225] Loss: 0.030122127383947372\n",
      "Epoch [13].[250] Loss: 0.006722953636199236\n",
      "\n",
      "Epoch [13] Train accuracy: 0.9966528162511542\n",
      "\n",
      "Epoch [13] Test accuracy: 0.9746192893401016\n",
      "\n",
      "Epoch [14].[0] Loss: 0.019037077203392982\n",
      "Epoch [14].[25] Loss: 0.001716908416710794\n",
      "Epoch [14].[50] Loss: 0.0009007260086946189\n",
      "Epoch [14].[75] Loss: 0.001858787494711578\n",
      "Epoch [14].[100] Loss: 0.00132458982989192\n",
      "Epoch [14].[125] Loss: 0.0043306113220751286\n",
      "Epoch [14].[150] Loss: 0.003854999551549554\n",
      "Epoch [14].[175] Loss: 0.00556549709290266\n",
      "Epoch [14].[200] Loss: 0.001803120831027627\n",
      "Epoch [14].[225] Loss: 0.0026131533086299896\n",
      "Epoch [14].[250] Loss: 0.0008584231836721301\n",
      "\n",
      "Epoch [14] Train accuracy: 0.9995383194829178\n",
      "\n",
      "Epoch [14] Test accuracy: 0.9778495616059067\n",
      "\n",
      "Epoch [15].[0] Loss: 0.002901944098994136\n",
      "Epoch [15].[25] Loss: 0.005436112638562918\n",
      "Epoch [15].[50] Loss: 0.0007856704760342836\n",
      "Epoch [15].[75] Loss: 7.38498565624468e-05\n",
      "Epoch [15].[100] Loss: 0.001712951809167862\n",
      "Epoch [15].[125] Loss: 9.007263724924996e-05\n",
      "Epoch [15].[150] Loss: 0.0005800393992103636\n",
      "Epoch [15].[175] Loss: 0.0018584034405648708\n",
      "Epoch [15].[200] Loss: 0.0009566358057782054\n",
      "Epoch [15].[225] Loss: 0.0021479050628840923\n",
      "Epoch [15].[250] Loss: 0.0006428305059671402\n",
      "\n",
      "Epoch [15] Train accuracy: 0.9991920590951062\n",
      "\n",
      "Epoch [15] Test accuracy: 0.9824642362713428\n",
      "\n",
      "Epoch [16].[0] Loss: 0.0032250643707811832\n",
      "Epoch [16].[25] Loss: 0.0007060880889184773\n",
      "Epoch [16].[50] Loss: 0.0005281518097035587\n",
      "Epoch [16].[75] Loss: 0.0009678893256932497\n",
      "Epoch [16].[100] Loss: 5.050559411756694e-05\n",
      "Epoch [16].[125] Loss: 0.0002701222838368267\n",
      "Epoch [16].[150] Loss: 0.00036191981052979827\n",
      "Epoch [16].[175] Loss: 0.0005984394811093807\n",
      "Epoch [16].[200] Loss: 0.0005818845238536596\n",
      "Epoch [16].[225] Loss: 0.0008320158231072128\n",
      "Epoch [16].[250] Loss: 0.0009174198494292796\n",
      "\n",
      "Epoch [16] Train accuracy: 1.0\n",
      "\n",
      "Epoch [16] Test accuracy: 0.9884633133364098\n",
      "\n",
      "Epoch [17].[0] Loss: 0.00023071230680216104\n",
      "Epoch [17].[25] Loss: 0.0002431802568025887\n",
      "Epoch [17].[50] Loss: 0.00023358527687378228\n",
      "Epoch [17].[75] Loss: 8.914891805034131e-05\n",
      "Epoch [17].[100] Loss: 0.0002958737313747406\n",
      "Epoch [17].[125] Loss: 0.002434899564832449\n",
      "Epoch [17].[150] Loss: 0.0006723666447214782\n",
      "Epoch [17].[175] Loss: 7.663085852982476e-05\n",
      "Epoch [17].[200] Loss: 0.0007050724234431982\n",
      "Epoch [17].[225] Loss: 0.0001422692439518869\n",
      "Epoch [17].[250] Loss: 0.0002556153922341764\n",
      "\n",
      "Epoch [17] Train accuracy: 1.0\n",
      "\n",
      "Epoch [17] Test accuracy: 0.9880018458698662\n",
      "\n",
      "Epoch [18].[0] Loss: 0.0018200320191681385\n",
      "Epoch [18].[25] Loss: 7.889830158092082e-05\n",
      "Epoch [18].[50] Loss: 0.00011282866762485355\n",
      "Epoch [18].[75] Loss: 0.00016413189587183297\n",
      "Epoch [18].[100] Loss: 6.934581324458122e-05\n",
      "Epoch [18].[125] Loss: 4.464189987629652e-05\n",
      "Epoch [18].[150] Loss: 0.00019210920436307788\n",
      "Epoch [18].[175] Loss: 0.0002231193648185581\n",
      "Epoch [18].[200] Loss: 0.00022658504894934595\n",
      "Epoch [18].[225] Loss: 0.0001097664498956874\n",
      "Epoch [18].[250] Loss: 0.00015538447769358754\n",
      "\n",
      "Epoch [18] Train accuracy: 1.0\n",
      "\n",
      "Epoch [18] Test accuracy: 0.9912321181356715\n",
      "\n",
      "Epoch [19].[0] Loss: 0.0001818922464735806\n",
      "Epoch [19].[25] Loss: 2.7029331249650568e-05\n",
      "Epoch [19].[50] Loss: 0.0001505257241660729\n",
      "Epoch [19].[75] Loss: 0.00045609293738380075\n",
      "Epoch [19].[100] Loss: 0.0002654188429005444\n",
      "Epoch [19].[125] Loss: 0.00023342890199273825\n",
      "Epoch [19].[150] Loss: 4.469537816476077e-05\n",
      "Epoch [19].[175] Loss: 2.233393388451077e-05\n",
      "Epoch [19].[200] Loss: 4.7377037844853476e-05\n",
      "Epoch [19].[225] Loss: 0.000935385818593204\n",
      "Epoch [19].[250] Loss: 0.0006236099870875478\n",
      "\n",
      "Epoch [19] Train accuracy: 1.0\n",
      "\n",
      "Epoch [19] Test accuracy: 0.9889247808029534\n",
      "\n",
      "Epoch [20].[0] Loss: 0.00013439610484056175\n",
      "Epoch [20].[25] Loss: 0.00015829087351448834\n",
      "Epoch [20].[50] Loss: 0.00048705009976401925\n",
      "Epoch [20].[75] Loss: 0.0001332361134700477\n",
      "Epoch [20].[100] Loss: 0.00014573383668903261\n",
      "Epoch [20].[125] Loss: 6.488900544354692e-05\n",
      "Epoch [20].[150] Loss: 6.695221964037046e-05\n",
      "Epoch [20].[175] Loss: 7.542111416114494e-05\n",
      "Epoch [20].[200] Loss: 0.0001008106191875413\n",
      "Epoch [20].[225] Loss: 0.00030136434361338615\n",
      "Epoch [20].[250] Loss: 4.254454324836843e-05\n",
      "\n",
      "Epoch [20] Train accuracy: 1.0\n",
      "\n",
      "Epoch [20] Test accuracy: 0.991693585602215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20 # hyperparameter\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_model(model, optimizer, criterion, device, train_loader, epoch)\n",
    "    test_model(model, device, test_loader, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172023fa-6761-4ee3-9592-0601a35fb227",
   "metadata": {},
   "source": [
    "# Reflection\n",
    "### Results\n",
    "The best test accuracy was about 99%. The train and test accuracies through the training processes were comparable, with test accuracy trailing behind by about 2% of the train accuracy.\n",
    "\n",
    "### Improvements Made\n",
    "The accuracy of the model improved drastically after generating my own train-test splits. In the previous model, the train-test splits used were taken directly from the original dataset on Hugging Face. The dataset's original splits were generally unbalanced, which caused the training process to not generalize well enough and overfit to the train set. By merging the original splits and generating my own, I was able to improve the training process and the model's performance as a whole. The test accuracy increased by 10%, and the train and test accuracies were much closer after each epoch.\n",
    "\n",
    "### Other Improvements Needed\n",
    "The outcome of the Alzeimer's CNN could have potentially been better if slight Data Augmentation was implemented (slight rotation, change in contrast and brightness, added blurness/sharpness, etc.), in order to add more noise to generalize the dataset more.\n",
    "\n",
    "Implementing proper normalization in the data transformation pipeline could have helped the neural network, specifically the optimization algorithm. Normalization is added, but it uses generic means and standard deviations considering the range of the brightness of each pixel. Finding the true mean and standard deviation could slightly improve the overall performance of the model.\n",
    "\n",
    "A better dataset could also have yielded better results. The [dataset](https://huggingface.co/datasets/yogitamakkar178/mri_scans_alzeimer_detection) used is relatively small (~10.8k entries).\n",
    "\n",
    "Finally, more experimentation is needed with the hyperparameters and other considerations of the model to determine optimal values for each. These include:\n",
    "- batch size\n",
    "- learning rate\n",
    "- number of epochs\n",
    "- number of hidden layers\n",
    "- number of filters for each convolutional layer\n",
    "- type of activation functions used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d31539-c1f1-42c3-a964-69c5ff706173",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
