{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ff77134-8f32-443d-9c3e-57eaf9773aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffbc9fe-f902-4691-93d9-4ea563920388",
   "metadata": {},
   "source": [
    "[MRI Scans Alzeimer Detection Dataset (via Hugging Face)](https://huggingface.co/datasets/yogitamakkar178/mri_scans_alzeimer_detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0e4be46-df8c-4392-9212-ced26926344d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c72c2ad63209410dab5b1a938d0d3126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/9552 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1309f22560eb4009b94a51b57a2fcbb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"yogitamakkar178/mri_scans_alzeimer_detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e72055d-8c6f-4e53-9e58-3c362cba17a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True)\n",
    "])\n",
    "def preprocess(data):\n",
    "    data[\"image\"] = [transform(image) for image in data[\"image\"]]\n",
    "    return data\n",
    "ds = ds.with_format(\"torch\") # ds = ds.with_format(\"torch\", device=device)\n",
    "ds = ds.with_transform(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "557dae90-cc84-4ed0-aede-f8cfc4dcd1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(ds[\"train\"], shuffle=True, batch_size=32)\n",
    "test_loader = DataLoader(ds[\"test\"], shuffle=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5947806-e816-4351-a1ca-43ff3f40c977",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlzeimersModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1) # 1x(128x128) -> 32x(128x128)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)# 32x(128x128) -> 32x(64x64)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) # 32x(64x64) -> 64x(64x64)\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # 64x(64x64) -> 64x(32x32)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1) # 32x(64x64) -> 64x(64x64)\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2) # 64x(64x64) -> 64x(32x32)\n",
    "\n",
    "        self.fc1   = nn.Linear(128 * 16 * 16, 128 * 16) # flatten\n",
    "        self.dropout1 = nn.Dropout(0.4)\n",
    "        self.fc2   = nn.Linear(128 * 16, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # first pass\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # second pass\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # third pass\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        # flatten and classify\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7a88843-a898-4a2a-8795-2e225259105a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlzeimersModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e1a0e75-fb87-4e20-9fad-b89188af2060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, criterion, device, train_loader, epoch):\n",
    "    model.train()\n",
    "    for idx, batch in enumerate(train_loader):\n",
    "        image = batch[\"image\"].to(device)\n",
    "        target = batch[\"label\"].to(device)\n",
    "        outputs = model(image)\n",
    "        loss = criterion(outputs, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if idx % 25 == 0:\n",
    "            print(f\"Epoch [{epoch}].[{idx}] Loss: {loss}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        num_correct = 0\n",
    "        num_total = 0\n",
    "        for batch in train_loader:\n",
    "            image = batch[\"image\"].to(device)\n",
    "            target = batch[\"label\"].to(device)\n",
    "            outputs = model(image)\n",
    "            output = outputs.argmax(dim=1)\n",
    "            num_correct += (output == target).sum().item()\n",
    "            num_total += target.size(0)\n",
    "    accuracy = num_correct / num_total\n",
    "    print(\"\")\n",
    "    print(f\"Epoch [{epoch}] Train accuracy: {accuracy}\")\n",
    "\n",
    "def test_model(model, device, test_loader, epoch):\n",
    "    with torch.no_grad():\n",
    "        num_correct = 0\n",
    "        num_total = 0\n",
    "        for batch in test_loader:\n",
    "            image = batch[\"image\"].to(device)\n",
    "            target = batch[\"label\"].to(device)\n",
    "            outputs = model(image)\n",
    "            output = outputs.argmax(dim=1)\n",
    "            num_correct += (output == target).sum().item()\n",
    "            num_total += target.size(0)\n",
    "        accuracy = num_correct / num_total\n",
    "        print(\"\")\n",
    "        print(f\"Epoch [{epoch}] Test accuracy: {accuracy}\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1066cdf2-62b2-482e-a508-eeffb1e89bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1].[0] Loss: 1.3855810165405273\n",
      "Epoch [1].[25] Loss: 1.3221006393432617\n",
      "Epoch [1].[50] Loss: 1.2587213516235352\n",
      "Epoch [1].[75] Loss: 0.9080191850662231\n",
      "Epoch [1].[100] Loss: 0.8253974914550781\n",
      "Epoch [1].[125] Loss: 0.7887484431266785\n",
      "Epoch [1].[150] Loss: 0.7643625140190125\n",
      "Epoch [1].[175] Loss: 0.9295473098754883\n",
      "Epoch [1].[200] Loss: 0.6828395128250122\n",
      "Epoch [1].[225] Loss: 0.41368886828422546\n",
      "Epoch [1].[250] Loss: 0.5650813579559326\n",
      "Epoch [1].[275] Loss: 0.3309713304042816\n",
      "\n",
      "Epoch [1] Train accuracy: 0.7949120603015075\n",
      "\n",
      "Epoch [1] Test accuracy: 0.5222830336200156\n",
      "\n",
      "Epoch [2].[0] Loss: 0.24613016843795776\n",
      "Epoch [2].[25] Loss: 0.36898088455200195\n",
      "Epoch [2].[50] Loss: 0.272490918636322\n",
      "Epoch [2].[75] Loss: 0.5769102573394775\n",
      "Epoch [2].[100] Loss: 0.4156542420387268\n",
      "Epoch [2].[125] Loss: 0.29828163981437683\n",
      "Epoch [2].[150] Loss: 0.48841753602027893\n",
      "Epoch [2].[175] Loss: 0.32642698287963867\n",
      "Epoch [2].[200] Loss: 0.4284372329711914\n",
      "Epoch [2].[225] Loss: 0.2629874348640442\n",
      "Epoch [2].[250] Loss: 0.38396742939949036\n",
      "Epoch [2].[275] Loss: 0.19530946016311646\n",
      "\n",
      "Epoch [2] Train accuracy: 0.8922738693467337\n",
      "\n",
      "Epoch [2] Test accuracy: 0.6559812353401094\n",
      "\n",
      "Epoch [3].[0] Loss: 0.27713072299957275\n",
      "Epoch [3].[25] Loss: 0.24239562451839447\n",
      "Epoch [3].[50] Loss: 0.38837218284606934\n",
      "Epoch [3].[75] Loss: 0.265144944190979\n",
      "Epoch [3].[100] Loss: 0.35106760263442993\n",
      "Epoch [3].[125] Loss: 0.2828522324562073\n",
      "Epoch [3].[150] Loss: 0.2276180386543274\n",
      "Epoch [3].[175] Loss: 0.23570199310779572\n",
      "Epoch [3].[200] Loss: 0.17003202438354492\n",
      "Epoch [3].[225] Loss: 0.2666236460208893\n",
      "Epoch [3].[250] Loss: 0.24615801870822906\n",
      "Epoch [3].[275] Loss: 0.3725912272930145\n",
      "\n",
      "Epoch [3] Train accuracy: 0.9022194304857621\n",
      "\n",
      "Epoch [3] Test accuracy: 0.7021110242376857\n",
      "\n",
      "Epoch [4].[0] Loss: 0.2884548306465149\n",
      "Epoch [4].[25] Loss: 0.2969701588153839\n",
      "Epoch [4].[50] Loss: 0.21048438549041748\n",
      "Epoch [4].[75] Loss: 0.24765390157699585\n",
      "Epoch [4].[100] Loss: 0.10744127631187439\n",
      "Epoch [4].[125] Loss: 0.12981471419334412\n",
      "Epoch [4].[150] Loss: 0.22703740000724792\n",
      "Epoch [4].[175] Loss: 0.17648042738437653\n",
      "Epoch [4].[200] Loss: 0.23125791549682617\n",
      "Epoch [4].[225] Loss: 0.11064808815717697\n",
      "Epoch [4].[250] Loss: 0.09265211224555969\n",
      "Epoch [4].[275] Loss: 0.2300618290901184\n",
      "\n",
      "Epoch [4] Train accuracy: 0.9605318257956449\n",
      "\n",
      "Epoch [4] Test accuracy: 0.7716966379984362\n",
      "\n",
      "Epoch [5].[0] Loss: 0.14158034324645996\n",
      "Epoch [5].[25] Loss: 0.16532480716705322\n",
      "Epoch [5].[50] Loss: 0.08807629346847534\n",
      "Epoch [5].[75] Loss: 0.0909002274274826\n",
      "Epoch [5].[100] Loss: 0.1257750689983368\n",
      "Epoch [5].[125] Loss: 0.1505759358406067\n",
      "Epoch [5].[150] Loss: 0.28005456924438477\n",
      "Epoch [5].[175] Loss: 0.17959797382354736\n",
      "Epoch [5].[200] Loss: 0.1894189864397049\n",
      "Epoch [5].[225] Loss: 0.13126881420612335\n",
      "Epoch [5].[250] Loss: 0.09944521635770798\n",
      "Epoch [5].[275] Loss: 0.10154782980680466\n",
      "\n",
      "Epoch [5] Train accuracy: 0.9798994974874372\n",
      "\n",
      "Epoch [5] Test accuracy: 0.8295543393275997\n",
      "\n",
      "Epoch [6].[0] Loss: 0.24973906576633453\n",
      "Epoch [6].[25] Loss: 0.10795572400093079\n",
      "Epoch [6].[50] Loss: 0.029815450310707092\n",
      "Epoch [6].[75] Loss: 0.0542658194899559\n",
      "Epoch [6].[100] Loss: 0.17319972813129425\n",
      "Epoch [6].[125] Loss: 0.12388671189546585\n",
      "Epoch [6].[150] Loss: 0.03453570604324341\n",
      "Epoch [6].[175] Loss: 0.04958000034093857\n",
      "Epoch [6].[200] Loss: 0.0828494280576706\n",
      "Epoch [6].[225] Loss: 0.013018999248743057\n",
      "Epoch [6].[250] Loss: 0.07897735387086868\n",
      "Epoch [6].[275] Loss: 0.07052091509103775\n",
      "\n",
      "Epoch [6] Train accuracy: 0.9857621440536013\n",
      "\n",
      "Epoch [6] Test accuracy: 0.8318999218139171\n",
      "\n",
      "Epoch [7].[0] Loss: 0.12591630220413208\n",
      "Epoch [7].[25] Loss: 0.09574566781520844\n",
      "Epoch [7].[50] Loss: 0.04467201605439186\n",
      "Epoch [7].[75] Loss: 0.10749752819538116\n",
      "Epoch [7].[100] Loss: 0.029682844877243042\n",
      "Epoch [7].[125] Loss: 0.01266342680901289\n",
      "Epoch [7].[150] Loss: 0.18977531790733337\n",
      "Epoch [7].[175] Loss: 0.05682023614645004\n",
      "Epoch [7].[200] Loss: 0.30769768357276917\n",
      "Epoch [7].[225] Loss: 0.025898408144712448\n",
      "Epoch [7].[250] Loss: 0.05898197367787361\n",
      "Epoch [7].[275] Loss: 0.010620491579174995\n",
      "\n",
      "Epoch [7] Train accuracy: 0.9959170854271356\n",
      "\n",
      "Epoch [7] Test accuracy: 0.8827208756841283\n",
      "\n",
      "Epoch [8].[0] Loss: 0.055391501635313034\n",
      "Epoch [8].[25] Loss: 0.02416916936635971\n",
      "Epoch [8].[50] Loss: 0.020878808572888374\n",
      "Epoch [8].[75] Loss: 0.007989881560206413\n",
      "Epoch [8].[100] Loss: 0.010329373180866241\n",
      "Epoch [8].[125] Loss: 0.10580980032682419\n",
      "Epoch [8].[150] Loss: 0.06159500032663345\n",
      "Epoch [8].[175] Loss: 0.016917334869503975\n",
      "Epoch [8].[200] Loss: 0.041296783834695816\n",
      "Epoch [8].[225] Loss: 0.04793790727853775\n",
      "Epoch [8].[250] Loss: 0.0321231335401535\n",
      "Epoch [8].[275] Loss: 0.017645929008722305\n",
      "\n",
      "Epoch [8] Train accuracy: 0.9964405360134003\n",
      "\n",
      "Epoch [8] Test accuracy: 0.8983580922595777\n",
      "\n",
      "Epoch [9].[0] Loss: 0.01844733953475952\n",
      "Epoch [9].[25] Loss: 0.030209071934223175\n",
      "Epoch [9].[50] Loss: 0.016288863494992256\n",
      "Epoch [9].[75] Loss: 0.0395478792488575\n",
      "Epoch [9].[100] Loss: 0.024915842339396477\n",
      "Epoch [9].[125] Loss: 0.06924494355916977\n",
      "Epoch [9].[150] Loss: 0.01390957459807396\n",
      "Epoch [9].[175] Loss: 0.007581587880849838\n",
      "Epoch [9].[200] Loss: 0.008935126475989819\n",
      "Epoch [9].[225] Loss: 0.025049038231372833\n",
      "Epoch [9].[250] Loss: 0.039303556084632874\n",
      "Epoch [9].[275] Loss: 0.012285202741622925\n",
      "\n",
      "Epoch [9] Train accuracy: 0.9935092127303182\n",
      "\n",
      "Epoch [9] Test accuracy: 0.8608287724784989\n",
      "\n",
      "Epoch [10].[0] Loss: 0.017300760373473167\n",
      "Epoch [10].[25] Loss: 0.009152411483228207\n",
      "Epoch [10].[50] Loss: 0.027628982439637184\n",
      "Epoch [10].[75] Loss: 0.017288416624069214\n",
      "Epoch [10].[100] Loss: 0.0676954835653305\n",
      "Epoch [10].[125] Loss: 0.001203881110996008\n",
      "Epoch [10].[150] Loss: 0.00892048329114914\n",
      "Epoch [10].[175] Loss: 0.007465452421456575\n",
      "Epoch [10].[200] Loss: 0.013616734184324741\n",
      "Epoch [10].[225] Loss: 0.00544454762712121\n",
      "Epoch [10].[250] Loss: 0.0029948491137474775\n",
      "Epoch [10].[275] Loss: 0.020609911531209946\n",
      "\n",
      "Epoch [10] Train accuracy: 0.9994765494137353\n",
      "\n",
      "Epoch [10] Test accuracy: 0.890539483971853\n",
      "\n",
      "Epoch [11].[0] Loss: 0.006566841155290604\n",
      "Epoch [11].[25] Loss: 0.010864957235753536\n",
      "Epoch [11].[50] Loss: 0.001832952257245779\n",
      "Epoch [11].[75] Loss: 0.010313309729099274\n",
      "Epoch [11].[100] Loss: 0.033635638654232025\n",
      "Epoch [11].[125] Loss: 0.0053358785808086395\n",
      "Epoch [11].[150] Loss: 0.008506523445248604\n",
      "Epoch [11].[175] Loss: 0.009107002057135105\n",
      "Epoch [11].[200] Loss: 0.015379243530333042\n",
      "Epoch [11].[225] Loss: 0.05318797379732132\n",
      "Epoch [11].[250] Loss: 0.01539926789700985\n",
      "Epoch [11].[275] Loss: 0.024272287264466286\n",
      "\n",
      "Epoch [11] Train accuracy: 0.9929857621440537\n",
      "\n",
      "Epoch [11] Test accuracy: 0.8835027365129007\n",
      "\n",
      "Epoch [12].[0] Loss: 0.03364972770214081\n",
      "Epoch [12].[25] Loss: 0.0014456873759627342\n",
      "Epoch [12].[50] Loss: 0.01595761999487877\n",
      "Epoch [12].[75] Loss: 0.0030796523205935955\n",
      "Epoch [12].[100] Loss: 0.03890141472220421\n",
      "Epoch [12].[125] Loss: 0.05431953817605972\n",
      "Epoch [12].[150] Loss: 0.00240958109498024\n",
      "Epoch [12].[175] Loss: 0.01036451943218708\n",
      "Epoch [12].[200] Loss: 0.0028333698865026236\n",
      "Epoch [12].[225] Loss: 0.003456012113019824\n",
      "Epoch [12].[250] Loss: 0.0028291139751672745\n",
      "Epoch [12].[275] Loss: 0.0041052913293242455\n",
      "\n",
      "Epoch [12] Train accuracy: 0.9965452261306532\n",
      "\n",
      "Epoch [12] Test accuracy: 0.8522283033620016\n",
      "\n",
      "Epoch [13].[0] Loss: 0.022988881915807724\n",
      "Epoch [13].[25] Loss: 0.012378544546663761\n",
      "Epoch [13].[50] Loss: 0.0008182168239727616\n",
      "Epoch [13].[75] Loss: 0.0005721466732211411\n",
      "Epoch [13].[100] Loss: 0.0009288011351600289\n",
      "Epoch [13].[125] Loss: 0.0027038617990911007\n",
      "Epoch [13].[150] Loss: 0.0006288535660132766\n",
      "Epoch [13].[175] Loss: 0.0040070535615086555\n",
      "Epoch [13].[200] Loss: 0.0018457095138728619\n",
      "Epoch [13].[225] Loss: 0.004830613266676664\n",
      "Epoch [13].[250] Loss: 0.0011085406877100468\n",
      "Epoch [13].[275] Loss: 0.014354798011481762\n",
      "\n",
      "Epoch [13] Train accuracy: 0.9993718592964824\n",
      "\n",
      "Epoch [13] Test accuracy: 0.9030492572322126\n",
      "\n",
      "Epoch [14].[0] Loss: 0.0014432664029300213\n",
      "Epoch [14].[25] Loss: 0.06168244406580925\n",
      "Epoch [14].[50] Loss: 0.017324361950159073\n",
      "Epoch [14].[75] Loss: 0.008870144374668598\n",
      "Epoch [14].[100] Loss: 0.00425163796171546\n",
      "Epoch [14].[125] Loss: 0.0045984662137925625\n",
      "Epoch [14].[150] Loss: 0.0019451972329989076\n",
      "Epoch [14].[175] Loss: 0.0025317715480923653\n",
      "Epoch [14].[200] Loss: 0.004374371841549873\n",
      "Epoch [14].[225] Loss: 0.0008564231102354825\n",
      "Epoch [14].[250] Loss: 0.005233401898294687\n",
      "Epoch [14].[275] Loss: 0.0002793976163957268\n",
      "\n",
      "Epoch [14] Train accuracy: 0.9996859296482412\n",
      "\n",
      "Epoch [14] Test accuracy: 0.8889757623143081\n",
      "\n",
      "Epoch [15].[0] Loss: 0.0019918978214263916\n",
      "Epoch [15].[25] Loss: 0.0016323091695085168\n",
      "Epoch [15].[50] Loss: 0.0012240776559337974\n",
      "Epoch [15].[75] Loss: 0.0011224077316001058\n",
      "Epoch [15].[100] Loss: 0.0021170733962208033\n",
      "Epoch [15].[125] Loss: 0.0011634830152615905\n",
      "Epoch [15].[150] Loss: 0.00013443213538266718\n",
      "Epoch [15].[175] Loss: 0.0009536921861581504\n",
      "Epoch [15].[200] Loss: 0.010771607980132103\n",
      "Epoch [15].[225] Loss: 0.06154026463627815\n",
      "Epoch [15].[250] Loss: 0.005268032196909189\n",
      "Epoch [15].[275] Loss: 0.00902404822409153\n",
      "\n",
      "Epoch [15] Train accuracy: 0.9993718592964824\n",
      "\n",
      "Epoch [15] Test accuracy: 0.8944487881157154\n",
      "\n",
      "Epoch [16].[0] Loss: 0.005480365827679634\n",
      "Epoch [16].[25] Loss: 0.01868700608611107\n",
      "Epoch [16].[50] Loss: 0.0007437572930939496\n",
      "Epoch [16].[75] Loss: 0.0406138077378273\n",
      "Epoch [16].[100] Loss: 0.0007281397702172399\n",
      "Epoch [16].[125] Loss: 0.020587995648384094\n",
      "Epoch [16].[150] Loss: 0.0007053555455058813\n",
      "Epoch [16].[175] Loss: 0.000721651129424572\n",
      "Epoch [16].[200] Loss: 0.02285744808614254\n",
      "Epoch [16].[225] Loss: 0.001678019529208541\n",
      "Epoch [16].[250] Loss: 0.014819000847637653\n",
      "Epoch [16].[275] Loss: 0.0023155396338552237\n",
      "\n",
      "Epoch [16] Train accuracy: 0.9988484087102177\n",
      "\n",
      "Epoch [16] Test accuracy: 0.9053948397185301\n",
      "\n",
      "Epoch [17].[0] Loss: 0.0013646415900439024\n",
      "Epoch [17].[25] Loss: 0.006774834357202053\n",
      "Epoch [17].[50] Loss: 0.004472505301237106\n",
      "Epoch [17].[75] Loss: 0.011591006070375443\n",
      "Epoch [17].[100] Loss: 0.0005818486679345369\n",
      "Epoch [17].[125] Loss: 0.0024306627456098795\n",
      "Epoch [17].[150] Loss: 0.020989645272493362\n",
      "Epoch [17].[175] Loss: 0.0013697459362447262\n",
      "Epoch [17].[200] Loss: 0.016468225046992302\n",
      "Epoch [17].[225] Loss: 0.05259431153535843\n",
      "Epoch [17].[250] Loss: 0.016938399523496628\n",
      "Epoch [17].[275] Loss: 0.004584389738738537\n",
      "\n",
      "Epoch [17] Train accuracy: 0.9966499162479062\n",
      "\n",
      "Epoch [17] Test accuracy: 0.874120406567631\n",
      "\n",
      "Epoch [18].[0] Loss: 0.009082134813070297\n",
      "Epoch [18].[25] Loss: 0.0006482820608653128\n",
      "Epoch [18].[50] Loss: 0.0046841735020279884\n",
      "Epoch [18].[75] Loss: 0.010795833542943\n",
      "Epoch [18].[100] Loss: 0.002242953982204199\n",
      "Epoch [18].[125] Loss: 0.0005426495335996151\n",
      "Epoch [18].[150] Loss: 0.0022513624280691147\n",
      "Epoch [18].[175] Loss: 0.001231316477060318\n",
      "Epoch [18].[200] Loss: 0.0010050117271021008\n",
      "Epoch [18].[225] Loss: 0.0024826000444591045\n",
      "Epoch [18].[250] Loss: 0.0004732199013233185\n",
      "Epoch [18].[275] Loss: 0.016202755272388458\n",
      "\n",
      "Epoch [18] Train accuracy: 0.9982202680067002\n",
      "\n",
      "Epoch [18] Test accuracy: 0.9007036747458952\n",
      "\n",
      "Epoch [19].[0] Loss: 0.018107034265995026\n",
      "Epoch [19].[25] Loss: 0.03922758996486664\n",
      "Epoch [19].[50] Loss: 0.0008162562153302133\n",
      "Epoch [19].[75] Loss: 0.0010260692797601223\n",
      "Epoch [19].[100] Loss: 0.0017236452549695969\n",
      "Epoch [19].[125] Loss: 0.00016227738524321467\n",
      "Epoch [19].[150] Loss: 0.0006184349185787141\n",
      "Epoch [19].[175] Loss: 0.000205982883926481\n",
      "Epoch [19].[200] Loss: 0.004272731486707926\n",
      "Epoch [19].[225] Loss: 0.0001143221597885713\n",
      "Epoch [19].[250] Loss: 0.010663044638931751\n",
      "Epoch [19].[275] Loss: 0.0002451430191285908\n",
      "\n",
      "Epoch [19] Train accuracy: 0.9998953098827471\n",
      "\n",
      "Epoch [19] Test accuracy: 0.8960125097732604\n",
      "\n",
      "Epoch [20].[0] Loss: 0.00037870247615501285\n",
      "Epoch [20].[25] Loss: 0.0036868425086140633\n",
      "Epoch [20].[50] Loss: 3.9515303797088563e-05\n",
      "Epoch [20].[75] Loss: 0.002538817236199975\n",
      "Epoch [20].[100] Loss: 0.0007891756831668317\n",
      "Epoch [20].[125] Loss: 7.002406346146017e-05\n",
      "Epoch [20].[150] Loss: 0.0011867049615830183\n",
      "Epoch [20].[175] Loss: 0.00010730422945925966\n",
      "Epoch [20].[200] Loss: 0.0003045888734050095\n",
      "Epoch [20].[225] Loss: 0.0006377623649314046\n",
      "Epoch [20].[250] Loss: 0.0006532407714985311\n",
      "Epoch [20].[275] Loss: 0.000630463007837534\n",
      "\n",
      "Epoch [20] Train accuracy: 1.0\n",
      "\n",
      "Epoch [20] Test accuracy: 0.9202501954652071\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20 # hyperparameter\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_model(model, optimizer, criterion, device, train_loader, epoch)\n",
    "    test_model(model, device, test_loader, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172023fa-6761-4ee3-9592-0601a35fb227",
   "metadata": {},
   "source": [
    "# Reflection\n",
    "### Results\n",
    "The best test accuracy obtained was around 92%. The test accuracy tended to be consistently about 10% below the training accuracy, which reached close to 100% accuracy. This suggests the training set was overfitted at some point.\n",
    "### Improvements\n",
    "The outcome of the Alzeimers CNN could have potentially been better if slight Data Augmentation was implemented (slight rotation, change in contrast and brightness, added blurness/sharpness, etc.), in order to add more noise to generalize the dataset more.\n",
    "\n",
    "A better dataset could also have yielded better results. The [dataset](https://huggingface.co/datasets/yogitamakkar178/mri_scans_alzeimer_detection) used is relatively small (~10.8k entries), has differently balanced train and test sets, and has a very imbalanced test set. A more balanced and larger dataset could have definitely improved the test accuracy.\n",
    "\n",
    "Implementing normalization in the data transformation pipeline could have helped the neural network, specifically the optimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d31539-c1f1-42c3-a964-69c5ff706173",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
