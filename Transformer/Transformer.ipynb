{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "956cde40-5eaa-4466-a6be-0a4f10b22222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchvision.transforms import v2\n",
    "from datasets import load_dataset\n",
    "import tiktoken\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac2d5eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from https://pytorch-tutorials-preview.netlify.app/beginner/transformer_tutorial.html\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 d_model: int, \n",
    "                 dropout: float = 0.1, \n",
    "                 max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(1, max_len, d_model)\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[batch_size, seq_len, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0ae2853",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, \n",
    "                 d_model: int, \n",
    "                 d_query: int = 128, \n",
    "                 n_heads: int = 8,\n",
    "                 device: torch.device = torch.device(\"cpu\")):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_query)\n",
    "        self.W_k = nn.Linear(d_model, d_query)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.scaling_factor = math.sqrt(d_query)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        q = self.W_q(x)\n",
    "        k = self.W_k(x)\n",
    "        v = self.W_v(x)\n",
    "\n",
    "        attention_pattern = torch.matmul(q, torch.transpose(k, 1, 2)) / self.scaling_factor\n",
    "        \n",
    "        seq_len = attention_pattern.shape[-1]\n",
    "        mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool().to(self.device)\n",
    "        attention_pattern = torch.masked_fill(attention_pattern, mask, float(\"-inf\"))\n",
    "\n",
    "        attention_pattern = self.softmax(attention_pattern)\n",
    "\n",
    "        output = torch.matmul(attention_pattern, v)\n",
    "        \n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd25bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron(nn.Module):\n",
    "    def __init__(self, \n",
    "                 d_model: int, \n",
    "                 d_up: int = 256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.Linear(d_model, d_up)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.down = nn.Linear(d_up, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        output = self.up(x)\n",
    "        output = self.relu(output)\n",
    "        output = self.down(output)\n",
    "\n",
    "        output = output + x\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7cbf8aa-4165-4b6f-963d-f1bbb138d0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 n_vocab: int, \n",
    "                 d_model: int = 128, \n",
    "                 d_query: int = 128, \n",
    "                 n_heads: int = 8, \n",
    "                 n_layers: int = 4, \n",
    "                 d_up: int = 256,\n",
    "                 device: torch.device = torch.device(\"cpu\")):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(n_vocab, d_model)\n",
    "        self.pe = PositionalEncoding(d_model, max_len=50000)\n",
    "\n",
    "        self.attention_layers = nn.ModuleList([layer for _ in range(n_layers) for layer in \n",
    "                                               (SelfAttention(d_model, d_query, n_heads, device), \n",
    "                                                nn.LayerNorm(d_model),\n",
    "                                                MultilayerPerceptron(d_model, d_up))])\n",
    "\n",
    "        # self.self_attention = SelfAttention(d_model, d_query, n_heads, device)\n",
    "        # self.mlp = MultilayerPerceptron(d_model, d_up)\n",
    "\n",
    "        self.unembedding = nn.Linear(d_model, n_vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.pe(x)\n",
    "\n",
    "        for layer in self.attention_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        x = self.unembedding(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec3c36a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, device, criterion, test_loader):\n",
    "    with torch.no_grad():\n",
    "        avg_loss = 0\n",
    "        for idx, inputs in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = inputs[:,1:]\n",
    "            outputs = model(inputs)[:,:-1,:]\n",
    "\n",
    "            targets = targets.reshape(-1)\n",
    "            outputs = outputs.reshape(-1, outputs.shape[-1])\n",
    "            \n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            avg_loss += loss\n",
    "\n",
    "        avg_loss /= len(test_loader)\n",
    "        print(f\"VALIDATE: Average Loss: {avg_loss}\")\n",
    "\n",
    "def train_model(model, optimizer, criterion, device, train_loader, validation_loader, accum_steps, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for idx, inputs in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = inputs[:,1:]\n",
    "        outputs = model(inputs)[:,:-1,:]\n",
    "\n",
    "        targets = targets.reshape(-1)\n",
    "        outputs = outputs.reshape(-1, outputs.shape[-1])\n",
    "        \n",
    "        loss = criterion(outputs, targets) / accum_steps\n",
    "        loss.backward()\n",
    "\n",
    "        if (idx + 1) % accum_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        if (idx + 1) % (accum_steps * 4) == 0:\n",
    "            print(f\"Epoch [{epoch}].[{idx}] Loss: {loss * accum_steps}\")\n",
    "\n",
    "        if (idx + 1) % (accum_steps * 16) == 0:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"TIME: {elapsed_time / (accum_steps * 16)} seconds per batch\")\n",
    "            start_time = time.time()\n",
    "\n",
    "            allocated = torch.cuda.memory_allocated() / 1e9\n",
    "            reserved = torch.cuda.memory_reserved() / 1e9\n",
    "            peak = torch.cuda.max_memory_allocated() / 1e9\n",
    "            print(f\"USAGE: Allocated {allocated:.2f}GB, Reserved {reserved:.2f}GB, Peak: {peak:.2f}GB\")\n",
    "\n",
    "        if (idx + 1) % (accum_steps * 32) == 0:\n",
    "            validate_model(model, device, criterion, validation_loader)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd02d0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81cedc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.set_float32_matmul_precision('high')\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86c0e410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 2141709\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train+validation\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca7d5ead-bd78-46a6-82cd-cdcec26fe137",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38761c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sequence):\n",
    "    sequence[\"text\"] = torch.tensor(encoder.encode(sequence[\"text\"]), dtype=torch.int64)\n",
    "    return sequence\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, num_proc=8).with_format(\"torch\")\n",
    "tokenized_dataset = tokenized_dataset.train_test_split(test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c17f5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tokenized_dataset[\"train\"][\"text\"]\n",
    "\n",
    "test_set = tokenized_dataset[\"test\"].train_test_split(test_size=0.001, shuffle=True)\n",
    "test = test_set[\"train\"][\"text\"]\n",
    "validation = test_set[\"test\"][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edf5859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 2\n",
    "accum_steps = 32\n",
    "d_model  = 256\n",
    "d_query  = 64\n",
    "d_up = 256\n",
    "n_heads  = 4\n",
    "n_layers = 4\n",
    "\n",
    "n_vocab  = encoder.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7887f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100277\n"
     ]
    }
   ],
   "source": [
    "print(n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29143c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_padding(batch):\n",
    "    batch = pad_sequence(batch, batch_first=True)\n",
    "    return batch\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn_padding)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=True, collate_fn=collate_fn_padding)\n",
    "validation_loader = DataLoader(validation, batch_size=batch_size, shuffle=True, collate_fn=collate_fn_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "417bc5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(n_vocab=n_vocab, \n",
    "                    d_model=d_model, \n",
    "                    d_query=d_query, \n",
    "                    n_heads=n_heads, \n",
    "                    n_layers=n_layers, \n",
    "                    d_up=d_up, \n",
    "                    device=device).to(device)\n",
    "model = torch.compile(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9788985c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0117 16:22:13.128000 29837 torch/_inductor/utils.py:1613] [0/0] Not enough SMs to use max_autotune_gemm mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1].[127] Loss: 11.313318252563477\n",
      "Epoch [1].[255] Loss: 10.960888862609863\n",
      "Epoch [1].[383] Loss: 10.343829154968262\n",
      "Epoch [1].[511] Loss: 10.263548851013184\n",
      "TIME: 0.032832566648721695 seconds per batch\n",
      "USAGE: Allocated 0.86GB, Reserved 4.17GB, Peak: 3.77GB\n",
      "Epoch [1].[639] Loss: 9.068053245544434\n",
      "Epoch [1].[767] Loss: 10.245465278625488\n",
      "Epoch [1].[895] Loss: 8.016122817993164\n",
      "Epoch [1].[1023] Loss: 9.145559310913086\n",
      "TIME: 0.019266319926828146 seconds per batch\n",
      "USAGE: Allocated 0.88GB, Reserved 4.17GB, Peak: 3.77GB\n",
      "VALIDATE: Average Loss: 8.405720710754395\n",
      "Epoch [1].[1151] Loss: 7.003304958343506\n",
      "Epoch [1].[1279] Loss: 7.640349388122559\n",
      "Epoch [1].[1407] Loss: 7.5531463623046875\n",
      "Epoch [1].[1535] Loss: 7.5790815353393555\n",
      "TIME: 0.025997907388955355 seconds per batch\n",
      "USAGE: Allocated 0.85GB, Reserved 4.23GB, Peak: 3.83GB\n",
      "Epoch [1].[1663] Loss: 6.104096412658691\n",
      "Epoch [1].[1791] Loss: 6.943158149719238\n",
      "Epoch [1].[1919] Loss: 6.1499342918396\n",
      "Epoch [1].[2047] Loss: 6.3445940017700195\n",
      "TIME: 0.01985983084887266 seconds per batch\n",
      "USAGE: Allocated 0.90GB, Reserved 4.95GB, Peak: 3.84GB\n",
      "VALIDATE: Average Loss: 6.003540992736816\n",
      "Epoch [1].[2175] Loss: 6.03765344619751\n",
      "Epoch [1].[2303] Loss: 4.796867847442627\n",
      "Epoch [1].[2431] Loss: 5.428086280822754\n",
      "Epoch [1].[2559] Loss: 5.5741286277771\n",
      "TIME: 0.02372154826298356 seconds per batch\n",
      "USAGE: Allocated 0.90GB, Reserved 4.95GB, Peak: 3.84GB\n",
      "Epoch [1].[2687] Loss: 5.049033164978027\n",
      "Epoch [1].[2815] Loss: 5.095229625701904\n",
      "Epoch [1].[2943] Loss: 5.281296730041504\n",
      "Epoch [1].[3071] Loss: 5.738682270050049\n",
      "TIME: 0.020885034929960966 seconds per batch\n",
      "USAGE: Allocated 0.89GB, Reserved 4.95GB, Peak: 3.84GB\n",
      "VALIDATE: Average Loss: 5.302672386169434\n",
      "Epoch [1].[3199] Loss: 5.8110880851745605\n",
      "Epoch [1].[3327] Loss: 5.769200801849365\n",
      "Epoch [1].[3455] Loss: 5.063082695007324\n",
      "Epoch [1].[3583] Loss: 4.657102584838867\n",
      "TIME: 0.023311852477490902 seconds per batch\n",
      "USAGE: Allocated 1.03GB, Reserved 4.95GB, Peak: 3.84GB\n",
      "Epoch [1].[3711] Loss: 5.3670334815979\n",
      "Epoch [1].[3839] Loss: 5.960312366485596\n",
      "Epoch [1].[3967] Loss: 5.872808456420898\n",
      "Epoch [1].[4095] Loss: 6.267874717712402\n",
      "TIME: 0.02042723260819912 seconds per batch\n",
      "USAGE: Allocated 0.82GB, Reserved 4.95GB, Peak: 3.84GB\n",
      "VALIDATE: Average Loss: 5.212799072265625\n",
      "Epoch [1].[4223] Loss: 4.940025806427002\n",
      "Epoch [1].[4351] Loss: 4.344242095947266\n",
      "Epoch [1].[4479] Loss: 5.670046806335449\n",
      "Epoch [1].[4607] Loss: 5.102075099945068\n",
      "TIME: 0.022873403504490852 seconds per batch\n",
      "USAGE: Allocated 0.88GB, Reserved 4.56GB, Peak: 4.19GB\n",
      "Epoch [1].[4735] Loss: 6.144431114196777\n",
      "Epoch [1].[4863] Loss: 5.442740440368652\n",
      "Epoch [1].[4991] Loss: 5.428670883178711\n",
      "Epoch [1].[5119] Loss: 5.6308913230896\n",
      "TIME: 0.021074573509395123 seconds per batch\n",
      "USAGE: Allocated 0.82GB, Reserved 5.36GB, Peak: 4.19GB\n",
      "VALIDATE: Average Loss: 5.149631500244141\n",
      "Epoch [1].[5247] Loss: 5.546969413757324\n",
      "Epoch [1].[5375] Loss: 5.505790710449219\n",
      "Epoch [1].[5503] Loss: 6.46179723739624\n",
      "Epoch [1].[5631] Loss: 5.185193061828613\n",
      "TIME: 0.023935929406434298 seconds per batch\n",
      "USAGE: Allocated 0.86GB, Reserved 5.36GB, Peak: 4.19GB\n",
      "Epoch [1].[5759] Loss: 5.593942165374756\n",
      "Epoch [1].[5887] Loss: 5.325995445251465\n",
      "Epoch [1].[6015] Loss: 4.646976947784424\n",
      "Epoch [1].[6143] Loss: 5.1547980308532715\n",
      "TIME: 0.019256808329373598 seconds per batch\n",
      "USAGE: Allocated 0.84GB, Reserved 5.36GB, Peak: 4.19GB\n",
      "VALIDATE: Average Loss: 5.157191753387451\n",
      "Epoch [1].[6271] Loss: 5.881787300109863\n",
      "Epoch [1].[6399] Loss: 4.137299060821533\n",
      "Epoch [1].[6527] Loss: 4.350343704223633\n",
      "Epoch [1].[6655] Loss: 5.2482733726501465\n",
      "TIME: 0.023885261733084917 seconds per batch\n",
      "USAGE: Allocated 0.85GB, Reserved 5.36GB, Peak: 4.19GB\n",
      "Epoch [1].[6783] Loss: 5.2944746017456055\n"
     ]
    }
   ],
   "source": [
    "train_model(model=model, \n",
    "            optimizer=optimizer, \n",
    "            criterion=criterion, \n",
    "            device=device, \n",
    "            train_loader=train_loader, \n",
    "            validation_loader=validation_loader, \n",
    "            accum_steps=accum_steps, \n",
    "            epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482a1d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = model(train[:8])\n",
    "# print(f\"output: {output.shape}\")\n",
    "# print(output[0,-4,:].argmax())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
