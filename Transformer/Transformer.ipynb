{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "956cde40-5eaa-4466-a6be-0a4f10b22222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchvision.transforms import v2\n",
    "from datasets import load_dataset\n",
    "import tiktoken\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac2d5eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from https://pytorch-tutorials-preview.netlify.app/beginner/transformer_tutorial.html\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 d_model: int, \n",
    "                 dropout: float = 0.1, \n",
    "                 max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(1, max_len, d_model)\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[batch_size, seq_len, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0ae2853",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, \n",
    "                 d_model: int, \n",
    "                 d_query: int = 128, \n",
    "                 n_heads: int = 8,\n",
    "                 device: torch.device = torch.device(\"cpu\")):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_query)\n",
    "        self.W_k = nn.Linear(d_model, d_query)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.scaling_factor = math.sqrt(d_query)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        \n",
    "        x = x.unsqueeze(1).repeat([1, self.n_heads, 1, 1])\n",
    "        \n",
    "        q = self.W_q(x)\n",
    "        k = self.W_k(x)\n",
    "        v = self.W_v(x)\n",
    "\n",
    "        attention_pattern = torch.matmul(q, torch.transpose(k, -2, -1)) / self.scaling_factor\n",
    "        \n",
    "        seq_len = attention_pattern.shape[-1]\n",
    "        mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool().to(self.device)\n",
    "        attention_pattern = torch.masked_fill(attention_pattern, mask, float(\"-inf\"))\n",
    "\n",
    "        attention_pattern = self.softmax(attention_pattern)\n",
    "\n",
    "        output = torch.sum(torch.matmul(attention_pattern, v), dim=1)\n",
    "        \n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd25bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron(nn.Module):\n",
    "    def __init__(self, \n",
    "                 d_model: int, \n",
    "                 d_up: int = 256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.Linear(d_model, d_up)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.down = nn.Linear(d_up, d_model)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        output = self.up(x)\n",
    "        output = self.relu(output)\n",
    "        output = self.down(output)\n",
    "\n",
    "        output = output + x\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7cbf8aa-4165-4b6f-963d-f1bbb138d0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 n_vocab: int, \n",
    "                 d_model: int = 128, \n",
    "                 d_query: int = 128, \n",
    "                 n_heads: int = 8, \n",
    "                 n_layers: int = 4, \n",
    "                 d_up: int = 256,\n",
    "                 device: torch.device = torch.device(\"cpu\")):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(n_vocab, d_model)\n",
    "        self.pe = PositionalEncoding(d_model, max_len=50000)\n",
    "\n",
    "        self.attention_layers = nn.ModuleList([layer for _ in range(n_layers) for layer in \n",
    "                                               (SelfAttention(d_model, d_query, n_heads, device), \n",
    "                                                nn.LayerNorm(d_model),\n",
    "                                                MultilayerPerceptron(d_model, d_up))])\n",
    "\n",
    "        # self.self_attention = SelfAttention(d_model, d_query, n_heads, device)\n",
    "        # self.mlp = MultilayerPerceptron(d_model, d_up)\n",
    "\n",
    "        self.unembedding = nn.Linear(d_model, n_vocab)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "        x = self.pe(x)\n",
    "\n",
    "        for layer in self.attention_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        x = self.unembedding(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa09e45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelCheckpoint():\n",
    "    def __init__(self, model_state, optim_state, epoch: int, batch: int, rng_state: torch.Tensor):\n",
    "        self.model_state = model_state\n",
    "        self.optim_state = optim_state\n",
    "        self.epoch       = epoch\n",
    "        self.batch       = batch\n",
    "        self.rng_state   = rng_state\n",
    "    def save(self, file_path):\n",
    "        torch.save({\n",
    "            \"model_state\": self.model_state,\n",
    "            \"optim_state\": self.optim_state,\n",
    "            \"epoch\"      : self.epoch,\n",
    "            \"batch\"      : self.batch,\n",
    "            \"rng_state\"  : self.rng_state\n",
    "        }, file_path)\n",
    "        print(f\"Model checkpoint saved at {file_path} at epoch {self.epoch} batch {self.batch}\")\n",
    "    @staticmethod\n",
    "    def load(file_path):\n",
    "        checkpoint = torch.load(file_path)\n",
    "        return ModelCheckpoint(checkpoint[\"model_state\"], \n",
    "                               checkpoint[\"optim_state\"], \n",
    "                               checkpoint[\"epoch\"], \n",
    "                               checkpoint[\"batch\"], \n",
    "                               checkpoint[\"rng_state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec3c36a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, \n",
    "                   device, \n",
    "                   criterion, \n",
    "                   test_loader):\n",
    "    with torch.no_grad():\n",
    "        avg_loss = 0\n",
    "        for idx, inputs in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = inputs[:,1:]\n",
    "            outputs = model(inputs)[:,:-1,:]\n",
    "\n",
    "            targets = targets.reshape(-1)\n",
    "            outputs = outputs.reshape(-1, outputs.shape[-1])\n",
    "            \n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            avg_loss += loss\n",
    "\n",
    "        avg_loss /= len(test_loader)\n",
    "        print(f\"VALIDATE: Average Loss: {avg_loss}\")\n",
    "\n",
    "def train_model(model: nn.Module, \n",
    "                optimizer, \n",
    "                criterion, \n",
    "                device, \n",
    "                train_loader, \n",
    "                validation_loader, \n",
    "                accum_steps,\n",
    "                num_epochs: int = 4,\n",
    "                checkpoint: ModelCheckpoint = None):\n",
    "    \n",
    "    epoch = 0\n",
    "    start_batch = 0\n",
    "\n",
    "    if checkpoint != None:\n",
    "        model.load_state_dict(checkpoint.model_state)\n",
    "        optimizer.load_state_dict(checkpoint.optim_state)\n",
    "        epoch = checkpoint.epoch\n",
    "        start_batch = checkpoint.batch\n",
    "        torch.set_rng_state(checkpoint.rng_state)\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epoch, num_epochs):\n",
    "        start_time = time.time()\n",
    "        for idx, inputs in enumerate(train_loader):\n",
    "            if idx > start_batch:\n",
    "                inputs = inputs.to(device)\n",
    "                targets = inputs[:,1:]\n",
    "                outputs = model(inputs)[:,:-1,:]\n",
    "\n",
    "                targets = targets.reshape(-1)\n",
    "                outputs = outputs.reshape(-1, outputs.shape[-1])\n",
    "                \n",
    "                loss = criterion(outputs, targets) / accum_steps\n",
    "                loss.backward()\n",
    "\n",
    "                if (idx + 1) % accum_steps == 0:\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                if (idx + 1) % (accum_steps * 4) == 0:\n",
    "                    print(f\"Epoch [{epoch}].[{idx}] Loss: {loss * accum_steps}\")\n",
    "\n",
    "                if (idx + 1) % (accum_steps * 16) == 0:\n",
    "                    elapsed_time = time.time() - start_time\n",
    "                    print(f\"TIME: {elapsed_time / (accum_steps * 16)} seconds per batch\")\n",
    "                    start_time = time.time()\n",
    "\n",
    "                    allocated = torch.cuda.memory_allocated() / 1e9\n",
    "                    reserved = torch.cuda.memory_reserved() / 1e9\n",
    "                    peak = torch.cuda.max_memory_allocated() / 1e9\n",
    "                    print(f\"USAGE: Allocated {allocated:.2f}GB, Reserved {reserved:.2f}GB, Peak: {peak:.2f}GB\")\n",
    "\n",
    "                if (idx + 1) % (accum_steps * 32) == 0:\n",
    "                    validate_model(model, device, criterion, validation_loader)\n",
    "                    checkpoint = ModelCheckpoint(model.state_dict(), \n",
    "                                                optimizer.state_dict(), \n",
    "                                                epoch, \n",
    "                                                idx, \n",
    "                                                torch.get_rng_state())\n",
    "                    checkpoint.save(\"checkpoint.pt\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81cedc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.set_float32_matmul_precision('high')\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86c0e410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 2141709\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train+validation\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca7d5ead-bd78-46a6-82cd-cdcec26fe137",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38761c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sequence):\n",
    "    sequence[\"text\"] = torch.tensor(encoder.encode(sequence[\"text\"]), dtype=torch.int64)\n",
    "    return sequence\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, num_proc=8).with_format(\"torch\")\n",
    "tokenized_dataset = tokenized_dataset.train_test_split(test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c17f5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tokenized_dataset[\"train\"][\"text\"]\n",
    "\n",
    "test_set = tokenized_dataset[\"test\"].train_test_split(test_size=0.001, shuffle=True)\n",
    "test = test_set[\"train\"][\"text\"]\n",
    "validation = test_set[\"test\"][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edf5859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 2\n",
    "accum_steps = 32\n",
    "d_model  = 256\n",
    "d_query  = 64\n",
    "d_up = 512\n",
    "n_heads  = 4\n",
    "n_layers = 4\n",
    "\n",
    "n_vocab  = encoder.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7887f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100277\n"
     ]
    }
   ],
   "source": [
    "print(n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5f9ba58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.3367,  0.1288],\n",
      "          [ 0.2345,  0.2303]],\n",
      "\n",
      "         [[ 0.3367,  0.1288],\n",
      "          [ 0.2345,  0.2303]],\n",
      "\n",
      "         [[ 0.3367,  0.1288],\n",
      "          [ 0.2345,  0.2303]],\n",
      "\n",
      "         [[ 0.3367,  0.1288],\n",
      "          [ 0.2345,  0.2303]]],\n",
      "\n",
      "\n",
      "        [[[-1.1229, -0.1863],\n",
      "          [ 2.2082, -0.6380]],\n",
      "\n",
      "         [[-1.1229, -0.1863],\n",
      "          [ 2.2082, -0.6380]],\n",
      "\n",
      "         [[-1.1229, -0.1863],\n",
      "          [ 2.2082, -0.6380]],\n",
      "\n",
      "         [[-1.1229, -0.1863],\n",
      "          [ 2.2082, -0.6380]]]])\n",
      "torch.Size([2, 4, 2, 2])\n",
      "tensor([[[ 1.3468,  0.5152],\n",
      "         [ 0.9378,  0.9213]],\n",
      "\n",
      "        [[-4.4914, -0.7453],\n",
      "         [ 8.8328, -2.5520]]])\n",
      "torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "test_tensor = torch.randn(2,2,2)\n",
    "test_tensor = test_tensor.unsqueeze(1)\n",
    "test_tensor = test_tensor.repeat(1,4,1,1)\n",
    "print(test_tensor)\n",
    "print(test_tensor.shape)\n",
    "test_tensor = torch.sum(test_tensor, dim=1)\n",
    "print(test_tensor)\n",
    "print(test_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29143c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_padding(batch):\n",
    "    batch = pad_sequence(batch, batch_first=True)\n",
    "    return batch\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn_padding)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=True, collate_fn=collate_fn_padding)\n",
    "validation_loader = DataLoader(validation, batch_size=batch_size, shuffle=True, collate_fn=collate_fn_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "417bc5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(n_vocab=n_vocab, \n",
    "                    d_model=d_model, \n",
    "                    d_query=d_query, \n",
    "                    n_heads=n_heads, \n",
    "                    n_layers=n_layers, \n",
    "                    d_up=d_up, \n",
    "                    device=device).to(device)\n",
    "# model = torch.compile(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9788985c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0].[127] Loss: 11.020341873168945\n",
      "Epoch [0].[255] Loss: 10.065437316894531\n",
      "Epoch [0].[383] Loss: 8.589371681213379\n",
      "Epoch [0].[511] Loss: 8.965344429016113\n",
      "TIME: 0.028048223815858364 seconds per batch\n",
      "USAGE: Allocated 0.85GB, Reserved 4.78GB, Peak: 4.36GB\n",
      "Epoch [0].[639] Loss: 9.545528411865234\n",
      "Epoch [0].[767] Loss: 9.132296562194824\n",
      "Epoch [0].[895] Loss: 7.2856364250183105\n",
      "Epoch [0].[1023] Loss: 7.764287948608398\n",
      "TIME: 0.026772727724164724 seconds per batch\n",
      "USAGE: Allocated 0.88GB, Reserved 4.78GB, Peak: 4.36GB\n",
      "VALIDATE: Average Loss: 8.018267631530762\n",
      "Model checkpoint saved at checkpoint.pt at epoch 0 batch 1023\n",
      "Epoch [0].[1151] Loss: 8.217638969421387\n",
      "Epoch [0].[1279] Loss: 8.103324890136719\n",
      "Epoch [0].[1407] Loss: 6.887085437774658\n",
      "Epoch [0].[1535] Loss: 6.411445617675781\n",
      "TIME: 0.03203374054282904 seconds per batch\n",
      "USAGE: Allocated 0.88GB, Reserved 4.78GB, Peak: 4.36GB\n",
      "Epoch [0].[1663] Loss: 5.6081037521362305\n",
      "Epoch [0].[1791] Loss: 6.965433120727539\n",
      "Epoch [0].[1919] Loss: 6.57459020614624\n",
      "Epoch [0].[2047] Loss: 6.747674465179443\n",
      "TIME: 0.026024804916232824 seconds per batch\n",
      "USAGE: Allocated 0.85GB, Reserved 4.78GB, Peak: 4.36GB\n",
      "VALIDATE: Average Loss: 5.56494665145874\n",
      "Model checkpoint saved at checkpoint.pt at epoch 0 batch 2047\n",
      "Epoch [0].[2175] Loss: 4.384857654571533\n",
      "Epoch [0].[2303] Loss: 4.930304050445557\n",
      "Epoch [0].[2431] Loss: 4.5449700355529785\n",
      "Epoch [0].[2559] Loss: 6.33753776550293\n",
      "TIME: 0.0321854492649436 seconds per batch\n",
      "USAGE: Allocated 0.87GB, Reserved 4.78GB, Peak: 4.36GB\n",
      "Epoch [0].[2687] Loss: 6.042402267456055\n",
      "Epoch [0].[2815] Loss: 5.3267645835876465\n",
      "Epoch [0].[2943] Loss: 5.901692867279053\n",
      "Epoch [0].[3071] Loss: 5.576667308807373\n",
      "TIME: 0.02715175924822688 seconds per batch\n",
      "USAGE: Allocated 0.83GB, Reserved 5.58GB, Peak: 4.36GB\n",
      "VALIDATE: Average Loss: 5.249988079071045\n",
      "Model checkpoint saved at checkpoint.pt at epoch 0 batch 3071\n",
      "Epoch [0].[3199] Loss: 5.067004203796387\n",
      "Epoch [0].[3327] Loss: 4.9743547439575195\n",
      "Epoch [0].[3455] Loss: 5.52419376373291\n",
      "Epoch [0].[3583] Loss: 5.293466091156006\n",
      "TIME: 0.032120696268975735 seconds per batch\n",
      "USAGE: Allocated 0.84GB, Reserved 5.58GB, Peak: 4.36GB\n",
      "Epoch [0].[3711] Loss: 5.910850524902344\n",
      "Epoch [0].[3839] Loss: 5.831585884094238\n",
      "Epoch [0].[3967] Loss: 5.177062511444092\n",
      "Epoch [0].[4095] Loss: 5.761264801025391\n",
      "TIME: 0.025783969555050135 seconds per batch\n",
      "USAGE: Allocated 0.88GB, Reserved 5.58GB, Peak: 4.36GB\n",
      "VALIDATE: Average Loss: 5.237551212310791\n",
      "Model checkpoint saved at checkpoint.pt at epoch 0 batch 4095\n",
      "Epoch [0].[4223] Loss: 5.341742038726807\n",
      "Epoch [0].[4351] Loss: 4.330378532409668\n",
      "Epoch [0].[4479] Loss: 3.950434446334839\n",
      "Epoch [0].[4607] Loss: 5.467171669006348\n",
      "TIME: 0.031950611155480146 seconds per batch\n",
      "USAGE: Allocated 0.89GB, Reserved 5.58GB, Peak: 4.36GB\n",
      "Epoch [0].[4735] Loss: 4.617631912231445\n",
      "Epoch [0].[4863] Loss: 5.025031566619873\n",
      "Epoch [0].[4991] Loss: 4.212835788726807\n",
      "Epoch [0].[5119] Loss: 6.22412633895874\n",
      "TIME: 0.026497114915400743 seconds per batch\n",
      "USAGE: Allocated 0.83GB, Reserved 5.58GB, Peak: 4.36GB\n",
      "VALIDATE: Average Loss: 5.2014665603637695\n",
      "Model checkpoint saved at checkpoint.pt at epoch 0 batch 5119\n",
      "Epoch [0].[5247] Loss: 5.698361873626709\n",
      "Epoch [0].[5375] Loss: 5.367188453674316\n",
      "Epoch [0].[5503] Loss: 5.199546813964844\n",
      "Epoch [0].[5631] Loss: 6.142830848693848\n",
      "TIME: 0.032837632577866316 seconds per batch\n",
      "USAGE: Allocated 0.85GB, Reserved 5.58GB, Peak: 4.36GB\n",
      "Epoch [0].[5759] Loss: 5.243741035461426\n",
      "Epoch [0].[5887] Loss: 5.336251258850098\n",
      "Epoch [0].[6015] Loss: 5.951211452484131\n",
      "Epoch [0].[6143] Loss: 4.890410423278809\n",
      "TIME: 0.02612044382840395 seconds per batch\n",
      "USAGE: Allocated 0.90GB, Reserved 5.58GB, Peak: 4.36GB\n",
      "VALIDATE: Average Loss: 5.144744873046875\n",
      "Model checkpoint saved at checkpoint.pt at epoch 0 batch 6143\n",
      "Epoch [0].[6271] Loss: 4.742621898651123\n",
      "Epoch [0].[6399] Loss: 5.4401936531066895\n",
      "Epoch [0].[6527] Loss: 5.7078094482421875\n",
      "Epoch [0].[6655] Loss: 5.718652725219727\n",
      "TIME: 0.03211949672549963 seconds per batch\n",
      "USAGE: Allocated 0.84GB, Reserved 5.58GB, Peak: 4.36GB\n",
      "Epoch [0].[6783] Loss: 4.682162761688232\n"
     ]
    }
   ],
   "source": [
    "# checkpoint = ModelCheckpoint.load(\"checkpoint.pt\")\n",
    "\n",
    "train_model(model=model, \n",
    "            optimizer=optimizer, \n",
    "            criterion=criterion, \n",
    "            device=device, \n",
    "            train_loader=train_loader, \n",
    "            validation_loader=validation_loader, \n",
    "            accum_steps=accum_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482a1d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(model, encoder: tiktoken.Encoding, device: torch.device, prompt: str):\n",
    "    sequence = encoder.encode(prompt)\n",
    "    with torch.no_grad():\n",
    "        for _ in range(100):\n",
    "            input = torch.tensor(sequence, dtype=torch.int64).unsqueeze(0).to(device)\n",
    "            output = model(input)\n",
    "            output = output[0,-1,:].argmax().item()\n",
    "            sequence = sequence + [output]\n",
    "\n",
    "        response = encoder.decode(sequence)\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6150ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "TorchRuntimeError",
     "evalue": "Dynamo failed to run FX node with fake tensors: call_function <built-in method matmul of type object at 0x79360d9dcaa0>(*(FakeTensor(..., device='cuda:0', size=(1, 4, 9, 64)), FakeTensor(..., device='cuda:0', size=(1, 9, 4, 64))), **{}): got RuntimeError('Attempting to broadcast a dimension of length 9 at -1! Mismatching argument at index 1 had [1, 9]; but expected shape should be broadcastable to [1, 4]')\n\nfrom user code:\n   File \"/tmp/ipykernel_109531/47181234.py\", line 30, in forward\n    x = layer(x)\n  File \"/tmp/ipykernel_109531/2885984990.py\", line 27, in forward\n    attention_pattern = torch.matmul(q, torch.transpose(k, 1, 2)) / self.scaling_factor\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTorchRuntimeError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# checkpoint = ModelCheckpoint.load(\"checkpoint.pt\")\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# model.load_state_dict(checkpoint.model_state)\u001b[39;00m\n\u001b[32m      4\u001b[39m prompt = \u001b[33m\"\u001b[39m\u001b[33mTell me a story about a hungry man.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m response = \u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mgenerate_response\u001b[39m\u001b[34m(model, encoder, device, prompt)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m100\u001b[39m):\n\u001b[32m      5\u001b[39m     \u001b[38;5;28minput\u001b[39m = torch.tensor(sequence, dtype=torch.int64).unsqueeze(\u001b[32m0\u001b[39m).to(device)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     output = output[\u001b[32m0\u001b[39m,-\u001b[32m1\u001b[39m,:].argmax().item()\n\u001b[32m      8\u001b[39m     sequence = sequence + [output]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/eval_frame.py:414\u001b[39m, in \u001b[36mOptimizedModule.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    404\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.nn.modules.module._has_any_global_hook():\n\u001b[32m    405\u001b[39m     warnings.warn(\n\u001b[32m    406\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUsing `torch.compile(module)` when there are global hooks on \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    407\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodules (e.g., from `register_module_forward_hook`); this will\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    412\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    413\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m414\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/eval_frame.py:832\u001b[39m, in \u001b[36m_TorchDynamoContext.__call__.<locals>.compile_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    829\u001b[39m _maybe_set_eval_frame(_callback_from_stance(callback))\n\u001b[32m    831\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m832\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    834\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config.verbose:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py:1875\u001b[39m, in \u001b[36mCatchErrorsWrapper.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, frame_state)\u001b[39m\n\u001b[32m   1869\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m hijacked_callback(\n\u001b[32m   1870\u001b[39m                 frame, cache_entry, \u001b[38;5;28mself\u001b[39m.hooks, frame_state\n\u001b[32m   1871\u001b[39m             )\n\u001b[32m   1873\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compile_lock, _disable_current_modes():\n\u001b[32m   1874\u001b[39m     \u001b[38;5;66;03m# skip=1: skip this frame\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1875\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_backend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1877\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py:1625\u001b[39m, in \u001b[36mConvertFrame.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[39m\n\u001b[32m   1623\u001b[39m counters[\u001b[33m\"\u001b[39m\u001b[33mframes\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtotal\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m   1624\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1625\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inner_convert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1627\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1628\u001b[39m     counters[\u001b[33m\"\u001b[39m\u001b[33mframes\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mok\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m   1629\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py:688\u001b[39m, in \u001b[36mConvertFrameAssert.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[39m\n\u001b[32m    685\u001b[39m     dynamo_tls.traced_frame_infos.append(info)\n\u001b[32m    687\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compile_context(CompileContext(compile_id)):\n\u001b[32m--> \u001b[39m\u001b[32m688\u001b[39m     result = \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_globals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_locals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_builtins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_one_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_package\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_frame_box\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_box\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.caching_precompile \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._package \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    710\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpackage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DynamoCache\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py:1434\u001b[39m, in \u001b[36m_compile\u001b[39m\u001b[34m(code, globals, locals, builtins, closure, compiler_fn, one_graph, export, export_constraints, hooks, cache_entry, cache_size, frame, frame_state, compile_id, skip, package, convert_frame_box)\u001b[39m\n\u001b[32m   1432\u001b[39m tracer_output = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1433\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1434\u001b[39m     guarded_code, tracer_output = \u001b[43mcompile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1436\u001b[39m     \u001b[38;5;66;03m# NB: We only put_code_state in success case.  Success case here\u001b[39;00m\n\u001b[32m   1437\u001b[39m     \u001b[38;5;66;03m# does include graph breaks; specifically, if a graph break still\u001b[39;00m\n\u001b[32m   1438\u001b[39m     \u001b[38;5;66;03m# resulted in a partially compiled graph, we WILL return here.  An\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1443\u001b[39m     \u001b[38;5;66;03m# to upload for graph break though, because this can prevent\u001b[39;00m\n\u001b[32m   1444\u001b[39m     \u001b[38;5;66;03m# extra graph break compilations.)\u001b[39;00m\n\u001b[32m   1445\u001b[39m     put_code_state()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_utils_internal.py:92\u001b[39m, in \u001b[36mcompile_time_strobelight_meta.<locals>.compile_time_strobelight_meta_inner.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;66;03m# This is not needed but we have it here to avoid having profile_compile_time\u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# in stack traces when profiling is not enabled.\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m StrobelightCompileTimeProfiler.enabled:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m StrobelightCompileTimeProfiler.profile_compile_time(\n\u001b[32m     95\u001b[39m     function, phase_name, *args, **kwargs\n\u001b[32m     96\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py:1117\u001b[39m, in \u001b[36m_compile.<locals>.compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks)\u001b[39m\n\u001b[32m   1111\u001b[39m     stack.enter_context(\n\u001b[32m   1112\u001b[39m         torch._dynamo.callback_handler.install_callbacks(\n\u001b[32m   1113\u001b[39m             CallbackTrigger.DYNAMO, \u001b[38;5;28mstr\u001b[39m(CompileContext.current_compile_id())\n\u001b[32m   1114\u001b[39m         )\n\u001b[32m   1115\u001b[39m     )\n\u001b[32m   1116\u001b[39m     stack.enter_context(CompileTimeInstructionCounter.record())\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m   1120\u001b[39m     ConvertFrameReturn(),\n\u001b[32m   1121\u001b[39m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1122\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py:1151\u001b[39m, in \u001b[36m_compile.<locals>._compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks)\u001b[39m\n\u001b[32m   1149\u001b[39m out_code = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1150\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1151\u001b[39m     dynamo_output = \u001b[43mcompile_frame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbuiltins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompiler_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrestart_reasons\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexport_constraints\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexport_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistributed_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistributed_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.SkipFrame \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m one_graph:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py:1032\u001b[39m, in \u001b[36mcompile_frame\u001b[39m\u001b[34m(code, globals, locals, builtins, closure, compiler_fn, one_graph, restart_reasons, export, export_constraints, frame_state, distributed_state, package)\u001b[39m\n\u001b[32m   1030\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1031\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcompile_attempt_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, log_pt2_compile_event=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m1032\u001b[39m         bytecode, tracer_output = \u001b[43mtransform_code_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1033\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m tracer_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1034\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m DynamoOutput(\n\u001b[32m   1035\u001b[39m             tracer_output=tracer_output,\n\u001b[32m   1036\u001b[39m             bytecode=bytecode,\n\u001b[32m   1037\u001b[39m             last_attempt_start_time=last_attempt_start_time,\n\u001b[32m   1038\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/bytecode_transformation.py:1592\u001b[39m, in \u001b[36mtransform_code_object\u001b[39m\u001b[34m(code, transformations, safe)\u001b[39m\n\u001b[32m   1589\u001b[39m \u001b[38;5;66;03m# propagate line nums again for added instructions\u001b[39;00m\n\u001b[32m   1590\u001b[39m propagate_line_nums(instructions)\n\u001b[32m-> \u001b[39m\u001b[32m1592\u001b[39m tracer_output = \u001b[43mtransformations\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1593\u001b[39m _, bytecode = clean_and_assemble_instructions(instructions, keys, code_options)\n\u001b[32m   1594\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m bytecode, tracer_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py:1004\u001b[39m, in \u001b[36mcompile_frame.<locals>.transform\u001b[39m\u001b[34m(instructions, code_options)\u001b[39m\n\u001b[32m    998\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransform\u001b[39m(\n\u001b[32m    999\u001b[39m     instructions: \u001b[38;5;28mlist\u001b[39m[Instruction], code_options: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mobject\u001b[39m]\n\u001b[32m   1000\u001b[39m ) -> DynamoTracerOutput:\n\u001b[32m   1001\u001b[39m     tf_mode_stack: \u001b[38;5;28mlist\u001b[39m[torch.overrides.TorchFunctionMode] = (\n\u001b[32m   1002\u001b[39m         torch.overrides._get_current_function_mode_stack()\n\u001b[32m   1003\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1004\u001b[39m     tracer_output = \u001b[43mtrace_frame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbuiltins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompiler_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtf_mode_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mspeculation_log\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcode_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexport_constraints\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexport_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistributed_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistributed_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1023\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m tracer_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1024\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tracer_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py:312\u001b[39m, in \u001b[36mpreserve_global_state.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    310\u001b[39m exit_stack.enter_context(torch_function_mode_stack_state_mgr)\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    314\u001b[39m     cleanup.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py:815\u001b[39m, in \u001b[36mtrace_frame\u001b[39m\u001b[34m(code, globals, locals, builtins, closure, compiler_fn, tf_mode_stack, one_graph, speculation_log, instructions, code_options, export, export_constraints, frame_state, distributed_state, package)\u001b[39m\n\u001b[32m    812\u001b[39m         tracer.output.call_cleanup_hooks()\n\u001b[32m    814\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m815\u001b[39m     \u001b[43mrun_tracer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    816\u001b[39m     tracer_output = DynamoTracerOutput(tracer)\n\u001b[32m    817\u001b[39m     output = tracer_output.output_graph\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py:797\u001b[39m, in \u001b[36mtrace_frame.<locals>.run_tracer\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    795\u001b[39m     tracer.output.mark_bytecode_tracing_start()\n\u001b[32m    796\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m tracing(tracer.output.tracing_context), tracer.set_current_tx():\n\u001b[32m--> \u001b[39m\u001b[32m797\u001b[39m         \u001b[43mtracer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.UnspecializeRestartAnalysis:\n\u001b[32m    799\u001b[39m     speculation_log.clear()  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py:1500\u001b[39m, in \u001b[36mInstructionTranslatorBase.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1498\u001b[39m \u001b[38;5;28mself\u001b[39m.start_point = \u001b[38;5;28mself\u001b[39m.instruction_pointer\n\u001b[32m   1499\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1500\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1501\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1502\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py:1348\u001b[39m, in \u001b[36mInstructionTranslatorBase.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1345\u001b[39m \u001b[38;5;28mself\u001b[39m.update_block_stack(inst)\n\u001b[32m   1347\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1348\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdispatch_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43minst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopcode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1349\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output.should_exit\n\u001b[32m   1350\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m TensorifyScalarRestartAnalysis:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py:904\u001b[39m, in \u001b[36mbreak_graph_if_unsupported.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_graph_break(\u001b[38;5;28mself\u001b[39m, inst, speculation.reason)\n\u001b[32m    903\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m904\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported \u001b[38;5;28;01mas\u001b[39;00m excp:\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.active_generic_context_managers:\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# We don't support graph break under GenericContextWrappingVariable,\u001b[39;00m\n\u001b[32m    908\u001b[39m         \u001b[38;5;66;03m# If there is, we roll back to the checkpoint and fall back.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py:3428\u001b[39m, in \u001b[36mInstructionTranslatorBase.CALL\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m   3426\u001b[39m \u001b[38;5;129m@break_graph_if_unsupported\u001b[39m(push=\u001b[32m1\u001b[39m)\n\u001b[32m   3427\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mCALL\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: Instruction) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3428\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py:3422\u001b[39m, in \u001b[36mInstructionTranslatorBase._call\u001b[39m\u001b[34m(self, inst, call_kw)\u001b[39m\n\u001b[32m   3417\u001b[39m     kwargs = {}\n\u001b[32m   3419\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   3420\u001b[39m     \u001b[38;5;66;03m# if call_function fails, need to set kw_names to None, otherwise\u001b[39;00m\n\u001b[32m   3421\u001b[39m     \u001b[38;5;66;03m# a subsequent call may have self.kw_names set to an old value\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3422\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3423\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   3424\u001b[39m     \u001b[38;5;28mself\u001b[39m.kw_names = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py:1266\u001b[39m, in \u001b[36mInstructionTranslatorBase.call_function\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m   1264\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inner_fn \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(inner_fn) \u001b[38;5;129;01mand\u001b[39;00m is_forbidden(inner_fn):\n\u001b[32m   1265\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAttempt to trace forbidden callable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_fn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1266\u001b[39m \u001b[38;5;28mself\u001b[39m.push(\u001b[43mfn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/variables/lazy.py:212\u001b[39m, in \u001b[36m_create_realize_and_forward.<locals>.realize_and_forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(\u001b[38;5;28mgetattr\u001b[39m(VariableTracker, name))\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrealize_and_forward\u001b[39m(\n\u001b[32m    210\u001b[39m     \u001b[38;5;28mself\u001b[39m: LazyVariableTracker, *args: Any, **kwargs: Any\n\u001b[32m    211\u001b[39m ) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrealize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/variables/nn_module.py:1010\u001b[39m, in \u001b[36mUnspecializedNNModuleVariable.call_function\u001b[39m\u001b[34m(self, tx, args, kwargs)\u001b[39m\n\u001b[32m   1002\u001b[39m ctx = (\n\u001b[32m   1003\u001b[39m     record_nn_module_stack(\n\u001b[32m   1004\u001b[39m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(mod)), \u001b[38;5;28mself\u001b[39m.get_nn_module_stack_source(), tx, mod\n\u001b[32m   (...)\u001b[39m\u001b[32m   1007\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m nullcontext()\n\u001b[32m   1008\u001b[39m )\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ctx:\n\u001b[32m-> \u001b[39m\u001b[32m1010\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvariables\u001b[49m\u001b[43m.\u001b[49m\u001b[43mUserFunctionVariable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/variables/functions.py:598\u001b[39m, in \u001b[36mUserFunctionVariable.call_function\u001b[39m\u001b[34m(self, tx, args, kwargs)\u001b[39m\n\u001b[32m    596\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m torch._dynamo.side_effects.allow_side_effects_under_checkpoint(tx):\n\u001b[32m    597\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().call_function(tx, args, kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m598\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/variables/functions.py:342\u001b[39m, in \u001b[36mBaseUserFunctionVariable.call_function\u001b[39m\u001b[34m(self, tx, args, kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_function\u001b[39m(\n\u001b[32m    337\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    338\u001b[39m     tx: \u001b[33m\"\u001b[39m\u001b[33mInstructionTranslator\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    339\u001b[39m     args: \u001b[33m\"\u001b[39m\u001b[33mlist[VariableTracker]\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    340\u001b[39m     kwargs: \u001b[33m\"\u001b[39m\u001b[33mdict[str, VariableTracker]\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    341\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mVariableTracker\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtx\u001b[49m\u001b[43m.\u001b[49m\u001b[43minline_user_function_return\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py:1288\u001b[39m, in \u001b[36mInstructionTranslatorBase.inline_user_function_return\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m   1286\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.inline_generator_function(fn, args, kwargs)\n\u001b[32m   1287\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1288\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mInliningInstructionTranslator\u001b[49m\u001b[43m.\u001b[49m\u001b[43minline_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py:4129\u001b[39m, in \u001b[36mInliningInstructionTranslator.inline_call\u001b[39m\u001b[34m(cls, parent, func, args, kwargs)\u001b[39m\n\u001b[32m   4127\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m patch.dict(counters, {\u001b[33m\"\u001b[39m\u001b[33munimplemented\u001b[39m\u001b[33m\"\u001b[39m: counters[\u001b[33m\"\u001b[39m\u001b[33minline_call\u001b[39m\u001b[33m\"\u001b[39m]}):\n\u001b[32m   4128\u001b[39m     tracer = \u001b[38;5;28mcls\u001b[39m.build_inline_tracer(parent, func, args, kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m4129\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracer\u001b[49m\u001b[43m.\u001b[49m\u001b[43minline_call_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py:4332\u001b[39m, in \u001b[36mInliningInstructionTranslator.inline_call_\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   4330\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   4331\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m strict_ctx:\n\u001b[32m-> \u001b[39m\u001b[32m4332\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4333\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.ObservedException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   4334\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mObserved exception DURING INLING \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py:1500\u001b[39m, in \u001b[36mInstructionTranslatorBase.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1498\u001b[39m \u001b[38;5;28mself\u001b[39m.start_point = \u001b[38;5;28mself\u001b[39m.instruction_pointer\n\u001b[32m   1499\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1500\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1501\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1502\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py:1348\u001b[39m, in \u001b[36mInstructionTranslatorBase.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1345\u001b[39m \u001b[38;5;28mself\u001b[39m.update_block_stack(inst)\n\u001b[32m   1347\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1348\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdispatch_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43minst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopcode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1349\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output.should_exit\n\u001b[32m   1350\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m TensorifyScalarRestartAnalysis:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py:904\u001b[39m, in \u001b[36mbreak_graph_if_unsupported.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_graph_break(\u001b[38;5;28mself\u001b[39m, inst, speculation.reason)\n\u001b[32m    903\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m904\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported \u001b[38;5;28;01mas\u001b[39;00m excp:\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.active_generic_context_managers:\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# We don't support graph break under GenericContextWrappingVariable,\u001b[39;00m\n\u001b[32m    908\u001b[39m         \u001b[38;5;66;03m# If there is, we roll back to the checkpoint and fall back.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py:3428\u001b[39m, in \u001b[36mInstructionTranslatorBase.CALL\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m   3426\u001b[39m \u001b[38;5;129m@break_graph_if_unsupported\u001b[39m(push=\u001b[32m1\u001b[39m)\n\u001b[32m   3427\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mCALL\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: Instruction) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3428\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py:3422\u001b[39m, in \u001b[36mInstructionTranslatorBase._call\u001b[39m\u001b[34m(self, inst, call_kw)\u001b[39m\n\u001b[32m   3417\u001b[39m     kwargs = {}\n\u001b[32m   3419\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   3420\u001b[39m     \u001b[38;5;66;03m# if call_function fails, need to set kw_names to None, otherwise\u001b[39;00m\n\u001b[32m   3421\u001b[39m     \u001b[38;5;66;03m# a subsequent call may have self.kw_names set to an old value\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3422\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3423\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   3424\u001b[39m     \u001b[38;5;28mself\u001b[39m.kw_names = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py:1266\u001b[39m, in \u001b[36mInstructionTranslatorBase.call_function\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m   1264\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inner_fn \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(inner_fn) \u001b[38;5;129;01mand\u001b[39;00m is_forbidden(inner_fn):\n\u001b[32m   1265\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAttempt to trace forbidden callable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_fn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1266\u001b[39m \u001b[38;5;28mself\u001b[39m.push(\u001b[43mfn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/variables/lazy.py:212\u001b[39m, in \u001b[36m_create_realize_and_forward.<locals>.realize_and_forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(\u001b[38;5;28mgetattr\u001b[39m(VariableTracker, name))\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrealize_and_forward\u001b[39m(\n\u001b[32m    210\u001b[39m     \u001b[38;5;28mself\u001b[39m: LazyVariableTracker, *args: Any, **kwargs: Any\n\u001b[32m    211\u001b[39m ) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrealize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/variables/torch.py:1516\u001b[39m, in \u001b[36mTorchInGraphFunctionVariable.call_function\u001b[39m\u001b[34m(self, tx, args, kwargs)\u001b[39m\n\u001b[32m   1513\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out_kwarg_vt, variables.TensorVariable):\n\u001b[32m   1514\u001b[39m         saved_out_shapes = out_kwarg_vt.proxy.node.meta[\u001b[33m\"\u001b[39m\u001b[33mexample_value\u001b[39m\u001b[33m\"\u001b[39m].shape\n\u001b[32m-> \u001b[39m\u001b[32m1516\u001b[39m tensor_variable = \u001b[43mwrap_fx_proxy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1517\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1518\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_proxy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1519\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcall_function\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1520\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfn_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1521\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43mproxy_args_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1523\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1525\u001b[39m \u001b[38;5;66;03m# Handle e.g., `torch.ones(10, requires_grad=True)`\u001b[39;00m\n\u001b[32m   1526\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1527\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(tensor_variable, TensorVariable)\n\u001b[32m   1528\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mrequires_grad\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs\n\u001b[32m   1529\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33mrequires_grad\u001b[39m\u001b[33m\"\u001b[39m].as_python_constant()\n\u001b[32m   1530\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/variables/builder.py:2645\u001b[39m, in \u001b[36mwrap_fx_proxy\u001b[39m\u001b[34m(tx, proxy, example_value, subclass_type, **options)\u001b[39m\n\u001b[32m   2637\u001b[39m kwargs = {\n\u001b[32m   2638\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtx\u001b[39m\u001b[33m\"\u001b[39m: tx,\n\u001b[32m   2639\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mproxy\u001b[39m\u001b[33m\"\u001b[39m: proxy,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2642\u001b[39m     **options,\n\u001b[32m   2643\u001b[39m }\n\u001b[32m   2644\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m subclass_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2645\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrap_fx_proxy_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTensorVariable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2646\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2647\u001b[39m     result = wrap_fx_proxy_cls(target_cls=TensorWithTFOverrideVariable, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/variables/builder.py:2711\u001b[39m, in \u001b[36mwrap_fx_proxy_cls\u001b[39m\u001b[34m(target_cls, tx, proxy, example_value, subclass_type, **options)\u001b[39m\n\u001b[32m   2707\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap_fx_proxy_cls\u001b[39m(\n\u001b[32m   2708\u001b[39m     target_cls, tx, proxy, example_value=\u001b[38;5;28;01mNone\u001b[39;00m, subclass_type=\u001b[38;5;28;01mNone\u001b[39;00m, **options\n\u001b[32m   2709\u001b[39m ):\n\u001b[32m   2710\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m example_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2711\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrap_fx_proxy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2712\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtarget_cls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubclass_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\n\u001b[32m   2713\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2714\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(example_value, torch.Tensor):\n\u001b[32m   2715\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _wrap_fx_preexisting_tensor(\n\u001b[32m   2716\u001b[39m             target_cls, tx, proxy, example_value, subclass_type, **options\n\u001b[32m   2717\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/variables/builder.py:2809\u001b[39m, in \u001b[36m_wrap_fx_proxy\u001b[39m\u001b[34m(target_cls, tx, proxy, example_value, subclass_type, **options)\u001b[39m\n\u001b[32m   2804\u001b[39m \u001b[38;5;66;03m# See NOTE: [Deferring tensor pack/unpack hooks until runtime]\u001b[39;00m\n\u001b[32m   2805\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch._dynamo.utils._disable_saved_tensors_hooks_during_tracing():\n\u001b[32m   2806\u001b[39m     \u001b[38;5;66;03m# with preserve_rng_state():\u001b[39;00m\n\u001b[32m   2807\u001b[39m     \u001b[38;5;66;03m# only allow_non_graph_fake in this instance because we handle the non-fake\u001b[39;00m\n\u001b[32m   2808\u001b[39m     \u001b[38;5;66;03m# cases properly below.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2809\u001b[39m     example_value = \u001b[43mget_fake_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproxy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_non_graph_fake\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   2811\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m handle_traced_output(\n\u001b[32m   2812\u001b[39m     example_value, tx, proxy, options, subclass_type, target_cls\n\u001b[32m   2813\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/utils.py:3478\u001b[39m, in \u001b[36mget_fake_value\u001b[39m\u001b[34m(node, tx, allow_non_graph_fake)\u001b[39m\n\u001b[32m   3470\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cause, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33margument\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(cause):\n\u001b[32m   3471\u001b[39m         unimplemented_v2(\n\u001b[32m   3472\u001b[39m             gb_type=\u001b[33m\"\u001b[39m\u001b[33mTypeError when making fake tensor call\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   3473\u001b[39m             context=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTypeError \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode.target\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcause\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   3474\u001b[39m             explanation=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   3475\u001b[39m             hints=[],\n\u001b[32m   3476\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m3478\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m TorchRuntimeError(\u001b[38;5;28mstr\u001b[39m(e)).with_traceback(e.__traceback__) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_non_graph_fake:\n\u001b[32m   3481\u001b[39m     _ = pytree.tree_map_only(\n\u001b[32m   3482\u001b[39m         torch.Tensor, functools.partial(ensure_graph_fake, tx=tx), ret_val\n\u001b[32m   3483\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/utils.py:3376\u001b[39m, in \u001b[36mget_fake_value\u001b[39m\u001b[34m(node, tx, allow_non_graph_fake)\u001b[39m\n\u001b[32m   3374\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   3375\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m fake_mode, enable_python_dispatcher():\n\u001b[32m-> \u001b[39m\u001b[32m3376\u001b[39m         ret_val = \u001b[43mwrap_fake_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3377\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnnmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3378\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3379\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported:\n\u001b[32m   3380\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/utils.py:2864\u001b[39m, in \u001b[36mwrap_fake_exception\u001b[39m\u001b[34m(fn)\u001b[39m\n\u001b[32m   2862\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap_fake_exception\u001b[39m(fn: Callable[[], Any]) -> Any:\n\u001b[32m   2863\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2864\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2865\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m UnsupportedFakeTensorException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2866\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m unimplemented_v2\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/utils.py:3377\u001b[39m, in \u001b[36mget_fake_value.<locals>.<lambda>\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   3374\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   3375\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m fake_mode, enable_python_dispatcher():\n\u001b[32m   3376\u001b[39m         ret_val = wrap_fake_exception(\n\u001b[32m-> \u001b[39m\u001b[32m3377\u001b[39m             \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mrun_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnnmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3378\u001b[39m         )\n\u001b[32m   3379\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported:\n\u001b[32m   3380\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/utils.py:3587\u001b[39m, in \u001b[36mrun_node\u001b[39m\u001b[34m(tracer, node, args, kwargs, nnmodule)\u001b[39m\n\u001b[32m   3585\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m   3586\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m3587\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(make_error_message(e)).with_traceback(\n\u001b[32m   3588\u001b[39m             e.__traceback__\n\u001b[32m   3589\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   3591\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(op)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_dynamo/utils.py:3546\u001b[39m, in \u001b[36mrun_node\u001b[39m\u001b[34m(tracer, node, args, kwargs, nnmodule)\u001b[39m\n\u001b[32m   3544\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   3545\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m op == \u001b[33m\"\u001b[39m\u001b[33mcall_function\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3546\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[32m   3547\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m op == \u001b[33m\"\u001b[39m\u001b[33mcall_method\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   3548\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(args[\u001b[32m0\u001b[39m], node.target):  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_prims_common/wrappers.py:307\u001b[39m, in \u001b[36mout_wrapper.<locals>._out_wrapper.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    304\u001b[39m     maybe_check_copy_devices(out)\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pass_is_out:\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_out\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    309\u001b[39m     result = fn(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_decomp/decompositions.py:4572\u001b[39m, in \u001b[36mmatmul\u001b[39m\u001b[34m(tensor1, tensor2, is_out)\u001b[39m\n\u001b[32m   4568\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m matmul(tensor1, tensor2.squeeze(\u001b[32m0\u001b[39m))\n\u001b[32m   4570\u001b[39m \u001b[38;5;66;03m# expand the batch portion (i.e. cut off matrix dimensions and expand rest)\u001b[39;00m\n\u001b[32m   4571\u001b[39m expand_batch_portion = \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m-> \u001b[39m\u001b[32m4572\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbroadcast_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_tensor1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_tensor2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4573\u001b[39m )\n\u001b[32m   4575\u001b[39m tensor1_expand_size = expand_batch_portion + [n, m1]\n\u001b[32m   4577\u001b[39m expand_batch_product = prod(expand_batch_portion)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/functional.py:108\u001b[39m, in \u001b[36mbroadcast_shapes\u001b[39m\u001b[34m(*shapes)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;66;03m# This wrapper exists to support variadic args.\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# TODO Move this to C++ once the jit has better support for torch.Size.\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.jit.is_tracing():\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     result = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_refs\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_broadcast_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mshapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    110\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m torch.Size([])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/_refs/__init__.py:436\u001b[39m, in \u001b[36m_broadcast_shapes\u001b[39m\u001b[34m(*_shapes)\u001b[39m\n\u001b[32m    433\u001b[39m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    434\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    435\u001b[39m             \u001b[38;5;66;03m# If broadcasting is undecided we pick non-broadcast path and add runtime assertion.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m436\u001b[39m             \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcommon_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAttempting to broadcast a dimension of length \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m at \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43midx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m! \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    439\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMismatching argument at index \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43marg_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m had \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mshape\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m; but expected shape \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    440\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshould be broadcastable to \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcommon_shape\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m common_shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/__init__.py:1695\u001b[39m, in \u001b[36m_check\u001b[39m\u001b[34m(cond, message)\u001b[39m\n\u001b[32m   1680\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_check\u001b[39m(cond, message=\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[32m   1681\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Throws error containing an optional message if the specified condition\u001b[39;00m\n\u001b[32m   1682\u001b[39m \u001b[33;03m    is False.\u001b[39;00m\n\u001b[32m   1683\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1693\u001b[39m \u001b[33;03m            message. Default: ``None``\u001b[39;00m\n\u001b[32m   1694\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1695\u001b[39m     \u001b[43m_check_with\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;167;43;01mRuntimeError\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/__init__.py:1677\u001b[39m, in \u001b[36m_check_with\u001b[39m\u001b[34m(error_type, cond, message)\u001b[39m\n\u001b[32m   1673\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mmessage must be a callable\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1675\u001b[39m     message_evaluated = \u001b[38;5;28mstr\u001b[39m(message())\n\u001b[32m-> \u001b[39m\u001b[32m1677\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m error_type(message_evaluated)\n",
      "\u001b[31mTorchRuntimeError\u001b[39m: Dynamo failed to run FX node with fake tensors: call_function <built-in method matmul of type object at 0x79360d9dcaa0>(*(FakeTensor(..., device='cuda:0', size=(1, 4, 9, 64)), FakeTensor(..., device='cuda:0', size=(1, 9, 4, 64))), **{}): got RuntimeError('Attempting to broadcast a dimension of length 9 at -1! Mismatching argument at index 1 had [1, 9]; but expected shape should be broadcastable to [1, 4]')\n\nfrom user code:\n   File \"/tmp/ipykernel_109531/47181234.py\", line 30, in forward\n    x = layer(x)\n  File \"/tmp/ipykernel_109531/2885984990.py\", line 27, in forward\n    attention_pattern = torch.matmul(q, torch.transpose(k, 1, 2)) / self.scaling_factor\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"
     ]
    }
   ],
   "source": [
    "# checkpoint = ModelCheckpoint.load(\"checkpoint.pt\")\n",
    "# model.load_state_dict(checkpoint.model_state)\n",
    "\n",
    "prompt = \"Tell me a story about a hungry man.\"\n",
    "\n",
    "response = generate_response(model, encoder=encoder, device=device, prompt=prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d82d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(encoder.encode(\"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
