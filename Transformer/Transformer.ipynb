{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "956cde40-5eaa-4466-a6be-0a4f10b22222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchvision.transforms import v2\n",
    "from datasets import load_dataset\n",
    "import tiktoken\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac2d5eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from https://pytorch-tutorials-preview.netlify.app/beginner/transformer_tutorial.html\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 d_model: int, \n",
    "                 dropout: float = 0.1, \n",
    "                 max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(1, max_len, d_model)\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[batch_size, seq_len, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0ae2853",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, \n",
    "                 d_model: int, \n",
    "                 d_query: int = 128, \n",
    "                 n_heads: int = 8,\n",
    "                 device: torch.device = torch.device(\"cpu\")):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_query)\n",
    "        self.W_k = nn.Linear(d_model, d_query)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        q = self.W_q(x)\n",
    "        k = self.W_k(x)\n",
    "        v = self.W_v(x)\n",
    "\n",
    "        attention_pattern = torch.matmul(q, torch.transpose(k, 1, 2))\n",
    "        \n",
    "        seq_len = attention_pattern.shape[-1]\n",
    "        mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool().to(self.device)\n",
    "        attention_pattern = torch.masked_fill(attention_pattern, mask, float(\"-inf\"))\n",
    "\n",
    "        attention_pattern = self.softmax(attention_pattern)\n",
    "\n",
    "        output = torch.matmul(attention_pattern, v)\n",
    "        \n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd25bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron(nn.Module):\n",
    "    def __init__(self, \n",
    "                 d_model: int, \n",
    "                 d_up: int = 256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.Linear(d_model, d_up)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.down = nn.Linear(d_up, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        output = self.up(x)\n",
    "        output = self.relu(output)\n",
    "        output = self.down(output)\n",
    "\n",
    "        output = output + x\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7cbf8aa-4165-4b6f-963d-f1bbb138d0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 n_vocab: int, \n",
    "                 d_model: int = 128, \n",
    "                 d_query: int = 128, \n",
    "                 n_heads: int = 8, \n",
    "                 n_layers: int = 4, \n",
    "                 d_up: int = 256,\n",
    "                 device: torch.device = torch.device(\"cpu\")):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(n_vocab, d_model)\n",
    "        self.pe = PositionalEncoding(d_model, max_len=50000)\n",
    "\n",
    "        self.self_attention = SelfAttention(d_model, d_query, n_heads, device)\n",
    "\n",
    "        self.mlp = MultilayerPerceptron(d_model, d_up)\n",
    "\n",
    "        self.unembedding = nn.Linear(d_model, n_vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.pe(x)\n",
    "\n",
    "        x = self.self_attention(x)\n",
    "\n",
    "        x = self.mlp(x)\n",
    "\n",
    "        x = self.unembedding(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec3c36a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, criterion, device, train_loader, accum_steps, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for idx, inputs in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = inputs[:,1:]\n",
    "        outputs = model(inputs)[:,:-1,:]\n",
    "\n",
    "        targets = targets.reshape(-1)\n",
    "        outputs = outputs.reshape(-1, outputs.shape[-1])\n",
    "        \n",
    "        loss = criterion(outputs, targets) / accum_steps\n",
    "        loss.backward()\n",
    "\n",
    "        if (idx + 1) % accum_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        if (idx + 1) % (accum_steps * 4) == 0:\n",
    "            print(f\"Epoch [{epoch}].[{idx}] Loss: {loss * accum_steps}\")\n",
    "\n",
    "        if (idx + 1) % (accum_steps * 16) == 0:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"TIME: {elapsed_time / (accum_steps * 16)} seconds per batch\")\n",
    "            start_time = time.time()\n",
    "\n",
    "            allocated = torch.cuda.memory_allocated() / 1e9\n",
    "            reserved = torch.cuda.memory_reserved() / 1e9\n",
    "            peak = torch.cuda.max_memory_allocated() / 1e9\n",
    "            print(f\"USAGE: Allocated {allocated:.2f}GB, Reserved {reserved:.2f}GB, Peak: {peak:.2f}GB\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81cedc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.set_float32_matmul_precision('high')\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86c0e410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 2141709\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train+validation\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca7d5ead-bd78-46a6-82cd-cdcec26fe137",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38761c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sequence):\n",
    "    sequence[\"text\"] = torch.tensor(encoder.encode(sequence[\"text\"]), dtype=torch.int64)\n",
    "    return sequence\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, num_proc=8).with_format(\"torch\")\n",
    "tokenized_dataset = tokenized_dataset.train_test_split(test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c17f5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tokenized_dataset[\"train\"][\"text\"]\n",
    "test = tokenized_dataset[\"test\"][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edf5859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 2\n",
    "accum_steps = 8\n",
    "d_model  = 128\n",
    "d_query  = 64\n",
    "d_up = 256\n",
    "n_heads  = 4\n",
    "n_layers = 4\n",
    "\n",
    "n_vocab  = encoder.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7887f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100277\n"
     ]
    }
   ],
   "source": [
    "print(n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29143c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_padding(batch):\n",
    "    batch = pad_sequence(batch, batch_first=True)\n",
    "    return batch\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "417bc5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(n_vocab=n_vocab, \n",
    "                    d_model=d_model, \n",
    "                    d_query=d_query, \n",
    "                    n_heads=n_heads, \n",
    "                    n_layers=n_layers, \n",
    "                    d_up=d_up, \n",
    "                    device=device).to(device)\n",
    "model = torch.compile(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9788985c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0117 14:20:55.099000 18924 torch/_inductor/utils.py:1613] [0/0] Not enough SMs to use max_autotune_gemm mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1].[31] Loss: 11.574928283691406\n",
      "Epoch [1].[63] Loss: 11.445477485656738\n",
      "Epoch [1].[95] Loss: 11.340519905090332\n",
      "Epoch [1].[127] Loss: 11.365422248840332\n",
      "TIME: 0.0678132139146328 seconds per batch\n",
      "USAGE: Allocated 0.48GB, Reserved 4.07GB, Peak: 2.57GB\n",
      "Epoch [1].[159] Loss: 11.288846969604492\n",
      "Epoch [1].[191] Loss: 11.1409912109375\n",
      "Epoch [1].[223] Loss: 10.636605262756348\n",
      "Epoch [1].[255] Loss: 10.760150909423828\n",
      "TIME: 0.017053373157978058 seconds per batch\n",
      "USAGE: Allocated 0.57GB, Reserved 4.00GB, Peak: 3.67GB\n",
      "Epoch [1].[287] Loss: 10.391779899597168\n",
      "Epoch [1].[319] Loss: 10.745203018188477\n",
      "Epoch [1].[351] Loss: 10.914483070373535\n",
      "Epoch [1].[383] Loss: 10.921076774597168\n",
      "TIME: 0.014722956344485283 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[415] Loss: 10.497237205505371\n",
      "Epoch [1].[447] Loss: 10.192230224609375\n",
      "Epoch [1].[479] Loss: 9.598983764648438\n",
      "Epoch [1].[511] Loss: 10.059351921081543\n",
      "TIME: 0.016624536365270615 seconds per batch\n",
      "USAGE: Allocated 0.49GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[543] Loss: 9.608104705810547\n",
      "Epoch [1].[575] Loss: 9.993766784667969\n",
      "Epoch [1].[607] Loss: 9.071187973022461\n",
      "Epoch [1].[639] Loss: 8.766876220703125\n",
      "TIME: 0.017623314633965492 seconds per batch\n",
      "USAGE: Allocated 0.49GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[671] Loss: 6.051055431365967\n",
      "Epoch [1].[703] Loss: 7.1695404052734375\n",
      "Epoch [1].[735] Loss: 7.401936054229736\n",
      "Epoch [1].[767] Loss: 6.30830192565918\n",
      "TIME: 0.014974396675825119 seconds per batch\n",
      "USAGE: Allocated 0.62GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[799] Loss: 6.6629958152771\n",
      "Epoch [1].[831] Loss: 6.234466552734375\n",
      "Epoch [1].[863] Loss: 6.7788262367248535\n",
      "Epoch [1].[895] Loss: 6.232843399047852\n",
      "TIME: 0.016508307307958603 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[927] Loss: 6.181678771972656\n",
      "Epoch [1].[959] Loss: 6.849793434143066\n",
      "Epoch [1].[991] Loss: 4.6422624588012695\n",
      "Epoch [1].[1023] Loss: 6.3988871574401855\n",
      "TIME: 0.016062526032328606 seconds per batch\n",
      "USAGE: Allocated 0.45GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[1055] Loss: 4.109000205993652\n",
      "Epoch [1].[1087] Loss: 5.581590175628662\n",
      "Epoch [1].[1119] Loss: 6.1858696937561035\n",
      "Epoch [1].[1151] Loss: 5.027027606964111\n",
      "TIME: 0.01552659459412098 seconds per batch\n",
      "USAGE: Allocated 0.65GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[1183] Loss: 5.60113525390625\n",
      "Epoch [1].[1215] Loss: 6.328508377075195\n",
      "Epoch [1].[1247] Loss: 5.945342540740967\n",
      "Epoch [1].[1279] Loss: 4.941056728363037\n",
      "TIME: 0.016544027253985405 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[1311] Loss: 6.147216320037842\n",
      "Epoch [1].[1343] Loss: 5.144340991973877\n",
      "Epoch [1].[1375] Loss: 4.858367443084717\n",
      "Epoch [1].[1407] Loss: 4.61747932434082\n",
      "TIME: 0.01609412580728531 seconds per batch\n",
      "USAGE: Allocated 0.61GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[1439] Loss: 5.583843231201172\n",
      "Epoch [1].[1471] Loss: 5.17045259475708\n",
      "Epoch [1].[1503] Loss: 5.39055061340332\n",
      "Epoch [1].[1535] Loss: 5.094180107116699\n",
      "TIME: 0.01521981693804264 seconds per batch\n",
      "USAGE: Allocated 0.47GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[1567] Loss: 5.224143981933594\n",
      "Epoch [1].[1599] Loss: 6.105587959289551\n",
      "Epoch [1].[1631] Loss: 5.395409107208252\n",
      "Epoch [1].[1663] Loss: 4.480562686920166\n",
      "TIME: 0.015466028824448586 seconds per batch\n",
      "USAGE: Allocated 0.56GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[1695] Loss: 4.765410900115967\n",
      "Epoch [1].[1727] Loss: 5.124418258666992\n",
      "Epoch [1].[1759] Loss: 5.6149983406066895\n",
      "Epoch [1].[1791] Loss: 6.266062259674072\n",
      "TIME: 0.01597793772816658 seconds per batch\n",
      "USAGE: Allocated 0.48GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[1823] Loss: 5.2897233963012695\n",
      "Epoch [1].[1855] Loss: 5.137136936187744\n",
      "Epoch [1].[1887] Loss: 5.852182865142822\n",
      "Epoch [1].[1919] Loss: 4.767878532409668\n",
      "TIME: 0.014833381399512291 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[1951] Loss: 5.022188663482666\n",
      "Epoch [1].[1983] Loss: 5.379500389099121\n",
      "Epoch [1].[2015] Loss: 5.881525039672852\n",
      "Epoch [1].[2047] Loss: 5.767456531524658\n",
      "TIME: 0.01663573645055294 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[2079] Loss: 5.633689880371094\n",
      "Epoch [1].[2111] Loss: 4.6705732345581055\n",
      "Epoch [1].[2143] Loss: 5.477733612060547\n",
      "Epoch [1].[2175] Loss: 5.963668346405029\n",
      "TIME: 0.016708053648471832 seconds per batch\n",
      "USAGE: Allocated 0.48GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[2207] Loss: 4.913413047790527\n",
      "Epoch [1].[2239] Loss: 4.784682273864746\n",
      "Epoch [1].[2271] Loss: 5.803204536437988\n",
      "Epoch [1].[2303] Loss: 5.1940178871154785\n",
      "TIME: 0.014524934813380241 seconds per batch\n",
      "USAGE: Allocated 0.76GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[2335] Loss: 5.453892230987549\n",
      "Epoch [1].[2367] Loss: 5.201775550842285\n",
      "Epoch [1].[2399] Loss: 5.1044721603393555\n",
      "Epoch [1].[2431] Loss: 4.417840003967285\n",
      "TIME: 0.016883082687854767 seconds per batch\n",
      "USAGE: Allocated 0.69GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[2463] Loss: 6.007861137390137\n",
      "Epoch [1].[2495] Loss: 5.305931568145752\n",
      "Epoch [1].[2527] Loss: 4.811901092529297\n",
      "Epoch [1].[2559] Loss: 5.398149013519287\n",
      "TIME: 0.01698089949786663 seconds per batch\n",
      "USAGE: Allocated 0.49GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[2591] Loss: 5.440099716186523\n",
      "Epoch [1].[2623] Loss: 5.103207111358643\n",
      "Epoch [1].[2655] Loss: 5.9414381980896\n",
      "Epoch [1].[2687] Loss: 4.208955764770508\n",
      "TIME: 0.015676474198698997 seconds per batch\n",
      "USAGE: Allocated 0.82GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[2719] Loss: 5.1420698165893555\n",
      "Epoch [1].[2751] Loss: 5.745720386505127\n",
      "Epoch [1].[2783] Loss: 6.117104530334473\n",
      "Epoch [1].[2815] Loss: 5.2769775390625\n",
      "TIME: 0.016555603593587875 seconds per batch\n",
      "USAGE: Allocated 0.61GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[2847] Loss: 5.211410045623779\n",
      "Epoch [1].[2879] Loss: 4.954926013946533\n",
      "Epoch [1].[2911] Loss: 4.680373668670654\n",
      "Epoch [1].[2943] Loss: 4.898260116577148\n",
      "TIME: 0.01572548784315586 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[2975] Loss: 5.3901047706604\n",
      "Epoch [1].[3007] Loss: 5.496212482452393\n",
      "Epoch [1].[3039] Loss: 5.555154323577881\n",
      "Epoch [1].[3071] Loss: 5.547577381134033\n",
      "TIME: 0.014797985553741455 seconds per batch\n",
      "USAGE: Allocated 0.68GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[3103] Loss: 5.329748153686523\n",
      "Epoch [1].[3135] Loss: 4.925924301147461\n",
      "Epoch [1].[3167] Loss: 5.054441928863525\n",
      "Epoch [1].[3199] Loss: 4.315089225769043\n",
      "TIME: 0.01608109287917614 seconds per batch\n",
      "USAGE: Allocated 0.72GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[3231] Loss: 5.615795135498047\n",
      "Epoch [1].[3263] Loss: 5.311988830566406\n",
      "Epoch [1].[3295] Loss: 5.315027713775635\n",
      "Epoch [1].[3327] Loss: 4.286348819732666\n",
      "TIME: 0.016246866434812546 seconds per batch\n",
      "USAGE: Allocated 0.63GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[3359] Loss: 5.938436985015869\n",
      "Epoch [1].[3391] Loss: 4.039003372192383\n",
      "Epoch [1].[3423] Loss: 5.522648811340332\n",
      "Epoch [1].[3455] Loss: 5.241006851196289\n",
      "TIME: 0.015844566747546196 seconds per batch\n",
      "USAGE: Allocated 0.55GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[3487] Loss: 5.851762294769287\n",
      "Epoch [1].[3519] Loss: 4.7936272621154785\n",
      "Epoch [1].[3551] Loss: 5.192734241485596\n",
      "Epoch [1].[3583] Loss: 4.447303295135498\n",
      "TIME: 0.013649241998791695 seconds per batch\n",
      "USAGE: Allocated 0.60GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[3615] Loss: 5.034119606018066\n",
      "Epoch [1].[3647] Loss: 4.279288291931152\n",
      "Epoch [1].[3679] Loss: 5.867144584655762\n",
      "Epoch [1].[3711] Loss: 5.877134323120117\n",
      "TIME: 0.015847327187657356 seconds per batch\n",
      "USAGE: Allocated 0.48GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[3743] Loss: 5.229828834533691\n",
      "Epoch [1].[3775] Loss: 5.289564609527588\n",
      "Epoch [1].[3807] Loss: 5.374820709228516\n",
      "Epoch [1].[3839] Loss: 5.703975677490234\n",
      "TIME: 0.015855979174375534 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[3871] Loss: 4.769211769104004\n",
      "Epoch [1].[3903] Loss: 5.779242992401123\n",
      "Epoch [1].[3935] Loss: 4.274871349334717\n",
      "Epoch [1].[3967] Loss: 5.527920246124268\n",
      "TIME: 0.014517588540911674 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[3999] Loss: 5.464345455169678\n",
      "Epoch [1].[4031] Loss: 5.6335015296936035\n",
      "Epoch [1].[4063] Loss: 5.501098155975342\n",
      "Epoch [1].[4095] Loss: 5.627523422241211\n",
      "TIME: 0.016267864033579826 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[4127] Loss: 3.648486614227295\n",
      "Epoch [1].[4159] Loss: 5.911393642425537\n",
      "Epoch [1].[4191] Loss: 5.754931926727295\n",
      "Epoch [1].[4223] Loss: 4.867335796356201\n",
      "TIME: 0.017113758251070976 seconds per batch\n",
      "USAGE: Allocated 0.55GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[4255] Loss: 5.326983451843262\n",
      "Epoch [1].[4287] Loss: 3.864764928817749\n",
      "Epoch [1].[4319] Loss: 4.538307189941406\n",
      "Epoch [1].[4351] Loss: 4.581534385681152\n",
      "TIME: 0.015576578676700592 seconds per batch\n",
      "USAGE: Allocated 0.59GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[4383] Loss: 4.629382610321045\n",
      "Epoch [1].[4415] Loss: 3.8017842769622803\n",
      "Epoch [1].[4447] Loss: 5.2984795570373535\n",
      "Epoch [1].[4479] Loss: 4.749711036682129\n",
      "TIME: 0.01628180406987667 seconds per batch\n",
      "USAGE: Allocated 0.66GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[4511] Loss: 6.105461120605469\n",
      "Epoch [1].[4543] Loss: 5.075610637664795\n",
      "Epoch [1].[4575] Loss: 5.306765556335449\n",
      "Epoch [1].[4607] Loss: 4.437169551849365\n",
      "TIME: 0.01580003648996353 seconds per batch\n",
      "USAGE: Allocated 0.56GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[4639] Loss: 5.173060894012451\n",
      "Epoch [1].[4671] Loss: 3.956490993499756\n",
      "Epoch [1].[4703] Loss: 5.400872230529785\n",
      "Epoch [1].[4735] Loss: 4.557823181152344\n",
      "TIME: 0.014489663764834404 seconds per batch\n",
      "USAGE: Allocated 0.62GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[4767] Loss: 6.193769931793213\n",
      "Epoch [1].[4799] Loss: 5.121111869812012\n",
      "Epoch [1].[4831] Loss: 5.060258388519287\n",
      "Epoch [1].[4863] Loss: 4.4355058670043945\n",
      "TIME: 0.01693117991089821 seconds per batch\n",
      "USAGE: Allocated 0.67GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[4895] Loss: 5.5245041847229\n",
      "Epoch [1].[4927] Loss: 4.977206707000732\n",
      "Epoch [1].[4959] Loss: 5.634549140930176\n",
      "Epoch [1].[4991] Loss: 5.874054431915283\n",
      "TIME: 0.015914708375930786 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[5023] Loss: 4.063153266906738\n",
      "Epoch [1].[5055] Loss: 5.014965057373047\n",
      "Epoch [1].[5087] Loss: 4.363880634307861\n",
      "Epoch [1].[5119] Loss: 5.464635372161865\n",
      "TIME: 0.01777704991400242 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[5151] Loss: 5.25047492980957\n",
      "Epoch [1].[5183] Loss: 5.880068778991699\n",
      "Epoch [1].[5215] Loss: 4.639678955078125\n",
      "Epoch [1].[5247] Loss: 4.710963249206543\n",
      "TIME: 0.016254015266895294 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[5279] Loss: 5.419134616851807\n",
      "Epoch [1].[5311] Loss: 5.837045669555664\n",
      "Epoch [1].[5343] Loss: 4.244798183441162\n",
      "Epoch [1].[5375] Loss: 4.219057083129883\n",
      "TIME: 0.014765717089176178 seconds per batch\n",
      "USAGE: Allocated 0.48GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[5407] Loss: 6.123437881469727\n",
      "Epoch [1].[5439] Loss: 5.562073230743408\n",
      "Epoch [1].[5471] Loss: 5.785677433013916\n",
      "Epoch [1].[5503] Loss: 4.272911071777344\n",
      "TIME: 0.01684573106467724 seconds per batch\n",
      "USAGE: Allocated 0.63GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[5535] Loss: 4.329127788543701\n",
      "Epoch [1].[5567] Loss: 5.058122158050537\n",
      "Epoch [1].[5599] Loss: 5.3643293380737305\n",
      "Epoch [1].[5631] Loss: 4.5076141357421875\n",
      "TIME: 0.01593303307890892 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[5663] Loss: 5.02700662612915\n",
      "Epoch [1].[5695] Loss: 4.17147159576416\n",
      "Epoch [1].[5727] Loss: 4.940922737121582\n",
      "Epoch [1].[5759] Loss: 5.345235824584961\n",
      "TIME: 0.013857446610927582 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[5791] Loss: 5.551158428192139\n",
      "Epoch [1].[5823] Loss: 5.1662821769714355\n",
      "Epoch [1].[5855] Loss: 5.904053211212158\n",
      "Epoch [1].[5887] Loss: 4.978384971618652\n",
      "TIME: 0.017065392807126045 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[5919] Loss: 5.333449363708496\n",
      "Epoch [1].[5951] Loss: 5.187375545501709\n",
      "Epoch [1].[5983] Loss: 4.973117828369141\n",
      "Epoch [1].[6015] Loss: 4.3619256019592285\n",
      "TIME: 0.017061574384570122 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[6047] Loss: 4.846249103546143\n",
      "Epoch [1].[6079] Loss: 5.575002193450928\n",
      "Epoch [1].[6111] Loss: 4.613831520080566\n",
      "Epoch [1].[6143] Loss: 4.201147079467773\n",
      "TIME: 0.014853760600090027 seconds per batch\n",
      "USAGE: Allocated 0.65GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[6175] Loss: 4.927089691162109\n",
      "Epoch [1].[6207] Loss: 4.393727779388428\n",
      "Epoch [1].[6239] Loss: 4.8225531578063965\n",
      "Epoch [1].[6271] Loss: 4.899301528930664\n",
      "TIME: 0.017332887277007103 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[6303] Loss: 4.3837080001831055\n",
      "Epoch [1].[6335] Loss: 5.374312400817871\n",
      "Epoch [1].[6367] Loss: 5.141350746154785\n",
      "Epoch [1].[6399] Loss: 5.531069755554199\n",
      "TIME: 0.016357576474547386 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[6431] Loss: 5.766019821166992\n",
      "Epoch [1].[6463] Loss: 5.140726089477539\n",
      "Epoch [1].[6495] Loss: 5.149789333343506\n",
      "Epoch [1].[6527] Loss: 4.195174217224121\n",
      "TIME: 0.013329990208148956 seconds per batch\n",
      "USAGE: Allocated 0.56GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[6559] Loss: 5.274423599243164\n",
      "Epoch [1].[6591] Loss: 5.588222980499268\n",
      "Epoch [1].[6623] Loss: 5.490942478179932\n",
      "Epoch [1].[6655] Loss: 5.305605888366699\n",
      "TIME: 0.015520332381129265 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[6687] Loss: 5.538256645202637\n",
      "Epoch [1].[6719] Loss: 5.212148189544678\n",
      "Epoch [1].[6751] Loss: 5.330414295196533\n",
      "Epoch [1].[6783] Loss: 5.4623613357543945\n",
      "TIME: 0.015620805323123932 seconds per batch\n",
      "USAGE: Allocated 0.47GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[6815] Loss: 4.376155376434326\n",
      "Epoch [1].[6847] Loss: 5.240428924560547\n",
      "Epoch [1].[6879] Loss: 5.198134899139404\n",
      "Epoch [1].[6911] Loss: 5.33240270614624\n",
      "TIME: 0.014717353507876396 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[6943] Loss: 4.5955376625061035\n",
      "Epoch [1].[6975] Loss: 3.8849375247955322\n",
      "Epoch [1].[7007] Loss: 5.349542140960693\n",
      "Epoch [1].[7039] Loss: 4.190536022186279\n",
      "TIME: 0.018501730635762215 seconds per batch\n",
      "USAGE: Allocated 0.70GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[7071] Loss: 5.143585205078125\n",
      "Epoch [1].[7103] Loss: 3.595099449157715\n",
      "Epoch [1].[7135] Loss: 4.080682277679443\n",
      "Epoch [1].[7167] Loss: 4.485249996185303\n",
      "TIME: 0.0165207851678133 seconds per batch\n",
      "USAGE: Allocated 0.56GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[7199] Loss: 5.191275596618652\n",
      "Epoch [1].[7231] Loss: 4.76686429977417\n",
      "Epoch [1].[7263] Loss: 4.575957775115967\n",
      "Epoch [1].[7295] Loss: 5.416865348815918\n",
      "TIME: 0.014047099277377129 seconds per batch\n",
      "USAGE: Allocated 0.56GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[7327] Loss: 5.167445182800293\n",
      "Epoch [1].[7359] Loss: 4.332834720611572\n",
      "Epoch [1].[7391] Loss: 6.2886762619018555\n",
      "Epoch [1].[7423] Loss: 4.9940385818481445\n",
      "TIME: 0.016047358512878418 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[7455] Loss: 4.472123622894287\n",
      "Epoch [1].[7487] Loss: 4.987748622894287\n",
      "Epoch [1].[7519] Loss: 5.79831075668335\n",
      "Epoch [1].[7551] Loss: 4.362579345703125\n",
      "TIME: 0.01623043790459633 seconds per batch\n",
      "USAGE: Allocated 0.58GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[7583] Loss: 4.291979789733887\n",
      "Epoch [1].[7615] Loss: 4.169736385345459\n",
      "Epoch [1].[7647] Loss: 3.6658382415771484\n",
      "Epoch [1].[7679] Loss: 4.679349422454834\n",
      "TIME: 0.014509031549096107 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[7711] Loss: 4.65500020980835\n",
      "Epoch [1].[7743] Loss: 5.185471057891846\n",
      "Epoch [1].[7775] Loss: 4.278353214263916\n",
      "Epoch [1].[7807] Loss: 5.384143352508545\n",
      "TIME: 0.016503097489476204 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[7839] Loss: 5.630602836608887\n",
      "Epoch [1].[7871] Loss: 5.383354663848877\n",
      "Epoch [1].[7903] Loss: 5.692185878753662\n",
      "Epoch [1].[7935] Loss: 5.289887428283691\n",
      "TIME: 0.016417784616351128 seconds per batch\n",
      "USAGE: Allocated 0.55GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[7967] Loss: 4.125174045562744\n",
      "Epoch [1].[7999] Loss: 4.329737663269043\n",
      "Epoch [1].[8031] Loss: 5.76513671875\n",
      "Epoch [1].[8063] Loss: 5.712263107299805\n",
      "TIME: 0.015319658443331718 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[8095] Loss: 4.131898403167725\n",
      "Epoch [1].[8127] Loss: 4.68307638168335\n",
      "Epoch [1].[8159] Loss: 4.9272541999816895\n",
      "Epoch [1].[8191] Loss: 4.701462745666504\n",
      "TIME: 0.016640570014715195 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[8223] Loss: 4.92397928237915\n",
      "Epoch [1].[8255] Loss: 5.229837894439697\n",
      "Epoch [1].[8287] Loss: 5.082712173461914\n",
      "Epoch [1].[8319] Loss: 5.736493110656738\n",
      "TIME: 0.01622261106967926 seconds per batch\n",
      "USAGE: Allocated 0.54GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[8351] Loss: 3.893260955810547\n",
      "Epoch [1].[8383] Loss: 3.8673877716064453\n",
      "Epoch [1].[8415] Loss: 4.675532341003418\n",
      "Epoch [1].[8447] Loss: 3.7938733100891113\n",
      "TIME: 0.013626046478748322 seconds per batch\n",
      "USAGE: Allocated 0.68GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[8479] Loss: 5.209159851074219\n",
      "Epoch [1].[8511] Loss: 4.7042717933654785\n",
      "Epoch [1].[8543] Loss: 5.502105236053467\n",
      "Epoch [1].[8575] Loss: 4.9506049156188965\n",
      "TIME: 0.016757246106863022 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[8607] Loss: 4.241768836975098\n",
      "Epoch [1].[8639] Loss: 5.469478130340576\n",
      "Epoch [1].[8671] Loss: 5.084072589874268\n",
      "Epoch [1].[8703] Loss: 4.491837978363037\n",
      "TIME: 0.016667665913701057 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[8735] Loss: 3.890538215637207\n",
      "Epoch [1].[8767] Loss: 4.732900142669678\n",
      "Epoch [1].[8799] Loss: 5.092459678649902\n",
      "Epoch [1].[8831] Loss: 5.162121772766113\n",
      "TIME: 0.013840602710843086 seconds per batch\n",
      "USAGE: Allocated 0.49GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[8863] Loss: 4.564429759979248\n",
      "Epoch [1].[8895] Loss: 4.326043128967285\n",
      "Epoch [1].[8927] Loss: 5.235106468200684\n",
      "Epoch [1].[8959] Loss: 5.221898555755615\n",
      "TIME: 0.01648947224020958 seconds per batch\n",
      "USAGE: Allocated 0.54GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[8991] Loss: 5.110567569732666\n",
      "Epoch [1].[9023] Loss: 4.0717902183532715\n",
      "Epoch [1].[9055] Loss: 3.9676005840301514\n",
      "Epoch [1].[9087] Loss: 5.3002448081970215\n",
      "TIME: 0.016226088628172874 seconds per batch\n",
      "USAGE: Allocated 0.60GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[9119] Loss: 4.241262912750244\n",
      "Epoch [1].[9151] Loss: 4.413147926330566\n",
      "Epoch [1].[9183] Loss: 4.828796863555908\n",
      "Epoch [1].[9215] Loss: 5.428796291351318\n",
      "TIME: 0.01686524972319603 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[9247] Loss: 3.953394889831543\n",
      "Epoch [1].[9279] Loss: 5.299539566040039\n",
      "Epoch [1].[9311] Loss: 4.4734907150268555\n",
      "Epoch [1].[9343] Loss: 4.201409816741943\n",
      "TIME: 0.01655062660574913 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[9375] Loss: 3.7468345165252686\n",
      "Epoch [1].[9407] Loss: 5.374639511108398\n",
      "Epoch [1].[9439] Loss: 4.870062351226807\n",
      "Epoch [1].[9471] Loss: 4.549109935760498\n",
      "TIME: 0.014548145234584808 seconds per batch\n",
      "USAGE: Allocated 0.48GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[9503] Loss: 5.524323463439941\n",
      "Epoch [1].[9535] Loss: 5.201497554779053\n",
      "Epoch [1].[9567] Loss: 4.868073463439941\n",
      "Epoch [1].[9599] Loss: 4.881184101104736\n",
      "TIME: 0.016086632385849953 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[9631] Loss: 5.187253952026367\n",
      "Epoch [1].[9663] Loss: 4.8908281326293945\n",
      "Epoch [1].[9695] Loss: 4.432069778442383\n",
      "Epoch [1].[9727] Loss: 5.1514811515808105\n",
      "TIME: 0.016794439405202866 seconds per batch\n",
      "USAGE: Allocated 0.49GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[9759] Loss: 4.366711616516113\n",
      "Epoch [1].[9791] Loss: 4.6507086753845215\n",
      "Epoch [1].[9823] Loss: 5.466030120849609\n",
      "Epoch [1].[9855] Loss: 3.7152557373046875\n",
      "TIME: 0.01451478898525238 seconds per batch\n",
      "USAGE: Allocated 0.70GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[9887] Loss: 4.672221660614014\n",
      "Epoch [1].[9919] Loss: 5.132509231567383\n",
      "Epoch [1].[9951] Loss: 5.029722690582275\n",
      "Epoch [1].[9983] Loss: 4.675641059875488\n",
      "TIME: 0.015850646421313286 seconds per batch\n",
      "USAGE: Allocated 0.54GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[10015] Loss: 4.1644463539123535\n",
      "Epoch [1].[10047] Loss: 4.403273105621338\n",
      "Epoch [1].[10079] Loss: 5.455226898193359\n",
      "Epoch [1].[10111] Loss: 4.658990383148193\n",
      "TIME: 0.01636740379035473 seconds per batch\n",
      "USAGE: Allocated 0.49GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[10143] Loss: 3.3900563716888428\n",
      "Epoch [1].[10175] Loss: 4.771017074584961\n",
      "Epoch [1].[10207] Loss: 5.770995616912842\n",
      "Epoch [1].[10239] Loss: 4.307467460632324\n",
      "TIME: 0.014551440253853798 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[10271] Loss: 5.655414581298828\n",
      "Epoch [1].[10303] Loss: 4.106611728668213\n",
      "Epoch [1].[10335] Loss: 4.6983962059021\n",
      "Epoch [1].[10367] Loss: 4.469620227813721\n",
      "TIME: 0.015661126002669334 seconds per batch\n",
      "USAGE: Allocated 0.54GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[10399] Loss: 5.809725761413574\n",
      "Epoch [1].[10431] Loss: 5.201910972595215\n",
      "Epoch [1].[10463] Loss: 4.8726277351379395\n",
      "Epoch [1].[10495] Loss: 5.75856876373291\n",
      "TIME: 0.015400402247905731 seconds per batch\n",
      "USAGE: Allocated 0.58GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[10527] Loss: 4.913281440734863\n",
      "Epoch [1].[10559] Loss: 4.37924337387085\n",
      "Epoch [1].[10591] Loss: 5.77457857131958\n",
      "Epoch [1].[10623] Loss: 4.4937744140625\n",
      "TIME: 0.014150045812129974 seconds per batch\n",
      "USAGE: Allocated 0.62GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[10655] Loss: 4.653764724731445\n",
      "Epoch [1].[10687] Loss: 5.356255054473877\n",
      "Epoch [1].[10719] Loss: 4.841299533843994\n",
      "Epoch [1].[10751] Loss: 5.127674579620361\n",
      "TIME: 0.015814946964383125 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[10783] Loss: 5.200991630554199\n",
      "Epoch [1].[10815] Loss: 4.749703884124756\n",
      "Epoch [1].[10847] Loss: 5.427026271820068\n",
      "Epoch [1].[10879] Loss: 5.399594306945801\n",
      "TIME: 0.016694433987140656 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[10911] Loss: 4.773680210113525\n",
      "Epoch [1].[10943] Loss: 5.321022033691406\n",
      "Epoch [1].[10975] Loss: 5.001342296600342\n",
      "Epoch [1].[11007] Loss: 5.402348518371582\n",
      "TIME: 0.01381695456802845 seconds per batch\n",
      "USAGE: Allocated 0.47GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[11039] Loss: 4.185835838317871\n",
      "Epoch [1].[11071] Loss: 5.494664669036865\n",
      "Epoch [1].[11103] Loss: 5.093496799468994\n",
      "Epoch [1].[11135] Loss: 4.76891565322876\n",
      "TIME: 0.016176771372556686 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[11167] Loss: 5.168517589569092\n",
      "Epoch [1].[11199] Loss: 5.344720363616943\n",
      "Epoch [1].[11231] Loss: 4.702243804931641\n",
      "Epoch [1].[11263] Loss: 5.034793376922607\n",
      "TIME: 0.015794197097420692 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[11295] Loss: 3.9195914268493652\n",
      "Epoch [1].[11327] Loss: 3.848109006881714\n",
      "Epoch [1].[11359] Loss: 4.300942420959473\n",
      "Epoch [1].[11391] Loss: 4.978147029876709\n",
      "TIME: 0.014593599364161491 seconds per batch\n",
      "USAGE: Allocated 0.55GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[11423] Loss: 4.985371112823486\n",
      "Epoch [1].[11455] Loss: 5.448235988616943\n",
      "Epoch [1].[11487] Loss: 3.2116036415100098\n",
      "Epoch [1].[11519] Loss: 5.592628479003906\n",
      "TIME: 0.016637906432151794 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[11551] Loss: 5.339369297027588\n",
      "Epoch [1].[11583] Loss: 3.246079683303833\n",
      "Epoch [1].[11615] Loss: 4.633996963500977\n",
      "Epoch [1].[11647] Loss: 5.420813083648682\n",
      "TIME: 0.01633879728615284 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[11679] Loss: 4.519717693328857\n",
      "Epoch [1].[11711] Loss: 4.774688243865967\n",
      "Epoch [1].[11743] Loss: 3.819146156311035\n",
      "Epoch [1].[11775] Loss: 4.486241817474365\n",
      "TIME: 0.014333266764879227 seconds per batch\n",
      "USAGE: Allocated 0.49GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[11807] Loss: 4.349416732788086\n",
      "Epoch [1].[11839] Loss: 4.9567484855651855\n",
      "Epoch [1].[11871] Loss: 4.606396675109863\n",
      "Epoch [1].[11903] Loss: 3.9554696083068848\n",
      "TIME: 0.016416529193520546 seconds per batch\n",
      "USAGE: Allocated 0.73GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[11935] Loss: 5.6389265060424805\n",
      "Epoch [1].[11967] Loss: 4.5282883644104\n",
      "Epoch [1].[11999] Loss: 5.191682815551758\n",
      "Epoch [1].[12031] Loss: 5.630862236022949\n",
      "TIME: 0.015616083517670631 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[12063] Loss: 5.093331336975098\n",
      "Epoch [1].[12095] Loss: 3.8611369132995605\n",
      "Epoch [1].[12127] Loss: 5.095759868621826\n",
      "Epoch [1].[12159] Loss: 3.420640230178833\n",
      "TIME: 0.013604288920760155 seconds per batch\n",
      "USAGE: Allocated 0.70GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[12191] Loss: 4.469349384307861\n",
      "Epoch [1].[12223] Loss: 3.585628032684326\n",
      "Epoch [1].[12255] Loss: 4.975103378295898\n",
      "Epoch [1].[12287] Loss: 4.673994064331055\n",
      "TIME: 0.016478465870022774 seconds per batch\n",
      "USAGE: Allocated 0.81GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[12319] Loss: 5.313221454620361\n",
      "Epoch [1].[12351] Loss: 5.538294792175293\n",
      "Epoch [1].[12383] Loss: 5.4268693923950195\n",
      "Epoch [1].[12415] Loss: 4.5064826011657715\n",
      "TIME: 0.01600486785173416 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[12447] Loss: 5.022647857666016\n",
      "Epoch [1].[12479] Loss: 4.918098449707031\n",
      "Epoch [1].[12511] Loss: 4.076225280761719\n",
      "Epoch [1].[12543] Loss: 4.802697658538818\n",
      "TIME: 0.013048890978097916 seconds per batch\n",
      "USAGE: Allocated 0.61GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[12575] Loss: 5.025144577026367\n",
      "Epoch [1].[12607] Loss: 4.786869049072266\n",
      "Epoch [1].[12639] Loss: 5.08939266204834\n",
      "Epoch [1].[12671] Loss: 3.8411312103271484\n",
      "TIME: 0.01603536866605282 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[12703] Loss: 4.605947971343994\n",
      "Epoch [1].[12735] Loss: 4.419378280639648\n",
      "Epoch [1].[12767] Loss: 4.92836332321167\n",
      "Epoch [1].[12799] Loss: 3.961895704269409\n",
      "TIME: 0.015991732478141785 seconds per batch\n",
      "USAGE: Allocated 0.57GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[12831] Loss: 4.762698173522949\n",
      "Epoch [1].[12863] Loss: 4.680675029754639\n",
      "Epoch [1].[12895] Loss: 5.819301128387451\n",
      "Epoch [1].[12927] Loss: 5.242409706115723\n",
      "TIME: 0.014167426154017448 seconds per batch\n",
      "USAGE: Allocated 0.55GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[12959] Loss: 5.264646530151367\n",
      "Epoch [1].[12991] Loss: 4.559143543243408\n",
      "Epoch [1].[13023] Loss: 4.8677449226379395\n",
      "Epoch [1].[13055] Loss: 4.728008270263672\n",
      "TIME: 0.016217876225709915 seconds per batch\n",
      "USAGE: Allocated 0.63GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[13087] Loss: 4.735153675079346\n",
      "Epoch [1].[13119] Loss: 5.032062530517578\n",
      "Epoch [1].[13151] Loss: 3.794168472290039\n",
      "Epoch [1].[13183] Loss: 4.789261817932129\n",
      "TIME: 0.016740091145038605 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[13215] Loss: 5.394033908843994\n",
      "Epoch [1].[13247] Loss: 4.8891425132751465\n",
      "Epoch [1].[13279] Loss: 4.208314418792725\n",
      "Epoch [1].[13311] Loss: 3.5271646976470947\n",
      "TIME: 0.016443215310573578 seconds per batch\n",
      "USAGE: Allocated 0.67GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[13343] Loss: 5.097792148590088\n",
      "Epoch [1].[13375] Loss: 4.545340538024902\n",
      "Epoch [1].[13407] Loss: 4.833350658416748\n",
      "Epoch [1].[13439] Loss: 4.018792152404785\n",
      "TIME: 0.016156721860170364 seconds per batch\n",
      "USAGE: Allocated 0.58GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[13471] Loss: 5.237938404083252\n",
      "Epoch [1].[13503] Loss: 5.127068996429443\n",
      "Epoch [1].[13535] Loss: 5.01978874206543\n",
      "Epoch [1].[13567] Loss: 4.873288154602051\n",
      "TIME: 0.014116289094090462 seconds per batch\n",
      "USAGE: Allocated 0.57GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[13599] Loss: 5.327460765838623\n",
      "Epoch [1].[13631] Loss: 4.741062641143799\n",
      "Epoch [1].[13663] Loss: 5.399107456207275\n",
      "Epoch [1].[13695] Loss: 3.9241411685943604\n",
      "TIME: 0.016609834507107735 seconds per batch\n",
      "USAGE: Allocated 0.69GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[13727] Loss: 4.719242572784424\n",
      "Epoch [1].[13759] Loss: 4.365238189697266\n",
      "Epoch [1].[13791] Loss: 3.8787784576416016\n",
      "Epoch [1].[13823] Loss: 4.251632213592529\n",
      "TIME: 0.015733174979686737 seconds per batch\n",
      "USAGE: Allocated 0.59GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[13855] Loss: 4.940506458282471\n",
      "Epoch [1].[13887] Loss: 4.870461463928223\n",
      "Epoch [1].[13919] Loss: 3.768603801727295\n",
      "Epoch [1].[13951] Loss: 3.1438522338867188\n",
      "TIME: 0.01413426548242569 seconds per batch\n",
      "USAGE: Allocated 0.90GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[13983] Loss: 4.868199348449707\n",
      "Epoch [1].[14015] Loss: 5.269445419311523\n",
      "Epoch [1].[14047] Loss: 4.664546489715576\n",
      "Epoch [1].[14079] Loss: 4.859744071960449\n",
      "TIME: 0.015837617218494415 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[14111] Loss: 4.921712875366211\n",
      "Epoch [1].[14143] Loss: 5.521417617797852\n",
      "Epoch [1].[14175] Loss: 4.704605579376221\n",
      "Epoch [1].[14207] Loss: 5.532767295837402\n",
      "TIME: 0.015704888850450516 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[14239] Loss: 4.425204753875732\n",
      "Epoch [1].[14271] Loss: 4.732461929321289\n",
      "Epoch [1].[14303] Loss: 4.87019157409668\n",
      "Epoch [1].[14335] Loss: 4.4826436042785645\n",
      "TIME: 0.013229366391897202 seconds per batch\n",
      "USAGE: Allocated 0.55GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[14367] Loss: 4.963852405548096\n",
      "Epoch [1].[14399] Loss: 4.721277236938477\n",
      "Epoch [1].[14431] Loss: 3.7630484104156494\n",
      "Epoch [1].[14463] Loss: 4.509969711303711\n",
      "TIME: 0.015669289976358414 seconds per batch\n",
      "USAGE: Allocated 0.49GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[14495] Loss: 4.565946102142334\n",
      "Epoch [1].[14527] Loss: 5.104228973388672\n",
      "Epoch [1].[14559] Loss: 4.307947635650635\n",
      "Epoch [1].[14591] Loss: 4.1547017097473145\n",
      "TIME: 0.01630210690200329 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[14623] Loss: 4.942490100860596\n",
      "Epoch [1].[14655] Loss: 4.628465175628662\n",
      "Epoch [1].[14687] Loss: 4.466164588928223\n",
      "Epoch [1].[14719] Loss: 3.81619930267334\n",
      "TIME: 0.01515958458185196 seconds per batch\n",
      "USAGE: Allocated 0.80GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[14751] Loss: 4.9928693771362305\n",
      "Epoch [1].[14783] Loss: 4.5477294921875\n",
      "Epoch [1].[14815] Loss: 4.585514068603516\n",
      "Epoch [1].[14847] Loss: 5.528450965881348\n",
      "TIME: 0.016024885699152946 seconds per batch\n",
      "USAGE: Allocated 0.56GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[14879] Loss: 5.093589782714844\n",
      "Epoch [1].[14911] Loss: 4.972274303436279\n",
      "Epoch [1].[14943] Loss: 4.779057025909424\n",
      "Epoch [1].[14975] Loss: 3.620806932449341\n",
      "TIME: 0.015796402469277382 seconds per batch\n",
      "USAGE: Allocated 0.68GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[15007] Loss: 5.0755767822265625\n",
      "Epoch [1].[15039] Loss: 4.684741020202637\n",
      "Epoch [1].[15071] Loss: 4.618860721588135\n",
      "Epoch [1].[15103] Loss: 5.284122467041016\n",
      "TIME: 0.013314355164766312 seconds per batch\n",
      "USAGE: Allocated 0.58GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[15135] Loss: 5.300509929656982\n",
      "Epoch [1].[15167] Loss: 3.703437089920044\n",
      "Epoch [1].[15199] Loss: 3.6714210510253906\n",
      "Epoch [1].[15231] Loss: 3.43161940574646\n",
      "TIME: 0.01707485131919384 seconds per batch\n",
      "USAGE: Allocated 0.91GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[15263] Loss: 4.405456066131592\n",
      "Epoch [1].[15295] Loss: 4.339696884155273\n",
      "Epoch [1].[15327] Loss: 5.190157890319824\n",
      "Epoch [1].[15359] Loss: 5.6148834228515625\n",
      "TIME: 0.01589251309633255 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[15391] Loss: 3.982196569442749\n",
      "Epoch [1].[15423] Loss: 4.8223419189453125\n",
      "Epoch [1].[15455] Loss: 4.965182781219482\n",
      "Epoch [1].[15487] Loss: 4.283024787902832\n",
      "TIME: 0.014365285634994507 seconds per batch\n",
      "USAGE: Allocated 0.65GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[15519] Loss: 4.381812572479248\n",
      "Epoch [1].[15551] Loss: 4.647005558013916\n",
      "Epoch [1].[15583] Loss: 4.049280643463135\n",
      "Epoch [1].[15615] Loss: 4.691513538360596\n",
      "TIME: 0.01702168770134449 seconds per batch\n",
      "USAGE: Allocated 0.58GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[15647] Loss: 4.636883735656738\n",
      "Epoch [1].[15679] Loss: 5.6835737228393555\n",
      "Epoch [1].[15711] Loss: 3.9743127822875977\n",
      "Epoch [1].[15743] Loss: 3.97160267829895\n",
      "TIME: 0.0159417986869812 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[15775] Loss: 4.772709369659424\n",
      "Epoch [1].[15807] Loss: 4.6391801834106445\n",
      "Epoch [1].[15839] Loss: 4.65907096862793\n",
      "Epoch [1].[15871] Loss: 3.8838706016540527\n",
      "TIME: 0.013723894953727722 seconds per batch\n",
      "USAGE: Allocated 0.55GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[15903] Loss: 5.568844318389893\n",
      "Epoch [1].[15935] Loss: 5.2697272300720215\n",
      "Epoch [1].[15967] Loss: 4.146308422088623\n",
      "Epoch [1].[15999] Loss: 4.913268089294434\n",
      "TIME: 0.016084793955087662 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[16031] Loss: 5.514558792114258\n",
      "Epoch [1].[16063] Loss: 5.134544372558594\n",
      "Epoch [1].[16095] Loss: 5.579402446746826\n",
      "Epoch [1].[16127] Loss: 5.330869674682617\n",
      "TIME: 0.015713220462203026 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[16159] Loss: 5.597534656524658\n",
      "Epoch [1].[16191] Loss: 4.0823259353637695\n",
      "Epoch [1].[16223] Loss: 4.083039283752441\n",
      "Epoch [1].[16255] Loss: 4.59780216217041\n",
      "TIME: 0.014774776995182037 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[16287] Loss: 3.9423651695251465\n",
      "Epoch [1].[16319] Loss: 4.3378705978393555\n",
      "Epoch [1].[16351] Loss: 4.442866802215576\n",
      "Epoch [1].[16383] Loss: 5.983042240142822\n",
      "TIME: 0.017214810475707054 seconds per batch\n",
      "USAGE: Allocated 0.48GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[16415] Loss: 4.250348091125488\n",
      "Epoch [1].[16447] Loss: 5.673903942108154\n",
      "Epoch [1].[16479] Loss: 4.898677825927734\n",
      "Epoch [1].[16511] Loss: 4.146174907684326\n",
      "TIME: 0.016871973872184753 seconds per batch\n",
      "USAGE: Allocated 0.54GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[16543] Loss: 5.291878700256348\n",
      "Epoch [1].[16575] Loss: 4.383870601654053\n",
      "Epoch [1].[16607] Loss: 4.823473930358887\n",
      "Epoch [1].[16639] Loss: 5.110156059265137\n",
      "TIME: 0.013456476852297783 seconds per batch\n",
      "USAGE: Allocated 0.61GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[16671] Loss: 4.490848541259766\n",
      "Epoch [1].[16703] Loss: 4.19585657119751\n",
      "Epoch [1].[16735] Loss: 4.646422386169434\n",
      "Epoch [1].[16767] Loss: 4.622385501861572\n",
      "TIME: 0.016829894855618477 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[16799] Loss: 5.280876159667969\n",
      "Epoch [1].[16831] Loss: 3.2480595111846924\n",
      "Epoch [1].[16863] Loss: 4.252512454986572\n",
      "Epoch [1].[16895] Loss: 5.196812152862549\n",
      "TIME: 0.016815075650811195 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[16927] Loss: 4.182506561279297\n",
      "Epoch [1].[16959] Loss: 4.533936500549316\n",
      "Epoch [1].[16991] Loss: 4.780013084411621\n",
      "Epoch [1].[17023] Loss: 4.902366638183594\n",
      "TIME: 0.013880886137485504 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[17055] Loss: 4.057309150695801\n",
      "Epoch [1].[17087] Loss: 4.652918338775635\n",
      "Epoch [1].[17119] Loss: 4.730710983276367\n",
      "Epoch [1].[17151] Loss: 5.573126316070557\n",
      "TIME: 0.01781415194272995 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[17183] Loss: 3.626826524734497\n",
      "Epoch [1].[17215] Loss: 4.916435241699219\n",
      "Epoch [1].[17247] Loss: 5.5569748878479\n",
      "Epoch [1].[17279] Loss: 4.886091232299805\n",
      "TIME: 0.016191929578781128 seconds per batch\n",
      "USAGE: Allocated 0.58GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[17311] Loss: 4.886923313140869\n",
      "Epoch [1].[17343] Loss: 3.860146999359131\n",
      "Epoch [1].[17375] Loss: 5.163968086242676\n",
      "Epoch [1].[17407] Loss: 4.181522846221924\n",
      "TIME: 0.016734950244426727 seconds per batch\n",
      "USAGE: Allocated 0.49GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[17439] Loss: 5.468778133392334\n",
      "Epoch [1].[17471] Loss: 4.899003028869629\n",
      "Epoch [1].[17503] Loss: 3.431641101837158\n",
      "Epoch [1].[17535] Loss: 4.8394951820373535\n",
      "TIME: 0.016317693516612053 seconds per batch\n",
      "USAGE: Allocated 0.54GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[17567] Loss: 4.803943634033203\n",
      "Epoch [1].[17599] Loss: 4.298335075378418\n",
      "Epoch [1].[17631] Loss: 3.8042678833007812\n",
      "Epoch [1].[17663] Loss: 4.718862533569336\n",
      "TIME: 0.014294154942035675 seconds per batch\n",
      "USAGE: Allocated 0.45GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[17695] Loss: 4.552624702453613\n",
      "Epoch [1].[17727] Loss: 5.165670394897461\n",
      "Epoch [1].[17759] Loss: 4.170161247253418\n",
      "Epoch [1].[17791] Loss: 4.7905073165893555\n",
      "TIME: 0.016394104808568954 seconds per batch\n",
      "USAGE: Allocated 0.48GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[17823] Loss: 4.413179874420166\n",
      "Epoch [1].[17855] Loss: 4.059695243835449\n",
      "Epoch [1].[17887] Loss: 4.1651611328125\n",
      "Epoch [1].[17919] Loss: 4.221580982208252\n",
      "TIME: 0.01647079363465309 seconds per batch\n",
      "USAGE: Allocated 0.66GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[17951] Loss: 3.594142436981201\n",
      "Epoch [1].[17983] Loss: 3.782320499420166\n",
      "Epoch [1].[18015] Loss: 4.91274356842041\n",
      "Epoch [1].[18047] Loss: 3.743387222290039\n",
      "TIME: 0.015332290902733803 seconds per batch\n",
      "USAGE: Allocated 0.64GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[18079] Loss: 4.943896293640137\n",
      "Epoch [1].[18111] Loss: 3.6692235469818115\n",
      "Epoch [1].[18143] Loss: 3.56152606010437\n",
      "Epoch [1].[18175] Loss: 4.620649337768555\n",
      "TIME: 0.016656655818223953 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[18207] Loss: 3.9125025272369385\n",
      "Epoch [1].[18239] Loss: 3.552976369857788\n",
      "Epoch [1].[18271] Loss: 5.386998176574707\n",
      "Epoch [1].[18303] Loss: 4.856111526489258\n",
      "TIME: 0.015809440985322 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[18335] Loss: 5.002305507659912\n",
      "Epoch [1].[18367] Loss: 3.5296621322631836\n",
      "Epoch [1].[18399] Loss: 4.393078804016113\n",
      "Epoch [1].[18431] Loss: 4.192127227783203\n",
      "TIME: 0.013550082221627235 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[18463] Loss: 4.617568492889404\n",
      "Epoch [1].[18495] Loss: 4.691102504730225\n",
      "Epoch [1].[18527] Loss: 4.699596405029297\n",
      "Epoch [1].[18559] Loss: 3.9679338932037354\n",
      "TIME: 0.015233509242534637 seconds per batch\n",
      "USAGE: Allocated 0.62GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[18591] Loss: 4.631350517272949\n",
      "Epoch [1].[18623] Loss: 3.5809993743896484\n",
      "Epoch [1].[18655] Loss: 4.174407482147217\n",
      "Epoch [1].[18687] Loss: 4.083065986633301\n",
      "TIME: 0.016469506546854973 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[18719] Loss: 4.838150501251221\n",
      "Epoch [1].[18751] Loss: 3.8741354942321777\n",
      "Epoch [1].[18783] Loss: 5.498514175415039\n",
      "Epoch [1].[18815] Loss: 5.072269916534424\n",
      "TIME: 0.013302041217684746 seconds per batch\n",
      "USAGE: Allocated 0.64GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[18847] Loss: 3.457369565963745\n",
      "Epoch [1].[18879] Loss: 4.821166515350342\n",
      "Epoch [1].[18911] Loss: 4.764225482940674\n",
      "Epoch [1].[18943] Loss: 4.594626426696777\n",
      "TIME: 0.015871461480855942 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[18975] Loss: 4.477660655975342\n",
      "Epoch [1].[19007] Loss: 4.903691291809082\n",
      "Epoch [1].[19039] Loss: 5.393920421600342\n",
      "Epoch [1].[19071] Loss: 4.944458961486816\n",
      "TIME: 0.016477687284350395 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[19103] Loss: 5.312995910644531\n",
      "Epoch [1].[19135] Loss: 3.2045040130615234\n",
      "Epoch [1].[19167] Loss: 3.5825793743133545\n",
      "Epoch [1].[19199] Loss: 5.384227752685547\n",
      "TIME: 0.013503070920705795 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[19231] Loss: 4.798032283782959\n",
      "Epoch [1].[19263] Loss: 4.384435653686523\n",
      "Epoch [1].[19295] Loss: 5.396664142608643\n",
      "Epoch [1].[19327] Loss: 4.940199851989746\n",
      "TIME: 0.01580791175365448 seconds per batch\n",
      "USAGE: Allocated 0.55GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[19359] Loss: 4.581692695617676\n",
      "Epoch [1].[19391] Loss: 5.285022735595703\n",
      "Epoch [1].[19423] Loss: 3.9996094703674316\n",
      "Epoch [1].[19455] Loss: 3.7446677684783936\n",
      "TIME: 0.01691397652029991 seconds per batch\n",
      "USAGE: Allocated 0.87GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[19487] Loss: 4.311060905456543\n",
      "Epoch [1].[19519] Loss: 4.497727870941162\n",
      "Epoch [1].[19551] Loss: 4.455300807952881\n",
      "Epoch [1].[19583] Loss: 4.376530170440674\n",
      "TIME: 0.014371765777468681 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[19615] Loss: 4.800150394439697\n",
      "Epoch [1].[19647] Loss: 5.538940906524658\n",
      "Epoch [1].[19679] Loss: 3.558439016342163\n",
      "Epoch [1].[19711] Loss: 4.731491565704346\n",
      "TIME: 0.016089480370283127 seconds per batch\n",
      "USAGE: Allocated 0.60GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[19743] Loss: 3.7030584812164307\n",
      "Epoch [1].[19775] Loss: 5.435759544372559\n",
      "Epoch [1].[19807] Loss: 4.640716075897217\n",
      "Epoch [1].[19839] Loss: 4.6445770263671875\n",
      "TIME: 0.015625642612576485 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[19871] Loss: 4.549931049346924\n",
      "Epoch [1].[19903] Loss: 5.270675182342529\n",
      "Epoch [1].[19935] Loss: 3.5000815391540527\n",
      "Epoch [1].[19967] Loss: 5.016513824462891\n",
      "TIME: 0.013955440372228622 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[19999] Loss: 5.2502031326293945\n",
      "Epoch [1].[20031] Loss: 4.800587177276611\n",
      "Epoch [1].[20063] Loss: 5.149653434753418\n",
      "Epoch [1].[20095] Loss: 5.005812168121338\n",
      "TIME: 0.015296323224902153 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[20127] Loss: 4.342776298522949\n",
      "Epoch [1].[20159] Loss: 4.854686260223389\n",
      "Epoch [1].[20191] Loss: 5.684208393096924\n",
      "Epoch [1].[20223] Loss: 3.60796856880188\n",
      "TIME: 0.016304753720760345 seconds per batch\n",
      "USAGE: Allocated 0.89GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[20255] Loss: 3.2256975173950195\n",
      "Epoch [1].[20287] Loss: 3.744652032852173\n",
      "Epoch [1].[20319] Loss: 4.962125301361084\n",
      "Epoch [1].[20351] Loss: 4.36513614654541\n",
      "TIME: 0.01368250697851181 seconds per batch\n",
      "USAGE: Allocated 0.80GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[20383] Loss: 4.505145072937012\n",
      "Epoch [1].[20415] Loss: 4.933774948120117\n",
      "Epoch [1].[20447] Loss: 4.075839996337891\n",
      "Epoch [1].[20479] Loss: 4.485544681549072\n",
      "TIME: 0.015793871134519577 seconds per batch\n",
      "USAGE: Allocated 0.47GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[20511] Loss: 5.200784206390381\n",
      "Epoch [1].[20543] Loss: 4.787051200866699\n",
      "Epoch [1].[20575] Loss: 4.688975811004639\n",
      "Epoch [1].[20607] Loss: 4.933564186096191\n",
      "TIME: 0.017080195248126984 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[20639] Loss: 4.589732646942139\n",
      "Epoch [1].[20671] Loss: 5.073996067047119\n",
      "Epoch [1].[20703] Loss: 3.8136820793151855\n",
      "Epoch [1].[20735] Loss: 3.788572311401367\n",
      "TIME: 0.013881608843803406 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[20767] Loss: 5.045577049255371\n",
      "Epoch [1].[20799] Loss: 4.961020469665527\n",
      "Epoch [1].[20831] Loss: 4.179934024810791\n",
      "Epoch [1].[20863] Loss: 5.498935222625732\n",
      "TIME: 0.01597185619175434 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[20895] Loss: 4.194412708282471\n",
      "Epoch [1].[20927] Loss: 5.109823703765869\n",
      "Epoch [1].[20959] Loss: 3.991347551345825\n",
      "Epoch [1].[20991] Loss: 3.8436176776885986\n",
      "TIME: 0.015482775866985321 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[21023] Loss: 4.752673149108887\n",
      "Epoch [1].[21055] Loss: 3.8236019611358643\n",
      "Epoch [1].[21087] Loss: 3.380005121231079\n",
      "Epoch [1].[21119] Loss: 4.754482746124268\n",
      "TIME: 0.014009999111294746 seconds per batch\n",
      "USAGE: Allocated 0.47GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[21151] Loss: 3.3173227310180664\n",
      "Epoch [1].[21183] Loss: 3.4435200691223145\n",
      "Epoch [1].[21215] Loss: 4.1555047035217285\n",
      "Epoch [1].[21247] Loss: 4.960305690765381\n",
      "TIME: 0.015878766775131226 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[21279] Loss: 5.1820759773254395\n",
      "Epoch [1].[21311] Loss: 3.4119772911071777\n",
      "Epoch [1].[21343] Loss: 4.3319196701049805\n",
      "Epoch [1].[21375] Loss: 3.723102569580078\n",
      "TIME: 0.015886522829532623 seconds per batch\n",
      "USAGE: Allocated 0.59GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[21407] Loss: 4.25657844543457\n",
      "Epoch [1].[21439] Loss: 5.004978656768799\n",
      "Epoch [1].[21471] Loss: 5.058117389678955\n",
      "Epoch [1].[21503] Loss: 4.119612216949463\n",
      "TIME: 0.015618238598108292 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[21535] Loss: 4.830891132354736\n",
      "Epoch [1].[21567] Loss: 5.080766201019287\n",
      "Epoch [1].[21599] Loss: 5.083446979522705\n",
      "Epoch [1].[21631] Loss: 4.196672439575195\n",
      "TIME: 0.015545174479484558 seconds per batch\n",
      "USAGE: Allocated 0.55GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[21663] Loss: 3.3916802406311035\n",
      "Epoch [1].[21695] Loss: 4.381969928741455\n",
      "Epoch [1].[21727] Loss: 4.336541175842285\n",
      "Epoch [1].[21759] Loss: 4.885165691375732\n",
      "TIME: 0.014618344604969025 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[21791] Loss: 4.5962443351745605\n",
      "Epoch [1].[21823] Loss: 5.4890241622924805\n",
      "Epoch [1].[21855] Loss: 4.777439594268799\n",
      "Epoch [1].[21887] Loss: 4.129076957702637\n",
      "TIME: 0.015778562054038048 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[21919] Loss: 3.5452723503112793\n",
      "Epoch [1].[21951] Loss: 3.578354835510254\n",
      "Epoch [1].[21983] Loss: 4.107293605804443\n",
      "Epoch [1].[22015] Loss: 4.090080738067627\n",
      "TIME: 0.015501718968153 seconds per batch\n",
      "USAGE: Allocated 0.48GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[22047] Loss: 4.30283784866333\n",
      "Epoch [1].[22079] Loss: 4.004558086395264\n",
      "Epoch [1].[22111] Loss: 4.707269668579102\n",
      "Epoch [1].[22143] Loss: 4.838473796844482\n",
      "TIME: 0.013635622337460518 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[22175] Loss: 3.6515231132507324\n",
      "Epoch [1].[22207] Loss: 4.205896854400635\n",
      "Epoch [1].[22239] Loss: 3.624326467514038\n",
      "Epoch [1].[22271] Loss: 3.4638235569000244\n",
      "TIME: 0.016333244740962982 seconds per batch\n",
      "USAGE: Allocated 0.82GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[22303] Loss: 4.932658672332764\n",
      "Epoch [1].[22335] Loss: 4.407684326171875\n",
      "Epoch [1].[22367] Loss: 3.7930290699005127\n",
      "Epoch [1].[22399] Loss: 4.394491672515869\n",
      "TIME: 0.016441011801362038 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[22431] Loss: 5.749265193939209\n",
      "Epoch [1].[22463] Loss: 4.155354976654053\n",
      "Epoch [1].[22495] Loss: 4.873292922973633\n",
      "Epoch [1].[22527] Loss: 4.984410762786865\n",
      "TIME: 0.013965461403131485 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[22559] Loss: 3.5834484100341797\n",
      "Epoch [1].[22591] Loss: 3.551969051361084\n",
      "Epoch [1].[22623] Loss: 5.093550682067871\n",
      "Epoch [1].[22655] Loss: 4.346875190734863\n",
      "TIME: 0.01586947590112686 seconds per batch\n",
      "USAGE: Allocated 0.59GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[22687] Loss: 4.0267229080200195\n",
      "Epoch [1].[22719] Loss: 3.4333090782165527\n",
      "Epoch [1].[22751] Loss: 5.165101528167725\n",
      "Epoch [1].[22783] Loss: 4.07102108001709\n",
      "TIME: 0.01763150468468666 seconds per batch\n",
      "USAGE: Allocated 0.66GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[22815] Loss: 4.404348373413086\n",
      "Epoch [1].[22847] Loss: 4.037508964538574\n",
      "Epoch [1].[22879] Loss: 3.7291438579559326\n",
      "Epoch [1].[22911] Loss: 5.075906276702881\n",
      "TIME: 0.014280842617154121 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[22943] Loss: 5.554429054260254\n",
      "Epoch [1].[22975] Loss: 4.582613945007324\n",
      "Epoch [1].[23007] Loss: 4.991955280303955\n",
      "Epoch [1].[23039] Loss: 3.834818124771118\n",
      "TIME: 0.015449535101652145 seconds per batch\n",
      "USAGE: Allocated 0.46GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[23071] Loss: 4.6222124099731445\n",
      "Epoch [1].[23103] Loss: 5.222288608551025\n",
      "Epoch [1].[23135] Loss: 4.037414073944092\n",
      "Epoch [1].[23167] Loss: 4.435023784637451\n",
      "TIME: 0.015257537364959717 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[23199] Loss: 4.684135437011719\n",
      "Epoch [1].[23231] Loss: 4.262957572937012\n",
      "Epoch [1].[23263] Loss: 5.233355522155762\n",
      "Epoch [1].[23295] Loss: 5.310909748077393\n",
      "TIME: 0.014110090211033821 seconds per batch\n",
      "USAGE: Allocated 0.54GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[23327] Loss: 4.904000282287598\n",
      "Epoch [1].[23359] Loss: 4.973056316375732\n",
      "Epoch [1].[23391] Loss: 4.747212886810303\n",
      "Epoch [1].[23423] Loss: 4.490588665008545\n",
      "TIME: 0.01690070331096649 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[23455] Loss: 4.188568115234375\n",
      "Epoch [1].[23487] Loss: 4.3340959548950195\n",
      "Epoch [1].[23519] Loss: 3.8574116230010986\n",
      "Epoch [1].[23551] Loss: 4.57847785949707\n",
      "TIME: 0.01653204672038555 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[23583] Loss: 4.847833633422852\n",
      "Epoch [1].[23615] Loss: 5.277459144592285\n",
      "Epoch [1].[23647] Loss: 4.983731746673584\n",
      "Epoch [1].[23679] Loss: 4.73573637008667\n",
      "TIME: 0.01404196210205555 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[23711] Loss: 5.1725921630859375\n",
      "Epoch [1].[23743] Loss: 4.29811954498291\n",
      "Epoch [1].[23775] Loss: 3.52921724319458\n",
      "Epoch [1].[23807] Loss: 4.440295696258545\n",
      "TIME: 0.01602233201265335 seconds per batch\n",
      "USAGE: Allocated 0.58GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[23839] Loss: 4.80270528793335\n",
      "Epoch [1].[23871] Loss: 3.697422504425049\n",
      "Epoch [1].[23903] Loss: 5.520693778991699\n",
      "Epoch [1].[23935] Loss: 4.6258344650268555\n",
      "TIME: 0.015859419479966164 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[23967] Loss: 4.239260196685791\n",
      "Epoch [1].[23999] Loss: 3.336169481277466\n",
      "Epoch [1].[24031] Loss: 4.650562286376953\n",
      "Epoch [1].[24063] Loss: 5.0479416847229\n",
      "TIME: 0.013833587989211082 seconds per batch\n",
      "USAGE: Allocated 0.57GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[24095] Loss: 3.1429314613342285\n",
      "Epoch [1].[24127] Loss: 3.275698661804199\n",
      "Epoch [1].[24159] Loss: 3.817455530166626\n",
      "Epoch [1].[24191] Loss: 4.879669666290283\n",
      "TIME: 0.01592395082116127 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[24223] Loss: 4.16366720199585\n",
      "Epoch [1].[24255] Loss: 3.223742723464966\n",
      "Epoch [1].[24287] Loss: 4.526994705200195\n",
      "Epoch [1].[24319] Loss: 4.622548580169678\n",
      "TIME: 0.016461757943034172 seconds per batch\n",
      "USAGE: Allocated 0.48GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[24351] Loss: 3.5328314304351807\n",
      "Epoch [1].[24383] Loss: 5.059872627258301\n",
      "Epoch [1].[24415] Loss: 4.468602657318115\n",
      "Epoch [1].[24447] Loss: 5.096883773803711\n",
      "TIME: 0.014524407684803009 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[24479] Loss: 4.326243877410889\n",
      "Epoch [1].[24511] Loss: 3.6443989276885986\n",
      "Epoch [1].[24543] Loss: 5.279776573181152\n",
      "Epoch [1].[24575] Loss: 4.514442443847656\n",
      "TIME: 0.015844376757740974 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[24607] Loss: 2.841623306274414\n",
      "Epoch [1].[24639] Loss: 4.782474994659424\n",
      "Epoch [1].[24671] Loss: 4.868791580200195\n",
      "Epoch [1].[24703] Loss: 4.278689384460449\n",
      "TIME: 0.015583744272589684 seconds per batch\n",
      "USAGE: Allocated 0.64GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[24735] Loss: 3.471989154815674\n",
      "Epoch [1].[24767] Loss: 3.34238862991333\n",
      "Epoch [1].[24799] Loss: 4.2303876876831055\n",
      "Epoch [1].[24831] Loss: 4.256478309631348\n",
      "TIME: 0.01458744890987873 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[24863] Loss: 4.859930515289307\n",
      "Epoch [1].[24895] Loss: 4.430478096008301\n",
      "Epoch [1].[24927] Loss: 4.4561238288879395\n",
      "Epoch [1].[24959] Loss: 4.477550983428955\n",
      "TIME: 0.016052711755037308 seconds per batch\n",
      "USAGE: Allocated 0.78GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[24991] Loss: 3.999315023422241\n",
      "Epoch [1].[25023] Loss: 4.836169719696045\n",
      "Epoch [1].[25055] Loss: 4.096007347106934\n",
      "Epoch [1].[25087] Loss: 4.98159122467041\n",
      "TIME: 0.015824178233742714 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[25119] Loss: 5.197707653045654\n",
      "Epoch [1].[25151] Loss: 4.992763519287109\n",
      "Epoch [1].[25183] Loss: 3.41837477684021\n",
      "Epoch [1].[25215] Loss: 4.819460391998291\n",
      "TIME: 0.014104090631008148 seconds per batch\n",
      "USAGE: Allocated 0.55GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[25247] Loss: 4.9891743659973145\n",
      "Epoch [1].[25279] Loss: 4.322656631469727\n",
      "Epoch [1].[25311] Loss: 4.775271892547607\n",
      "Epoch [1].[25343] Loss: 3.5797317028045654\n",
      "TIME: 0.016716880723834038 seconds per batch\n",
      "USAGE: Allocated 0.72GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[25375] Loss: 5.135371208190918\n",
      "Epoch [1].[25407] Loss: 3.3435781002044678\n",
      "Epoch [1].[25439] Loss: 4.565440654754639\n",
      "Epoch [1].[25471] Loss: 3.891087770462036\n",
      "TIME: 0.015626488253474236 seconds per batch\n",
      "USAGE: Allocated 0.83GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[25503] Loss: 3.5688889026641846\n",
      "Epoch [1].[25535] Loss: 4.236481189727783\n",
      "Epoch [1].[25567] Loss: 5.071403980255127\n",
      "Epoch [1].[25599] Loss: 4.660383224487305\n",
      "TIME: 0.015587979927659035 seconds per batch\n",
      "USAGE: Allocated 0.47GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[25631] Loss: 4.562491416931152\n",
      "Epoch [1].[25663] Loss: 3.591885805130005\n",
      "Epoch [1].[25695] Loss: 3.9737744331359863\n",
      "Epoch [1].[25727] Loss: 4.687387943267822\n",
      "TIME: 0.01615496352314949 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[25759] Loss: 3.4747207164764404\n",
      "Epoch [1].[25791] Loss: 4.392124176025391\n",
      "Epoch [1].[25823] Loss: 3.457611083984375\n",
      "Epoch [1].[25855] Loss: 4.379712104797363\n",
      "TIME: 0.014139752835035324 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[25887] Loss: 4.637578964233398\n",
      "Epoch [1].[25919] Loss: 4.923834800720215\n",
      "Epoch [1].[25951] Loss: 4.039909839630127\n",
      "Epoch [1].[25983] Loss: 3.584958791732788\n",
      "TIME: 0.01620243489742279 seconds per batch\n",
      "USAGE: Allocated 0.67GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[26015] Loss: 4.3636250495910645\n",
      "Epoch [1].[26047] Loss: 5.114958763122559\n",
      "Epoch [1].[26079] Loss: 4.511236190795898\n",
      "Epoch [1].[26111] Loss: 4.766613483428955\n",
      "TIME: 0.015948422253131866 seconds per batch\n",
      "USAGE: Allocated 0.60GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[26143] Loss: 4.75945520401001\n",
      "Epoch [1].[26175] Loss: 5.174662113189697\n",
      "Epoch [1].[26207] Loss: 3.4736061096191406\n",
      "Epoch [1].[26239] Loss: 4.8123955726623535\n",
      "TIME: 0.014250000938773155 seconds per batch\n",
      "USAGE: Allocated 0.48GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[26271] Loss: 3.7931220531463623\n",
      "Epoch [1].[26303] Loss: 3.871957540512085\n",
      "Epoch [1].[26335] Loss: 3.246497631072998\n",
      "Epoch [1].[26367] Loss: 4.511017322540283\n",
      "TIME: 0.017213759943842888 seconds per batch\n",
      "USAGE: Allocated 0.54GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[26399] Loss: 4.699873924255371\n",
      "Epoch [1].[26431] Loss: 3.2292323112487793\n",
      "Epoch [1].[26463] Loss: 4.720801830291748\n",
      "Epoch [1].[26495] Loss: 3.414924383163452\n",
      "TIME: 0.016101181507110596 seconds per batch\n",
      "USAGE: Allocated 0.54GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[26527] Loss: 4.531028747558594\n",
      "Epoch [1].[26559] Loss: 3.8415427207946777\n",
      "Epoch [1].[26591] Loss: 4.664346694946289\n",
      "Epoch [1].[26623] Loss: 3.9412243366241455\n",
      "TIME: 0.015329746529459953 seconds per batch\n",
      "USAGE: Allocated 0.70GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[26655] Loss: 4.16969633102417\n",
      "Epoch [1].[26687] Loss: 4.994476795196533\n",
      "Epoch [1].[26719] Loss: 4.9161272048950195\n",
      "Epoch [1].[26751] Loss: 3.7211787700653076\n",
      "TIME: 0.016400791704654694 seconds per batch\n",
      "USAGE: Allocated 0.63GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[26783] Loss: 4.735629081726074\n",
      "Epoch [1].[26815] Loss: 4.613903522491455\n",
      "Epoch [1].[26847] Loss: 4.757432460784912\n",
      "Epoch [1].[26879] Loss: 4.76362943649292\n",
      "TIME: 0.016207769513130188 seconds per batch\n",
      "USAGE: Allocated 0.48GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[26911] Loss: 5.0931291580200195\n",
      "Epoch [1].[26943] Loss: 4.04760217666626\n",
      "Epoch [1].[26975] Loss: 3.682938575744629\n",
      "Epoch [1].[27007] Loss: 3.3042564392089844\n",
      "TIME: 0.01419251412153244 seconds per batch\n",
      "USAGE: Allocated 0.64GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[27039] Loss: 4.922361373901367\n",
      "Epoch [1].[27071] Loss: 5.12123966217041\n",
      "Epoch [1].[27103] Loss: 4.389097213745117\n",
      "Epoch [1].[27135] Loss: 4.866029739379883\n",
      "TIME: 0.01682543009519577 seconds per batch\n",
      "USAGE: Allocated 0.54GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[27167] Loss: 5.042071342468262\n",
      "Epoch [1].[27199] Loss: 5.0214643478393555\n",
      "Epoch [1].[27231] Loss: 4.677873134613037\n",
      "Epoch [1].[27263] Loss: 4.099552154541016\n",
      "TIME: 0.01556151732802391 seconds per batch\n",
      "USAGE: Allocated 0.54GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[27295] Loss: 3.6046016216278076\n",
      "Epoch [1].[27327] Loss: 4.153706073760986\n",
      "Epoch [1].[27359] Loss: 4.737599849700928\n",
      "Epoch [1].[27391] Loss: 3.352992296218872\n",
      "TIME: 0.014632023870944977 seconds per batch\n",
      "USAGE: Allocated 0.63GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[27423] Loss: 3.4546055793762207\n",
      "Epoch [1].[27455] Loss: 4.130429267883301\n",
      "Epoch [1].[27487] Loss: 3.2330706119537354\n",
      "Epoch [1].[27519] Loss: 3.516833782196045\n",
      "TIME: 0.016288192942738533 seconds per batch\n",
      "USAGE: Allocated 0.72GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[27551] Loss: 4.6183271408081055\n",
      "Epoch [1].[27583] Loss: 4.468425273895264\n",
      "Epoch [1].[27615] Loss: 3.646350860595703\n",
      "Epoch [1].[27647] Loss: 4.582240104675293\n",
      "TIME: 0.016451235860586166 seconds per batch\n",
      "USAGE: Allocated 0.49GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[27679] Loss: 4.058785438537598\n",
      "Epoch [1].[27711] Loss: 4.684444904327393\n",
      "Epoch [1].[27743] Loss: 4.279293060302734\n",
      "Epoch [1].[27775] Loss: 4.698872089385986\n",
      "TIME: 0.0147430170327425 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[27807] Loss: 3.7228493690490723\n",
      "Epoch [1].[27839] Loss: 4.888767242431641\n",
      "Epoch [1].[27871] Loss: 4.284793853759766\n",
      "Epoch [1].[27903] Loss: 4.170294761657715\n",
      "TIME: 0.016781896352767944 seconds per batch\n",
      "USAGE: Allocated 0.60GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[27935] Loss: 4.364784240722656\n",
      "Epoch [1].[27967] Loss: 3.9768497943878174\n",
      "Epoch [1].[27999] Loss: 4.683279037475586\n",
      "Epoch [1].[28031] Loss: 4.096836090087891\n",
      "TIME: 0.01618414930999279 seconds per batch\n",
      "USAGE: Allocated 0.44GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[28063] Loss: 5.113351821899414\n",
      "Epoch [1].[28095] Loss: 4.080401420593262\n",
      "Epoch [1].[28127] Loss: 4.624175548553467\n",
      "Epoch [1].[28159] Loss: 3.7372727394104004\n",
      "TIME: 0.014245253056287766 seconds per batch\n",
      "USAGE: Allocated 0.65GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[28191] Loss: 4.267174243927002\n",
      "Epoch [1].[28223] Loss: 4.531153202056885\n",
      "Epoch [1].[28255] Loss: 3.369995594024658\n",
      "Epoch [1].[28287] Loss: 3.8171095848083496\n",
      "TIME: 0.016607390716671944 seconds per batch\n",
      "USAGE: Allocated 0.55GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[28319] Loss: 4.94477653503418\n",
      "Epoch [1].[28351] Loss: 4.247162342071533\n",
      "Epoch [1].[28383] Loss: 4.42176628112793\n",
      "Epoch [1].[28415] Loss: 4.437615394592285\n",
      "TIME: 0.016474507749080658 seconds per batch\n",
      "USAGE: Allocated 0.54GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[28447] Loss: 3.4553606510162354\n",
      "Epoch [1].[28479] Loss: 4.268219947814941\n",
      "Epoch [1].[28511] Loss: 4.814670562744141\n",
      "Epoch [1].[28543] Loss: 3.269296407699585\n",
      "TIME: 0.014976592734456062 seconds per batch\n",
      "USAGE: Allocated 0.67GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[28575] Loss: 4.5113444328308105\n",
      "Epoch [1].[28607] Loss: 3.7661633491516113\n",
      "Epoch [1].[28639] Loss: 3.941392660140991\n",
      "Epoch [1].[28671] Loss: 4.3540940284729\n",
      "TIME: 0.015713224187493324 seconds per batch\n",
      "USAGE: Allocated 0.49GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[28703] Loss: 5.750982761383057\n",
      "Epoch [1].[28735] Loss: 3.2853639125823975\n",
      "Epoch [1].[28767] Loss: 4.20859956741333\n",
      "Epoch [1].[28799] Loss: 3.5198018550872803\n",
      "TIME: 0.016895122826099396 seconds per batch\n",
      "USAGE: Allocated 0.65GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[28831] Loss: 3.211149215698242\n",
      "Epoch [1].[28863] Loss: 3.9172520637512207\n",
      "Epoch [1].[28895] Loss: 3.623659133911133\n",
      "Epoch [1].[28927] Loss: 3.9033892154693604\n",
      "TIME: 0.015400364995002747 seconds per batch\n",
      "USAGE: Allocated 0.64GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[28959] Loss: 4.559347629547119\n",
      "Epoch [1].[28991] Loss: 4.315319538116455\n",
      "Epoch [1].[29023] Loss: 5.423214435577393\n",
      "Epoch [1].[29055] Loss: 3.9699835777282715\n",
      "TIME: 0.016469581052660942 seconds per batch\n",
      "USAGE: Allocated 0.49GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[29087] Loss: 4.153087615966797\n",
      "Epoch [1].[29119] Loss: 3.3106632232666016\n",
      "Epoch [1].[29151] Loss: 4.377323627471924\n",
      "Epoch [1].[29183] Loss: 4.414271354675293\n",
      "TIME: 0.015999948605895042 seconds per batch\n",
      "USAGE: Allocated 0.60GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[29215] Loss: 4.787787437438965\n",
      "Epoch [1].[29247] Loss: 3.700596332550049\n",
      "Epoch [1].[29279] Loss: 4.119386196136475\n",
      "Epoch [1].[29311] Loss: 4.099672794342041\n",
      "TIME: 0.014489050954580307 seconds per batch\n",
      "USAGE: Allocated 0.49GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[29343] Loss: 3.785999059677124\n",
      "Epoch [1].[29375] Loss: 3.8139290809631348\n",
      "Epoch [1].[29407] Loss: 4.415482521057129\n",
      "Epoch [1].[29439] Loss: 3.5786468982696533\n",
      "TIME: 0.016980759799480438 seconds per batch\n",
      "USAGE: Allocated 0.64GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[29471] Loss: 5.147545337677002\n",
      "Epoch [1].[29503] Loss: 3.739422082901001\n",
      "Epoch [1].[29535] Loss: 3.8519787788391113\n",
      "Epoch [1].[29567] Loss: 5.133527755737305\n",
      "TIME: 0.01603608950972557 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[29599] Loss: 4.174973487854004\n",
      "Epoch [1].[29631] Loss: 4.663140296936035\n",
      "Epoch [1].[29663] Loss: 4.492869853973389\n",
      "Epoch [1].[29695] Loss: 4.104623317718506\n",
      "TIME: 0.01391245611011982 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[29727] Loss: 4.249821662902832\n",
      "Epoch [1].[29759] Loss: 3.3828957080841064\n",
      "Epoch [1].[29791] Loss: 4.567156791687012\n",
      "Epoch [1].[29823] Loss: 4.225805282592773\n",
      "TIME: 0.0186460018157959 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[29855] Loss: 3.921410322189331\n",
      "Epoch [1].[29887] Loss: 3.9158546924591064\n",
      "Epoch [1].[29919] Loss: 5.44766092300415\n",
      "Epoch [1].[29951] Loss: 4.376705169677734\n",
      "TIME: 0.015064680948853493 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[29983] Loss: 3.500697612762451\n",
      "Epoch [1].[30015] Loss: 4.212600231170654\n",
      "Epoch [1].[30047] Loss: 4.066873073577881\n",
      "Epoch [1].[30079] Loss: 5.3216423988342285\n",
      "TIME: 0.01646823063492775 seconds per batch\n",
      "USAGE: Allocated 0.49GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[30111] Loss: 4.01697301864624\n",
      "Epoch [1].[30143] Loss: 4.312557697296143\n",
      "Epoch [1].[30175] Loss: 4.792132377624512\n",
      "Epoch [1].[30207] Loss: 3.96923565864563\n",
      "TIME: 0.0165523961186409 seconds per batch\n",
      "USAGE: Allocated 0.55GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[30239] Loss: 4.18762731552124\n",
      "Epoch [1].[30271] Loss: 4.107034683227539\n",
      "Epoch [1].[30303] Loss: 4.211090087890625\n",
      "Epoch [1].[30335] Loss: 5.015476226806641\n",
      "TIME: 0.013544607907533646 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[30367] Loss: 3.2915656566619873\n",
      "Epoch [1].[30399] Loss: 4.399590969085693\n",
      "Epoch [1].[30431] Loss: 3.5729503631591797\n",
      "Epoch [1].[30463] Loss: 3.723019599914551\n",
      "TIME: 0.01636708527803421 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[30495] Loss: 3.874680519104004\n",
      "Epoch [1].[30527] Loss: 4.561863422393799\n",
      "Epoch [1].[30559] Loss: 3.59175968170166\n",
      "Epoch [1].[30591] Loss: 4.324967384338379\n",
      "TIME: 0.016865741461515427 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[30623] Loss: 4.202549457550049\n",
      "Epoch [1].[30655] Loss: 3.951249599456787\n",
      "Epoch [1].[30687] Loss: 3.8478991985321045\n",
      "Epoch [1].[30719] Loss: 4.129401683807373\n",
      "TIME: 0.014523329213261604 seconds per batch\n",
      "USAGE: Allocated 0.49GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[30751] Loss: 3.5918612480163574\n",
      "Epoch [1].[30783] Loss: 3.1481475830078125\n",
      "Epoch [1].[30815] Loss: 4.688734531402588\n",
      "Epoch [1].[30847] Loss: 4.259143829345703\n",
      "TIME: 0.01663506217300892 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[30879] Loss: 3.766514778137207\n",
      "Epoch [1].[30911] Loss: 4.358621120452881\n",
      "Epoch [1].[30943] Loss: 5.5205254554748535\n",
      "Epoch [1].[30975] Loss: 4.6356072425842285\n",
      "TIME: 0.017286689952015877 seconds per batch\n",
      "USAGE: Allocated 0.54GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[31007] Loss: 3.8247382640838623\n",
      "Epoch [1].[31039] Loss: 3.72117280960083\n",
      "Epoch [1].[31071] Loss: 4.183266639709473\n",
      "Epoch [1].[31103] Loss: 4.5299787521362305\n",
      "TIME: 0.015602242201566696 seconds per batch\n",
      "USAGE: Allocated 0.47GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[31135] Loss: 4.455697059631348\n",
      "Epoch [1].[31167] Loss: 5.343196392059326\n",
      "Epoch [1].[31199] Loss: 4.621708869934082\n",
      "Epoch [1].[31231] Loss: 3.550450563430786\n",
      "TIME: 0.015311181545257568 seconds per batch\n",
      "USAGE: Allocated 0.71GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[31263] Loss: 3.865457534790039\n",
      "Epoch [1].[31295] Loss: 4.356785774230957\n",
      "Epoch [1].[31327] Loss: 4.936577320098877\n",
      "Epoch [1].[31359] Loss: 4.200008869171143\n",
      "TIME: 0.015506600961089134 seconds per batch\n",
      "USAGE: Allocated 0.55GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[31391] Loss: 5.103945732116699\n",
      "Epoch [1].[31423] Loss: 4.656190395355225\n",
      "Epoch [1].[31455] Loss: 3.8405680656433105\n",
      "Epoch [1].[31487] Loss: 3.760468006134033\n",
      "TIME: 0.014388218522071838 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[31519] Loss: 5.142395973205566\n",
      "Epoch [1].[31551] Loss: 4.6997456550598145\n",
      "Epoch [1].[31583] Loss: 4.375803470611572\n",
      "Epoch [1].[31615] Loss: 4.239853858947754\n",
      "TIME: 0.01578368991613388 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[31647] Loss: 4.123785495758057\n",
      "Epoch [1].[31679] Loss: 3.6730308532714844\n",
      "Epoch [1].[31711] Loss: 3.3594372272491455\n",
      "Epoch [1].[31743] Loss: 5.042685031890869\n",
      "TIME: 0.015882864594459534 seconds per batch\n",
      "USAGE: Allocated 0.49GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[31775] Loss: 5.325713634490967\n",
      "Epoch [1].[31807] Loss: 3.7022275924682617\n",
      "Epoch [1].[31839] Loss: 4.3014607429504395\n",
      "Epoch [1].[31871] Loss: 4.187117576599121\n",
      "TIME: 0.01432017982006073 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[31903] Loss: 3.971524953842163\n",
      "Epoch [1].[31935] Loss: 4.169480800628662\n",
      "Epoch [1].[31967] Loss: 3.4758334159851074\n",
      "Epoch [1].[31999] Loss: 4.0850043296813965\n",
      "TIME: 0.016076864674687386 seconds per batch\n",
      "USAGE: Allocated 0.67GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[32031] Loss: 4.880525588989258\n",
      "Epoch [1].[32063] Loss: 3.690112352371216\n",
      "Epoch [1].[32095] Loss: 4.079469680786133\n",
      "Epoch [1].[32127] Loss: 4.106213092803955\n",
      "TIME: 0.01755637302994728 seconds per batch\n",
      "USAGE: Allocated 0.49GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[32159] Loss: 4.140540599822998\n",
      "Epoch [1].[32191] Loss: 4.144733905792236\n",
      "Epoch [1].[32223] Loss: 4.3393964767456055\n",
      "Epoch [1].[32255] Loss: 4.232709884643555\n",
      "TIME: 0.015380064025521278 seconds per batch\n",
      "USAGE: Allocated 0.49GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[32287] Loss: 3.637967586517334\n",
      "Epoch [1].[32319] Loss: 4.386636734008789\n",
      "Epoch [1].[32351] Loss: 4.837704181671143\n",
      "Epoch [1].[32383] Loss: 5.011116027832031\n",
      "TIME: 0.016458939760923386 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[32415] Loss: 4.815533638000488\n",
      "Epoch [1].[32447] Loss: 3.5149686336517334\n",
      "Epoch [1].[32479] Loss: 4.502493381500244\n",
      "Epoch [1].[32511] Loss: 3.8000004291534424\n",
      "TIME: 0.01594027318060398 seconds per batch\n",
      "USAGE: Allocated 0.59GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[32543] Loss: 4.497796058654785\n",
      "Epoch [1].[32575] Loss: 4.673969745635986\n",
      "Epoch [1].[32607] Loss: 3.606966495513916\n",
      "Epoch [1].[32639] Loss: 4.663994312286377\n",
      "TIME: 0.014231087639927864 seconds per batch\n",
      "USAGE: Allocated 0.48GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[32671] Loss: 4.179397106170654\n",
      "Epoch [1].[32703] Loss: 5.1950860023498535\n",
      "Epoch [1].[32735] Loss: 4.565715789794922\n",
      "Epoch [1].[32767] Loss: 4.2018723487854\n",
      "TIME: 0.015700215473771095 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[32799] Loss: 3.489461660385132\n",
      "Epoch [1].[32831] Loss: 3.68501877784729\n",
      "Epoch [1].[32863] Loss: 4.927852630615234\n",
      "Epoch [1].[32895] Loss: 4.15030574798584\n",
      "TIME: 0.016456646844744682 seconds per batch\n",
      "USAGE: Allocated 0.48GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[32927] Loss: 4.991672992706299\n",
      "Epoch [1].[32959] Loss: 4.355783939361572\n",
      "Epoch [1].[32991] Loss: 3.946291446685791\n",
      "Epoch [1].[33023] Loss: 4.153339862823486\n",
      "TIME: 0.01353546418249607 seconds per batch\n",
      "USAGE: Allocated 0.54GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[33055] Loss: 4.359789848327637\n",
      "Epoch [1].[33087] Loss: 3.438966751098633\n",
      "Epoch [1].[33119] Loss: 3.2180404663085938\n",
      "Epoch [1].[33151] Loss: 4.466724395751953\n",
      "TIME: 0.015876926481723785 seconds per batch\n",
      "USAGE: Allocated 0.48GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[33183] Loss: 2.953281879425049\n",
      "Epoch [1].[33215] Loss: 4.184700965881348\n",
      "Epoch [1].[33247] Loss: 2.9146318435668945\n",
      "Epoch [1].[33279] Loss: 5.1167216300964355\n",
      "TIME: 0.01621747948229313 seconds per batch\n",
      "USAGE: Allocated 0.47GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[33311] Loss: 4.150339126586914\n",
      "Epoch [1].[33343] Loss: 4.550731658935547\n",
      "Epoch [1].[33375] Loss: 5.069187641143799\n",
      "Epoch [1].[33407] Loss: 4.103242874145508\n",
      "TIME: 0.013925010338425636 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[33439] Loss: 4.121224880218506\n",
      "Epoch [1].[33471] Loss: 4.216123580932617\n",
      "Epoch [1].[33503] Loss: 4.64697790145874\n",
      "Epoch [1].[33535] Loss: 3.7886548042297363\n",
      "TIME: 0.01565411686897278 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[33567] Loss: 4.8107123374938965\n",
      "Epoch [1].[33599] Loss: 4.543156623840332\n",
      "Epoch [1].[33631] Loss: 3.587139368057251\n",
      "Epoch [1].[33663] Loss: 5.167532920837402\n",
      "TIME: 0.017192022874951363 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[33695] Loss: 4.9002790451049805\n",
      "Epoch [1].[33727] Loss: 5.243144512176514\n",
      "Epoch [1].[33759] Loss: 3.5750973224639893\n",
      "Epoch [1].[33791] Loss: 4.723728656768799\n",
      "TIME: 0.01489526778459549 seconds per batch\n",
      "USAGE: Allocated 0.54GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[33823] Loss: 4.286901473999023\n",
      "Epoch [1].[33855] Loss: 4.421894550323486\n",
      "Epoch [1].[33887] Loss: 3.7941837310791016\n",
      "Epoch [1].[33919] Loss: 3.445866346359253\n",
      "TIME: 0.015664109960198402 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[33951] Loss: 4.7602128982543945\n",
      "Epoch [1].[33983] Loss: 3.2262513637542725\n",
      "Epoch [1].[34015] Loss: 3.022350549697876\n",
      "Epoch [1].[34047] Loss: 4.031888961791992\n",
      "TIME: 0.015472067520022392 seconds per batch\n",
      "USAGE: Allocated 0.57GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[34079] Loss: 4.248271465301514\n",
      "Epoch [1].[34111] Loss: 3.633012294769287\n",
      "Epoch [1].[34143] Loss: 3.7857542037963867\n",
      "Epoch [1].[34175] Loss: 3.3142032623291016\n",
      "TIME: 0.01577559858560562 seconds per batch\n",
      "USAGE: Allocated 0.54GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[34207] Loss: 4.570608615875244\n",
      "Epoch [1].[34239] Loss: 4.939446449279785\n",
      "Epoch [1].[34271] Loss: 4.321582317352295\n",
      "Epoch [1].[34303] Loss: 4.648702621459961\n",
      "TIME: 0.01616637408733368 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[34335] Loss: 3.6764514446258545\n",
      "Epoch [1].[34367] Loss: 4.554442882537842\n",
      "Epoch [1].[34399] Loss: 4.320584297180176\n",
      "Epoch [1].[34431] Loss: 3.341254472732544\n",
      "TIME: 0.015115758404135704 seconds per batch\n",
      "USAGE: Allocated 0.80GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[34463] Loss: 4.98498010635376\n",
      "Epoch [1].[34495] Loss: 4.177901268005371\n",
      "Epoch [1].[34527] Loss: 3.4901599884033203\n",
      "Epoch [1].[34559] Loss: 4.344498634338379\n",
      "TIME: 0.01562400721013546 seconds per batch\n",
      "USAGE: Allocated 0.54GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[34591] Loss: 4.5270094871521\n",
      "Epoch [1].[34623] Loss: 4.569110870361328\n",
      "Epoch [1].[34655] Loss: 4.905877590179443\n",
      "Epoch [1].[34687] Loss: 3.3612327575683594\n",
      "TIME: 0.01675453409552574 seconds per batch\n",
      "USAGE: Allocated 0.76GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[34719] Loss: 3.52290415763855\n",
      "Epoch [1].[34751] Loss: 3.5027060508728027\n",
      "Epoch [1].[34783] Loss: 4.275262832641602\n",
      "Epoch [1].[34815] Loss: 3.911837339401245\n",
      "TIME: 0.01388092152774334 seconds per batch\n",
      "USAGE: Allocated 0.59GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[34847] Loss: 3.0250980854034424\n",
      "Epoch [1].[34879] Loss: 4.588585376739502\n",
      "Epoch [1].[34911] Loss: 3.470104932785034\n",
      "Epoch [1].[34943] Loss: 3.5279922485351562\n",
      "TIME: 0.016551285982131958 seconds per batch\n",
      "USAGE: Allocated 0.67GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[34975] Loss: 3.880000352859497\n",
      "Epoch [1].[35007] Loss: 3.4163577556610107\n",
      "Epoch [1].[35039] Loss: 3.64070200920105\n",
      "Epoch [1].[35071] Loss: 4.419053077697754\n",
      "TIME: 0.015221808105707169 seconds per batch\n",
      "USAGE: Allocated 0.49GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[35103] Loss: 5.053792476654053\n",
      "Epoch [1].[35135] Loss: 3.5474579334259033\n",
      "Epoch [1].[35167] Loss: 4.538984775543213\n",
      "Epoch [1].[35199] Loss: 3.420429229736328\n",
      "TIME: 0.01385459303855896 seconds per batch\n",
      "USAGE: Allocated 0.81GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[35231] Loss: 4.003848552703857\n",
      "Epoch [1].[35263] Loss: 4.480432033538818\n",
      "Epoch [1].[35295] Loss: 3.4162795543670654\n",
      "Epoch [1].[35327] Loss: 3.758293628692627\n",
      "TIME: 0.016117025166749954 seconds per batch\n",
      "USAGE: Allocated 0.60GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[35359] Loss: 4.604119300842285\n",
      "Epoch [1].[35391] Loss: 3.68333101272583\n",
      "Epoch [1].[35423] Loss: 4.355034351348877\n",
      "Epoch [1].[35455] Loss: 4.0900139808654785\n",
      "TIME: 0.015581728890538216 seconds per batch\n",
      "USAGE: Allocated 0.59GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[35487] Loss: 4.568117141723633\n",
      "Epoch [1].[35519] Loss: 4.323304176330566\n",
      "Epoch [1].[35551] Loss: 3.962599992752075\n",
      "Epoch [1].[35583] Loss: 4.689927577972412\n",
      "TIME: 0.014479512348771095 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[35615] Loss: 3.6876096725463867\n",
      "Epoch [1].[35647] Loss: 3.6026604175567627\n",
      "Epoch [1].[35679] Loss: 4.168628215789795\n",
      "Epoch [1].[35711] Loss: 3.8835246562957764\n",
      "TIME: 0.01738300919532776 seconds per batch\n",
      "USAGE: Allocated 0.62GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[35743] Loss: 3.917039632797241\n",
      "Epoch [1].[35775] Loss: 3.1944503784179688\n",
      "Epoch [1].[35807] Loss: 3.875474691390991\n",
      "Epoch [1].[35839] Loss: 3.214672565460205\n",
      "TIME: 0.01675652153789997 seconds per batch\n",
      "USAGE: Allocated 0.70GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[35871] Loss: 3.7865822315216064\n",
      "Epoch [1].[35903] Loss: 3.461444616317749\n",
      "Epoch [1].[35935] Loss: 4.316387176513672\n",
      "Epoch [1].[35967] Loss: 3.522143840789795\n",
      "TIME: 0.015106461942195892 seconds per batch\n",
      "USAGE: Allocated 0.66GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[35999] Loss: 3.93418288230896\n",
      "Epoch [1].[36031] Loss: 3.954291820526123\n",
      "Epoch [1].[36063] Loss: 3.412055253982544\n",
      "Epoch [1].[36095] Loss: 4.219653606414795\n",
      "TIME: 0.015271825715899467 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[36127] Loss: 4.351496696472168\n",
      "Epoch [1].[36159] Loss: 4.72123384475708\n",
      "Epoch [1].[36191] Loss: 4.818732738494873\n",
      "Epoch [1].[36223] Loss: 4.292541027069092\n",
      "TIME: 0.016820969060063362 seconds per batch\n",
      "USAGE: Allocated 0.45GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[36255] Loss: 3.3269269466400146\n",
      "Epoch [1].[36287] Loss: 4.258482456207275\n",
      "Epoch [1].[36319] Loss: 3.764932155609131\n",
      "Epoch [1].[36351] Loss: 3.2676026821136475\n",
      "TIME: 0.01391039788722992 seconds per batch\n",
      "USAGE: Allocated 0.66GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[36383] Loss: 4.783915042877197\n",
      "Epoch [1].[36415] Loss: 3.5321409702301025\n",
      "Epoch [1].[36447] Loss: 3.517197847366333\n",
      "Epoch [1].[36479] Loss: 5.303800106048584\n",
      "TIME: 0.015274489298462868 seconds per batch\n",
      "USAGE: Allocated 0.54GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[36511] Loss: 4.521055221557617\n",
      "Epoch [1].[36543] Loss: 3.5460219383239746\n",
      "Epoch [1].[36575] Loss: 3.5941591262817383\n",
      "Epoch [1].[36607] Loss: 4.3741278648376465\n",
      "TIME: 0.01592807099223137 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[36639] Loss: 4.491629600524902\n",
      "Epoch [1].[36671] Loss: 4.265721321105957\n",
      "Epoch [1].[36703] Loss: 4.21699857711792\n",
      "Epoch [1].[36735] Loss: 4.18172025680542\n",
      "TIME: 0.014042973518371582 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[36767] Loss: 3.931318759918213\n",
      "Epoch [1].[36799] Loss: 4.426849365234375\n",
      "Epoch [1].[36831] Loss: 3.338665723800659\n",
      "Epoch [1].[36863] Loss: 4.582294940948486\n",
      "TIME: 0.017970282584428787 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[36895] Loss: 4.534952163696289\n",
      "Epoch [1].[36927] Loss: 4.459660053253174\n",
      "Epoch [1].[36959] Loss: 4.522451400756836\n",
      "Epoch [1].[36991] Loss: 3.992233991622925\n",
      "TIME: 0.016223212704062462 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[37023] Loss: 4.5019731521606445\n",
      "Epoch [1].[37055] Loss: 3.2203783988952637\n",
      "Epoch [1].[37087] Loss: 3.5680301189422607\n",
      "Epoch [1].[37119] Loss: 3.5001022815704346\n",
      "TIME: 0.013631755486130714 seconds per batch\n",
      "USAGE: Allocated 0.55GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[37151] Loss: 4.014826774597168\n",
      "Epoch [1].[37183] Loss: 4.483691692352295\n",
      "Epoch [1].[37215] Loss: 4.693028450012207\n",
      "Epoch [1].[37247] Loss: 3.5683140754699707\n",
      "TIME: 0.0165794026106596 seconds per batch\n",
      "USAGE: Allocated 0.77GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[37279] Loss: 3.3682117462158203\n",
      "Epoch [1].[37311] Loss: 3.973357915878296\n",
      "Epoch [1].[37343] Loss: 4.829400062561035\n",
      "Epoch [1].[37375] Loss: 4.338152885437012\n",
      "TIME: 0.016963617876172066 seconds per batch\n",
      "USAGE: Allocated 0.59GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[37407] Loss: 4.605962753295898\n",
      "Epoch [1].[37439] Loss: 4.417845726013184\n",
      "Epoch [1].[37471] Loss: 3.7390615940093994\n",
      "Epoch [1].[37503] Loss: 3.874955654144287\n",
      "TIME: 0.013623787090182304 seconds per batch\n",
      "USAGE: Allocated 0.54GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[37535] Loss: 3.9546682834625244\n",
      "Epoch [1].[37567] Loss: 4.394175052642822\n",
      "Epoch [1].[37599] Loss: 3.0232999324798584\n",
      "Epoch [1].[37631] Loss: 4.630761623382568\n",
      "TIME: 0.015759294852614403 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[37663] Loss: 3.61537766456604\n",
      "Epoch [1].[37695] Loss: 3.6632792949676514\n",
      "Epoch [1].[37727] Loss: 4.757587432861328\n",
      "Epoch [1].[37759] Loss: 4.1143879890441895\n",
      "TIME: 0.016335660591721535 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[37791] Loss: 4.220142841339111\n",
      "Epoch [1].[37823] Loss: 3.5924413204193115\n",
      "Epoch [1].[37855] Loss: 4.325334072113037\n",
      "Epoch [1].[37887] Loss: 3.68522572517395\n",
      "TIME: 0.01411055214703083 seconds per batch\n",
      "USAGE: Allocated 0.63GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[37919] Loss: 4.526927471160889\n",
      "Epoch [1].[37951] Loss: 4.238846778869629\n",
      "Epoch [1].[37983] Loss: 3.583869457244873\n",
      "Epoch [1].[38015] Loss: 3.099524736404419\n",
      "TIME: 0.01570083573460579 seconds per batch\n",
      "USAGE: Allocated 0.63GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[38047] Loss: 3.9219398498535156\n",
      "Epoch [1].[38079] Loss: 4.162169456481934\n",
      "Epoch [1].[38111] Loss: 4.657739639282227\n",
      "Epoch [1].[38143] Loss: 3.9839155673980713\n",
      "TIME: 0.017305903136730194 seconds per batch\n",
      "USAGE: Allocated 0.48GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[38175] Loss: 3.4871599674224854\n",
      "Epoch [1].[38207] Loss: 5.140586853027344\n",
      "Epoch [1].[38239] Loss: 3.455559015274048\n",
      "Epoch [1].[38271] Loss: 4.369035243988037\n",
      "TIME: 0.01675485074520111 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[38303] Loss: 4.857010841369629\n",
      "Epoch [1].[38335] Loss: 4.094872951507568\n",
      "Epoch [1].[38367] Loss: 3.5329134464263916\n",
      "Epoch [1].[38399] Loss: 4.332919120788574\n",
      "TIME: 0.016080334782600403 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[38431] Loss: 3.1300883293151855\n",
      "Epoch [1].[38463] Loss: 3.6003212928771973\n",
      "Epoch [1].[38495] Loss: 2.716956853866577\n",
      "Epoch [1].[38527] Loss: 4.641085624694824\n",
      "TIME: 0.014593958854675293 seconds per batch\n",
      "USAGE: Allocated 0.54GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[38559] Loss: 4.852304458618164\n",
      "Epoch [1].[38591] Loss: 4.714346408843994\n",
      "Epoch [1].[38623] Loss: 4.350162029266357\n",
      "Epoch [1].[38655] Loss: 3.6757609844207764\n",
      "TIME: 0.016117002815008163 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[38687] Loss: 4.42230224609375\n",
      "Epoch [1].[38719] Loss: 3.828810930252075\n",
      "Epoch [1].[38751] Loss: 4.909205913543701\n",
      "Epoch [1].[38783] Loss: 3.20733904838562\n",
      "TIME: 0.015446506440639496 seconds per batch\n",
      "USAGE: Allocated 0.62GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[38815] Loss: 3.9782543182373047\n",
      "Epoch [1].[38847] Loss: 4.805020809173584\n",
      "Epoch [1].[38879] Loss: 3.7107698917388916\n",
      "Epoch [1].[38911] Loss: 5.003210067749023\n",
      "TIME: 0.014538619667291641 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[38943] Loss: 4.058826446533203\n",
      "Epoch [1].[38975] Loss: 4.601555347442627\n",
      "Epoch [1].[39007] Loss: 3.3441250324249268\n",
      "Epoch [1].[39039] Loss: 4.9804205894470215\n",
      "TIME: 0.016188452020287514 seconds per batch\n",
      "USAGE: Allocated 0.48GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[39071] Loss: 4.750067710876465\n",
      "Epoch [1].[39103] Loss: 4.010462284088135\n",
      "Epoch [1].[39135] Loss: 3.3143982887268066\n",
      "Epoch [1].[39167] Loss: 3.7224600315093994\n",
      "TIME: 0.016395967453718185 seconds per batch\n",
      "USAGE: Allocated 0.55GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[39199] Loss: 4.397563457489014\n",
      "Epoch [1].[39231] Loss: 4.271831035614014\n",
      "Epoch [1].[39263] Loss: 4.418514728546143\n",
      "Epoch [1].[39295] Loss: 4.162590026855469\n",
      "TIME: 0.013625061139464378 seconds per batch\n",
      "USAGE: Allocated 0.49GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[39327] Loss: 3.2794859409332275\n",
      "Epoch [1].[39359] Loss: 3.8413867950439453\n",
      "Epoch [1].[39391] Loss: 5.2099809646606445\n",
      "Epoch [1].[39423] Loss: 3.111348867416382\n",
      "TIME: 0.016571735963225365 seconds per batch\n",
      "USAGE: Allocated 0.74GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[39455] Loss: 4.529165267944336\n",
      "Epoch [1].[39487] Loss: 3.603973150253296\n",
      "Epoch [1].[39519] Loss: 3.4161810874938965\n",
      "Epoch [1].[39551] Loss: 3.2251410484313965\n",
      "TIME: 0.01692897267639637 seconds per batch\n",
      "USAGE: Allocated 0.83GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[39583] Loss: 3.514134645462036\n",
      "Epoch [1].[39615] Loss: 4.362252712249756\n",
      "Epoch [1].[39647] Loss: 3.7394073009490967\n",
      "Epoch [1].[39679] Loss: 3.804551839828491\n",
      "TIME: 0.01438819244503975 seconds per batch\n",
      "USAGE: Allocated 0.48GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[39711] Loss: 4.335359573364258\n",
      "Epoch [1].[39743] Loss: 4.061374187469482\n",
      "Epoch [1].[39775] Loss: 4.506505012512207\n",
      "Epoch [1].[39807] Loss: 3.3946845531463623\n",
      "TIME: 0.016110945492982864 seconds per batch\n",
      "USAGE: Allocated 0.66GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[39839] Loss: 3.1267387866973877\n",
      "Epoch [1].[39871] Loss: 3.9946727752685547\n",
      "Epoch [1].[39903] Loss: 3.459110736846924\n",
      "Epoch [1].[39935] Loss: 4.650903224945068\n",
      "TIME: 0.016918610781431198 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[39967] Loss: 3.844167709350586\n",
      "Epoch [1].[39999] Loss: 4.32454776763916\n",
      "Epoch [1].[40031] Loss: 3.805985689163208\n",
      "Epoch [1].[40063] Loss: 2.9937078952789307\n",
      "TIME: 0.014840222895145416 seconds per batch\n",
      "USAGE: Allocated 0.59GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[40095] Loss: 3.988501787185669\n",
      "Epoch [1].[40127] Loss: 4.107905864715576\n",
      "Epoch [1].[40159] Loss: 4.705721378326416\n",
      "Epoch [1].[40191] Loss: 4.04081392288208\n",
      "TIME: 0.016462750732898712 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[40223] Loss: 4.690128803253174\n",
      "Epoch [1].[40255] Loss: 3.6955831050872803\n",
      "Epoch [1].[40287] Loss: 4.804724216461182\n",
      "Epoch [1].[40319] Loss: 4.397378444671631\n",
      "TIME: 0.015808064490556717 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[40351] Loss: 4.909324645996094\n",
      "Epoch [1].[40383] Loss: 4.0333051681518555\n",
      "Epoch [1].[40415] Loss: 3.3852498531341553\n",
      "Epoch [1].[40447] Loss: 3.7503716945648193\n",
      "TIME: 0.014344591647386551 seconds per batch\n",
      "USAGE: Allocated 0.55GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[40479] Loss: 3.5576725006103516\n",
      "Epoch [1].[40511] Loss: 2.951572895050049\n",
      "Epoch [1].[40543] Loss: 3.699514627456665\n",
      "Epoch [1].[40575] Loss: 3.4129385948181152\n",
      "TIME: 0.016169946640729904 seconds per batch\n",
      "USAGE: Allocated 0.84GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[40607] Loss: 4.54421854019165\n",
      "Epoch [1].[40639] Loss: 3.9839320182800293\n",
      "Epoch [1].[40671] Loss: 4.8098249435424805\n",
      "Epoch [1].[40703] Loss: 4.855728626251221\n",
      "TIME: 0.016540518030524254 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[40735] Loss: 4.831492900848389\n",
      "Epoch [1].[40767] Loss: 3.8591558933258057\n",
      "Epoch [1].[40799] Loss: 4.5494842529296875\n",
      "Epoch [1].[40831] Loss: 4.609732627868652\n",
      "TIME: 0.013885198161005974 seconds per batch\n",
      "USAGE: Allocated 0.54GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[40863] Loss: 3.706294536590576\n",
      "Epoch [1].[40895] Loss: 4.283071041107178\n",
      "Epoch [1].[40927] Loss: 3.042576313018799\n",
      "Epoch [1].[40959] Loss: 4.693362236022949\n",
      "TIME: 0.015531152486801147 seconds per batch\n",
      "USAGE: Allocated 0.49GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[40991] Loss: 3.952218770980835\n",
      "Epoch [1].[41023] Loss: 3.9564802646636963\n",
      "Epoch [1].[41055] Loss: 4.654491901397705\n",
      "Epoch [1].[41087] Loss: 4.08103084564209\n",
      "TIME: 0.016231663525104523 seconds per batch\n",
      "USAGE: Allocated 0.47GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[41119] Loss: 4.087146759033203\n",
      "Epoch [1].[41151] Loss: 4.4302802085876465\n",
      "Epoch [1].[41183] Loss: 2.8686037063598633\n",
      "Epoch [1].[41215] Loss: 4.152738571166992\n",
      "TIME: 0.014583151787519455 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[41247] Loss: 3.727466106414795\n",
      "Epoch [1].[41279] Loss: 4.230525016784668\n",
      "Epoch [1].[41311] Loss: 4.4334235191345215\n",
      "Epoch [1].[41343] Loss: 4.095561981201172\n",
      "TIME: 0.016110893338918686 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[41375] Loss: 4.411530494689941\n",
      "Epoch [1].[41407] Loss: 3.6234896183013916\n",
      "Epoch [1].[41439] Loss: 4.356638431549072\n",
      "Epoch [1].[41471] Loss: 3.328596830368042\n",
      "TIME: 0.015668310225009918 seconds per batch\n",
      "USAGE: Allocated 0.82GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[41503] Loss: 3.8695061206817627\n",
      "Epoch [1].[41535] Loss: 4.6075615882873535\n",
      "Epoch [1].[41567] Loss: 4.136451721191406\n",
      "Epoch [1].[41599] Loss: 2.6644139289855957\n",
      "TIME: 0.01403864473104477 seconds per batch\n",
      "USAGE: Allocated 0.85GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[41631] Loss: 4.744962215423584\n",
      "Epoch [1].[41663] Loss: 4.214744567871094\n",
      "Epoch [1].[41695] Loss: 3.3564181327819824\n",
      "Epoch [1].[41727] Loss: 3.759312629699707\n",
      "TIME: 0.015925759449601173 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[41759] Loss: 3.7097880840301514\n",
      "Epoch [1].[41791] Loss: 3.6435024738311768\n",
      "Epoch [1].[41823] Loss: 4.183211803436279\n",
      "Epoch [1].[41855] Loss: 5.1483659744262695\n",
      "TIME: 0.01592443883419037 seconds per batch\n",
      "USAGE: Allocated 0.49GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[41887] Loss: 4.990582466125488\n",
      "Epoch [1].[41919] Loss: 3.9674150943756104\n",
      "Epoch [1].[41951] Loss: 4.0483479499816895\n",
      "Epoch [1].[41983] Loss: 3.4922895431518555\n",
      "TIME: 0.014283476397395134 seconds per batch\n",
      "USAGE: Allocated 0.72GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[42015] Loss: 4.461803913116455\n",
      "Epoch [1].[42047] Loss: 4.054848670959473\n",
      "Epoch [1].[42079] Loss: 4.809682846069336\n",
      "Epoch [1].[42111] Loss: 4.5903191566467285\n",
      "TIME: 0.01619303598999977 seconds per batch\n",
      "USAGE: Allocated 0.48GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[42143] Loss: 4.0733442306518555\n",
      "Epoch [1].[42175] Loss: 5.148069381713867\n",
      "Epoch [1].[42207] Loss: 3.561861038208008\n",
      "Epoch [1].[42239] Loss: 4.054056167602539\n",
      "TIME: 0.015564395114779472 seconds per batch\n",
      "USAGE: Allocated 0.55GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[42271] Loss: 4.677846431732178\n",
      "Epoch [1].[42303] Loss: 2.91188645362854\n",
      "Epoch [1].[42335] Loss: 3.1717772483825684\n",
      "Epoch [1].[42367] Loss: 3.275599241256714\n",
      "TIME: 0.016889827325940132 seconds per batch\n",
      "USAGE: Allocated 0.69GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[42399] Loss: 4.0957489013671875\n",
      "Epoch [1].[42431] Loss: 4.507620811462402\n",
      "Epoch [1].[42463] Loss: 4.212879657745361\n",
      "Epoch [1].[42495] Loss: 3.8068149089813232\n",
      "TIME: 0.015398001298308372 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[42527] Loss: 4.665283203125\n",
      "Epoch [1].[42559] Loss: 4.015459060668945\n",
      "Epoch [1].[42591] Loss: 3.394794464111328\n",
      "Epoch [1].[42623] Loss: 3.9726321697235107\n",
      "TIME: 0.014534149318933487 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[42655] Loss: 3.645993947982788\n",
      "Epoch [1].[42687] Loss: 3.9000749588012695\n",
      "Epoch [1].[42719] Loss: 4.124851703643799\n",
      "Epoch [1].[42751] Loss: 4.77821683883667\n",
      "TIME: 0.016004575416445732 seconds per batch\n",
      "USAGE: Allocated 0.49GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[42783] Loss: 4.810183048248291\n",
      "Epoch [1].[42815] Loss: 4.439328193664551\n",
      "Epoch [1].[42847] Loss: 4.234184265136719\n",
      "Epoch [1].[42879] Loss: 3.9210898876190186\n",
      "TIME: 0.016114387661218643 seconds per batch\n",
      "USAGE: Allocated 0.73GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[42911] Loss: 4.240440368652344\n",
      "Epoch [1].[42943] Loss: 4.332056522369385\n",
      "Epoch [1].[42975] Loss: 3.7056691646575928\n",
      "Epoch [1].[43007] Loss: 4.1236677169799805\n",
      "TIME: 0.01436728797852993 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[43039] Loss: 4.025667190551758\n",
      "Epoch [1].[43071] Loss: 4.606130123138428\n",
      "Epoch [1].[43103] Loss: 4.081014156341553\n",
      "Epoch [1].[43135] Loss: 4.547503471374512\n",
      "TIME: 0.01511635072529316 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[43167] Loss: 3.18157958984375\n",
      "Epoch [1].[43199] Loss: 4.178619861602783\n",
      "Epoch [1].[43231] Loss: 3.2975971698760986\n",
      "Epoch [1].[43263] Loss: 3.968039035797119\n",
      "TIME: 0.01660260371863842 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[43295] Loss: 3.9588418006896973\n",
      "Epoch [1].[43327] Loss: 4.0589776039123535\n",
      "Epoch [1].[43359] Loss: 3.5800766944885254\n",
      "Epoch [1].[43391] Loss: 4.59001350402832\n",
      "TIME: 0.01422632485628128 seconds per batch\n",
      "USAGE: Allocated 0.52GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[43423] Loss: 4.777982711791992\n",
      "Epoch [1].[43455] Loss: 4.277711391448975\n",
      "Epoch [1].[43487] Loss: 4.604818344116211\n",
      "Epoch [1].[43519] Loss: 3.2158074378967285\n",
      "TIME: 0.016009829938411713 seconds per batch\n",
      "USAGE: Allocated 0.70GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[43551] Loss: 4.357142925262451\n",
      "Epoch [1].[43583] Loss: 3.4921176433563232\n",
      "Epoch [1].[43615] Loss: 3.2280807495117188\n",
      "Epoch [1].[43647] Loss: 2.9598464965820312\n",
      "TIME: 0.016226669773459435 seconds per batch\n",
      "USAGE: Allocated 0.73GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[43679] Loss: 4.013765811920166\n",
      "Epoch [1].[43711] Loss: 4.49464225769043\n",
      "Epoch [1].[43743] Loss: 4.502045154571533\n",
      "Epoch [1].[43775] Loss: 3.6291468143463135\n",
      "TIME: 0.013992751017212868 seconds per batch\n",
      "USAGE: Allocated 0.51GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[43807] Loss: 4.1849236488342285\n",
      "Epoch [1].[43839] Loss: 4.460168361663818\n",
      "Epoch [1].[43871] Loss: 4.7432451248168945\n",
      "Epoch [1].[43903] Loss: 3.8891141414642334\n",
      "TIME: 0.016521699726581573 seconds per batch\n",
      "USAGE: Allocated 0.53GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[43935] Loss: 4.081455230712891\n",
      "Epoch [1].[43967] Loss: 3.859787940979004\n",
      "Epoch [1].[43999] Loss: 3.9185855388641357\n",
      "Epoch [1].[44031] Loss: 3.4697484970092773\n",
      "TIME: 0.016266612336039543 seconds per batch\n",
      "USAGE: Allocated 0.55GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[44063] Loss: 3.4689338207244873\n",
      "Epoch [1].[44095] Loss: 3.0438942909240723\n",
      "Epoch [1].[44127] Loss: 3.1395978927612305\n",
      "Epoch [1].[44159] Loss: 4.0100908279418945\n",
      "TIME: 0.013829894363880157 seconds per batch\n",
      "USAGE: Allocated 0.50GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[44191] Loss: 3.2890782356262207\n",
      "Epoch [1].[44223] Loss: 3.6542813777923584\n",
      "Epoch [1].[44255] Loss: 3.456092119216919\n",
      "Epoch [1].[44287] Loss: 3.778399705886841\n",
      "TIME: 0.016202077269554138 seconds per batch\n",
      "USAGE: Allocated 0.49GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[44319] Loss: 4.56702995300293\n",
      "Epoch [1].[44351] Loss: 4.616317272186279\n",
      "Epoch [1].[44383] Loss: 4.145824909210205\n",
      "Epoch [1].[44415] Loss: 3.6292426586151123\n",
      "TIME: 0.016581863164901733 seconds per batch\n",
      "USAGE: Allocated 0.63GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[44447] Loss: 3.1013476848602295\n",
      "Epoch [1].[44479] Loss: 4.33102560043335\n",
      "Epoch [1].[44511] Loss: 3.368147134780884\n",
      "Epoch [1].[44543] Loss: 4.783424377441406\n",
      "TIME: 0.014531994238495827 seconds per batch\n",
      "USAGE: Allocated 0.64GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[44575] Loss: 4.194797515869141\n",
      "Epoch [1].[44607] Loss: 4.328668117523193\n",
      "Epoch [1].[44639] Loss: 4.501016139984131\n",
      "Epoch [1].[44671] Loss: 4.222689151763916\n",
      "TIME: 0.016161346808075905 seconds per batch\n",
      "USAGE: Allocated 0.55GB, Reserved 4.80GB, Peak: 3.67GB\n",
      "Epoch [1].[44703] Loss: 3.7919280529022217\n",
      "Epoch [1].[44735] Loss: 4.482357978820801\n"
     ]
    }
   ],
   "source": [
    "train_model(model, optimizer, criterion, device, train_loader, accum_steps, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482a1d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(train[:8])\n",
    "print(f\"output: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291345d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0,-4,:].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e952a12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_word = encoder.decode([output[0,-1,:].argmax()])\n",
    "print(predicted_word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
