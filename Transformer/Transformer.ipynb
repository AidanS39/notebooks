{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "956cde40-5eaa-4466-a6be-0a4f10b22222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchvision.transforms import v2\n",
    "from datasets import load_dataset\n",
    "import tiktoken\n",
    "import time\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac2d5eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from https://pytorch-tutorials-preview.netlify.app/beginner/transformer_tutorial.html\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 d_model: int, \n",
    "                 dropout: float = 0.1, \n",
    "                 max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(1, max_len, d_model)\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[batch_size, seq_len, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0ae2853",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, \n",
    "                 d_model: int, \n",
    "                 d_query: int = 128, \n",
    "                 n_heads: int = 8,\n",
    "                 device: torch.device = torch.device(\"cpu\")):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_query)\n",
    "        self.W_k = nn.Linear(d_model, d_query)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.scaling_factor = math.sqrt(d_query)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        \n",
    "        x = x.unsqueeze(1).repeat([1, self.n_heads, 1, 1])\n",
    "        \n",
    "        q = self.W_q(x)\n",
    "        k = self.W_k(x)\n",
    "        v = self.W_v(x)\n",
    "\n",
    "        attention_pattern = torch.matmul(q, torch.transpose(k, -2, -1)) / self.scaling_factor\n",
    "        \n",
    "        seq_len = attention_pattern.shape[-1]\n",
    "        mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool().to(self.device)\n",
    "        attention_pattern = torch.masked_fill(attention_pattern, mask, float(\"-inf\"))\n",
    "\n",
    "        attention_pattern = self.softmax(attention_pattern)\n",
    "\n",
    "        output = torch.sum(torch.matmul(attention_pattern, v), dim=1)\n",
    "        \n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd25bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron(nn.Module):\n",
    "    def __init__(self, \n",
    "                 d_model: int, \n",
    "                 d_up: int = 256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.Linear(d_model, d_up)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.down = nn.Linear(d_up, d_model)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        output = self.up(x)\n",
    "        output = self.relu(output)\n",
    "        output = self.down(output)\n",
    "\n",
    "        output = output + x\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7cbf8aa-4165-4b6f-963d-f1bbb138d0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 n_vocab: int, \n",
    "                 d_model: int = 128, \n",
    "                 d_query: int = 128, \n",
    "                 n_heads: int = 8, \n",
    "                 n_layers: int = 4, \n",
    "                 d_up: int = 256,\n",
    "                 device: torch.device = torch.device(\"cpu\")):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(n_vocab, d_model)\n",
    "        self.pe = PositionalEncoding(d_model, max_len=50000)\n",
    "\n",
    "        self.attention_layers = nn.ModuleList([layer for _ in range(n_layers) for layer in \n",
    "                                               (SelfAttention(d_model, d_query, n_heads, device), \n",
    "                                                nn.LayerNorm(d_model),\n",
    "                                                MultilayerPerceptron(d_model, d_up))])\n",
    "\n",
    "        # self.self_attention = SelfAttention(d_model, d_query, n_heads, device)\n",
    "        # self.mlp = MultilayerPerceptron(d_model, d_up)\n",
    "\n",
    "        self.unembedding = nn.Linear(d_model, n_vocab)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "        x = self.pe(x)\n",
    "\n",
    "        for layer in self.attention_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        x = self.unembedding(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa09e45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelCheckpoint():\n",
    "    def __init__(self, model_state, optim_state, epoch: int, batch: int, rng_state: torch.Tensor):\n",
    "        self.model_state = model_state\n",
    "        self.optim_state = optim_state\n",
    "        self.epoch       = epoch\n",
    "        self.batch       = batch\n",
    "        self.rng_state   = rng_state\n",
    "    def save(self, file_path):\n",
    "        torch.save({\n",
    "            \"model_state\": self.model_state,\n",
    "            \"optim_state\": self.optim_state,\n",
    "            \"epoch\"      : self.epoch,\n",
    "            \"batch\"      : self.batch,\n",
    "            \"rng_state\"  : self.rng_state\n",
    "        }, file_path)\n",
    "        print(f\"Model checkpoint saved at {file_path} at epoch {self.epoch} batch {self.batch}\")\n",
    "    @staticmethod\n",
    "    def load(file_path):\n",
    "        checkpoint = torch.load(file_path)\n",
    "        return ModelCheckpoint(checkpoint[\"model_state\"], \n",
    "                               checkpoint[\"optim_state\"], \n",
    "                               checkpoint[\"epoch\"], \n",
    "                               checkpoint[\"batch\"], \n",
    "                               checkpoint[\"rng_state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba1fdfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheckpointRandomSampler(torch.utils.data.RandomSampler):\n",
    "    def __init__(self, data_source, checkpoint: ModelCheckpoint = None):\n",
    "        super().__init__(data_source)\n",
    "        self.start_idx = 0 if checkpoint == None else checkpoint.batch\n",
    "    def __iter__(self):\n",
    "        batch_idxs = list(super().__iter__())\n",
    "        for idx in batch_idxs[self.start_idx:]:\n",
    "            yield idx\n",
    "        return\n",
    "    def __len__(self):\n",
    "        return super().__len__() - self.start_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec3c36a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, \n",
    "                   device, \n",
    "                   criterion, \n",
    "                   test_loader):\n",
    "    with torch.no_grad():\n",
    "        avg_loss = 0\n",
    "        for idx, inputs in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = inputs[:,1:]\n",
    "            outputs = model(inputs)[:,:-1,:]\n",
    "\n",
    "            targets = targets.reshape(-1)\n",
    "            outputs = outputs.reshape(-1, outputs.shape[-1])\n",
    "            \n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            avg_loss += loss\n",
    "\n",
    "        avg_loss /= len(test_loader)\n",
    "        print(f\"VALIDATE: Average Loss: {avg_loss}\")\n",
    "\n",
    "def train_model(model: nn.Module, \n",
    "                optimizer, \n",
    "                criterion, \n",
    "                device, \n",
    "                train_loader, \n",
    "                validation_loader, \n",
    "                accum_steps,\n",
    "                num_epochs: int = 4,\n",
    "                checkpoint: ModelCheckpoint = None):\n",
    "    \n",
    "    epoch = 0\n",
    "    start_batch = 0\n",
    "\n",
    "    if checkpoint != None:\n",
    "        model.load_state_dict(checkpoint.model_state)\n",
    "        optimizer.load_state_dict(checkpoint.optim_state)\n",
    "        epoch = checkpoint.epoch\n",
    "        start_batch = checkpoint.batch\n",
    "        torch.set_rng_state(checkpoint.rng_state)\n",
    "\n",
    "    print(f\"Starting training on epoch {epoch}, batch {start_batch}\")\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epoch, num_epochs):\n",
    "        start_time = time.time()\n",
    "        for idx, inputs in enumerate(train_loader):\n",
    "            batch_idx = start_batch + idx\n",
    "            inputs = inputs.to(device)\n",
    "            targets = inputs[:,1:]\n",
    "            outputs = model(inputs)[:,:-1,:]\n",
    "\n",
    "            targets = targets.reshape(-1)\n",
    "            outputs = outputs.reshape(-1, outputs.shape[-1])\n",
    "            \n",
    "            loss = criterion(outputs, targets) / accum_steps\n",
    "            loss.backward()\n",
    "\n",
    "            if (batch_idx + 1) % accum_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            if (batch_idx + 1) % (accum_steps * 4) == 0:\n",
    "                print(f\"Epoch [{epoch}].[{batch_idx}] Loss: {loss * accum_steps}\")\n",
    "\n",
    "            if (batch_idx + 1) % (accum_steps * 16) == 0:\n",
    "                elapsed_time = time.time() - start_time\n",
    "                print(f\"TIME: {elapsed_time / (accum_steps * 16)} seconds per batch\")\n",
    "                start_time = time.time()\n",
    "\n",
    "                allocated = torch.cuda.memory_allocated() / 1e9\n",
    "                reserved = torch.cuda.memory_reserved() / 1e9\n",
    "                peak = torch.cuda.max_memory_allocated() / 1e9\n",
    "                print(f\"USAGE: Allocated {allocated:.2f}GB, Reserved {reserved:.2f}GB, Peak: {peak:.2f}GB\")\n",
    "\n",
    "            if (batch_idx + 1) % (accum_steps * 32) == 0:\n",
    "                validate_model(model, device, criterion, validation_loader)\n",
    "                checkpoint = ModelCheckpoint(model.state_dict(), \n",
    "                                            optimizer.state_dict(), \n",
    "                                            epoch, \n",
    "                                            batch_idx, \n",
    "                                            torch.get_rng_state())\n",
    "                checkpoint.save(\"checkpoint.pt\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81cedc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.set_float32_matmul_precision('high')\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86c0e410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 2141709\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train+validation\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca7d5ead-bd78-46a6-82cd-cdcec26fe137",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38761c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sequence, encoder):\n",
    "    # NOTE: <EOS> token is encoder.n_vocab\n",
    "    sequence[\"text\"] = torch.tensor(encoder.encode(sequence[\"text\"]) + [encoder.n_vocab], dtype=torch.int64)\n",
    "    return sequence\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, num_proc=8, fn_kwargs={\"encoder\": encoder}).with_format(\"torch\")\n",
    "tokenized_dataset = tokenized_dataset.train_test_split(test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c17f5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tokenized_dataset[\"train\"][\"text\"]\n",
    "\n",
    "test_set = tokenized_dataset[\"test\"].train_test_split(test_size=0.001, shuffle=True)\n",
    "test = test_set[\"train\"][\"text\"]\n",
    "validation = test_set[\"test\"][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf5859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 16\n",
    "accum_steps = 2\n",
    "d_model  = 256\n",
    "d_query  = 64\n",
    "d_up = 512\n",
    "n_heads  = 4\n",
    "n_layers = 4\n",
    "\n",
    "# NOTE: add 1 for <EOS> token\n",
    "n_vocab  = encoder.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7887f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100278\n"
     ]
    }
   ],
   "source": [
    "print(n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29143c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_padding(batch):\n",
    "    batch = pad_sequence(batch, batch_first=True)\n",
    "    return batch\n",
    "\n",
    "checkpoint_path = \"checkpoint.pt\"\n",
    "\n",
    "checkpoint = None\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = ModelCheckpoint.load(checkpoint_path)\n",
    "\n",
    "\n",
    "sampler = CheckpointRandomSampler(train, checkpoint)\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=batch_size, sampler=sampler, collate_fn=collate_fn_padding)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=True, collate_fn=collate_fn_padding)\n",
    "validation_loader = DataLoader(validation, batch_size=batch_size, shuffle=True, collate_fn=collate_fn_padding)\n",
    "\n",
    "model = Transformer(n_vocab=n_vocab, \n",
    "                    d_model=d_model, \n",
    "                    d_query=d_query, \n",
    "                    n_heads=n_heads, \n",
    "                    n_layers=n_layers, \n",
    "                    d_up=d_up, \n",
    "                    device=device).to(device)\n",
    "model = torch.compile(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9788985c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on epoch 0, batch 42431\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidation_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43maccum_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccum_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 52\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, criterion, device, train_loader, validation_loader, accum_steps, num_epochs, checkpoint)\u001b[0m\n\u001b[1;32m     50\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     51\u001b[0m targets \u001b[38;5;241m=\u001b[39m inputs[:,\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m---> 52\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m[:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:]\n\u001b[1;32m     54\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     55\u001b[0m outputs \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, outputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:414\u001b[0m, in \u001b[0;36mOptimizedModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39m_has_any_global_hook():\n\u001b[1;32m    405\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `torch.compile(module)` when there are global hooks on \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    407\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodules (e.g., from `register_module_forward_hook`); this will\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    412\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    413\u001b[0m     )\n\u001b[0;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:832\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>.compile_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    829\u001b[0m _maybe_set_eval_frame(_callback_from_stance(callback))\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 832\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mverbose:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:1875\u001b[0m, in \u001b[0;36mCatchErrorsWrapper.__call__\u001b[0;34m(self, frame, cache_entry, frame_state)\u001b[0m\n\u001b[1;32m   1869\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m hijacked_callback(\n\u001b[1;32m   1870\u001b[0m                 frame, cache_entry, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhooks, frame_state\n\u001b[1;32m   1871\u001b[0m             )\n\u001b[1;32m   1873\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m compile_lock, _disable_current_modes():\n\u001b[1;32m   1874\u001b[0m     \u001b[38;5;66;03m# skip=1: skip this frame\u001b[39;00m\n\u001b[0;32m-> 1875\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_torchdynamo_orig_backend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m   1877\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:1625\u001b[0m, in \u001b[0;36mConvertFrame.__call__\u001b[0;34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[0m\n\u001b[1;32m   1623\u001b[0m counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframes\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1624\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1625\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inner_convert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1628\u001b[0m     counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframes\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:688\u001b[0m, in \u001b[0;36mConvertFrameAssert.__call__\u001b[0;34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[0m\n\u001b[1;32m    685\u001b[0m     dynamo_tls\u001b[38;5;241m.\u001b[39mtraced_frame_infos\u001b[38;5;241m.\u001b[39mappend(info)\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m compile_context(CompileContext(compile_id)):\n\u001b[0;32m--> 688\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_globals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_locals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_builtins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_torchdynamo_orig_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_one_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_export\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_export_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompile_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpackage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_package\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_frame_box\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_box\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mcaching_precompile \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_package \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    710\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpackage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DynamoCache\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:1434\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(code, globals, locals, builtins, closure, compiler_fn, one_graph, export, export_constraints, hooks, cache_entry, cache_size, frame, frame_state, compile_id, skip, package, convert_frame_box)\u001b[0m\n\u001b[1;32m   1432\u001b[0m tracer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1433\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1434\u001b[0m     guarded_code, tracer_output \u001b[38;5;241m=\u001b[39m \u001b[43mcompile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1436\u001b[0m     \u001b[38;5;66;03m# NB: We only put_code_state in success case.  Success case here\u001b[39;00m\n\u001b[1;32m   1437\u001b[0m     \u001b[38;5;66;03m# does include graph breaks; specifically, if a graph break still\u001b[39;00m\n\u001b[1;32m   1438\u001b[0m     \u001b[38;5;66;03m# resulted in a partially compiled graph, we WILL return here.  An\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1443\u001b[0m     \u001b[38;5;66;03m# to upload for graph break though, because this can prevent\u001b[39;00m\n\u001b[1;32m   1444\u001b[0m     \u001b[38;5;66;03m# extra graph break compilations.)\u001b[39;00m\n\u001b[1;32m   1445\u001b[0m     put_code_state()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_utils_internal.py:92\u001b[0m, in \u001b[0;36mcompile_time_strobelight_meta.<locals>.compile_time_strobelight_meta_inner.<locals>.wrapper_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# This is not needed but we have it here to avoid having profile_compile_time\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# in stack traces when profiling is not enabled.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m StrobelightCompileTimeProfiler\u001b[38;5;241m.\u001b[39menabled:\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m StrobelightCompileTimeProfiler\u001b[38;5;241m.\u001b[39mprofile_compile_time(\n\u001b[1;32m     95\u001b[0m     function, phase_name, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     96\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:1117\u001b[0m, in \u001b[0;36m_compile.<locals>.compile_inner\u001b[0;34m(code, one_graph, hooks)\u001b[0m\n\u001b[1;32m   1111\u001b[0m     stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[1;32m   1112\u001b[0m         torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39minstall_callbacks(\n\u001b[1;32m   1113\u001b[0m             CallbackTrigger\u001b[38;5;241m.\u001b[39mDYNAMO, \u001b[38;5;28mstr\u001b[39m(CompileContext\u001b[38;5;241m.\u001b[39mcurrent_compile_id())\n\u001b[1;32m   1114\u001b[0m         )\n\u001b[1;32m   1115\u001b[0m     )\n\u001b[1;32m   1116\u001b[0m     stack\u001b[38;5;241m.\u001b[39menter_context(CompileTimeInstructionCounter\u001b[38;5;241m.\u001b[39mrecord())\n\u001b[0;32m-> 1117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m   1120\u001b[0m     ConvertFrameReturn(),\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1122\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:1151\u001b[0m, in \u001b[0;36m_compile.<locals>._compile_inner\u001b[0;34m(code, one_graph, hooks)\u001b[0m\n\u001b[1;32m   1149\u001b[0m out_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1151\u001b[0m     dynamo_output \u001b[38;5;241m=\u001b[39m \u001b[43mcompile_frame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuiltins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompiler_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrestart_reasons\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_constraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistributed_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistributed_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpackage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mSkipFrame \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m one_graph:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:1032\u001b[0m, in \u001b[0;36mcompile_frame\u001b[0;34m(code, globals, locals, builtins, closure, compiler_fn, one_graph, restart_reasons, export, export_constraints, frame_state, distributed_state, package)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1031\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompile_attempt_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, log_pt2_compile_event\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m-> 1032\u001b[0m         bytecode, tracer_output \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_code_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1033\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m tracer_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m DynamoOutput(\n\u001b[1;32m   1035\u001b[0m             tracer_output\u001b[38;5;241m=\u001b[39mtracer_output,\n\u001b[1;32m   1036\u001b[0m             bytecode\u001b[38;5;241m=\u001b[39mbytecode,\n\u001b[1;32m   1037\u001b[0m             last_attempt_start_time\u001b[38;5;241m=\u001b[39mlast_attempt_start_time,\n\u001b[1;32m   1038\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py:1592\u001b[0m, in \u001b[0;36mtransform_code_object\u001b[0;34m(code, transformations, safe)\u001b[0m\n\u001b[1;32m   1589\u001b[0m \u001b[38;5;66;03m# propagate line nums again for added instructions\u001b[39;00m\n\u001b[1;32m   1590\u001b[0m propagate_line_nums(instructions)\n\u001b[0;32m-> 1592\u001b[0m tracer_output \u001b[38;5;241m=\u001b[39m \u001b[43mtransformations\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1593\u001b[0m _, bytecode \u001b[38;5;241m=\u001b[39m clean_and_assemble_instructions(instructions, keys, code_options)\n\u001b[1;32m   1594\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bytecode, tracer_output\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:1004\u001b[0m, in \u001b[0;36mcompile_frame.<locals>.transform\u001b[0;34m(instructions, code_options)\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m    999\u001b[0m     instructions: \u001b[38;5;28mlist\u001b[39m[Instruction], code_options: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mobject\u001b[39m]\n\u001b[1;32m   1000\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DynamoTracerOutput:\n\u001b[1;32m   1001\u001b[0m     tf_mode_stack: \u001b[38;5;28mlist\u001b[39m[torch\u001b[38;5;241m.\u001b[39moverrides\u001b[38;5;241m.\u001b[39mTorchFunctionMode] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1002\u001b[0m         torch\u001b[38;5;241m.\u001b[39moverrides\u001b[38;5;241m.\u001b[39m_get_current_function_mode_stack()\n\u001b[1;32m   1003\u001b[0m     )\n\u001b[0;32m-> 1004\u001b[0m     tracer_output \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_frame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuiltins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompiler_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtf_mode_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspeculation_log\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_constraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistributed_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistributed_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpackage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m tracer_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tracer_output\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:312\u001b[0m, in \u001b[0;36mpreserve_global_state.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m exit_stack\u001b[38;5;241m.\u001b[39menter_context(torch_function_mode_stack_state_mgr)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     cleanup\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:815\u001b[0m, in \u001b[0;36mtrace_frame\u001b[0;34m(code, globals, locals, builtins, closure, compiler_fn, tf_mode_stack, one_graph, speculation_log, instructions, code_options, export, export_constraints, frame_state, distributed_state, package)\u001b[0m\n\u001b[1;32m    812\u001b[0m         tracer\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mcall_cleanup_hooks()\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 815\u001b[0m     \u001b[43mrun_tracer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    816\u001b[0m     tracer_output \u001b[38;5;241m=\u001b[39m DynamoTracerOutput(tracer)\n\u001b[1;32m    817\u001b[0m     output \u001b[38;5;241m=\u001b[39m tracer_output\u001b[38;5;241m.\u001b[39moutput_graph\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:797\u001b[0m, in \u001b[0;36mtrace_frame.<locals>.run_tracer\u001b[0;34m()\u001b[0m\n\u001b[1;32m    795\u001b[0m     tracer\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mmark_bytecode_tracing_start()\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracing(tracer\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mtracing_context), tracer\u001b[38;5;241m.\u001b[39mset_current_tx():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mtracer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mUnspecializeRestartAnalysis:\n\u001b[1;32m    799\u001b[0m     speculation_log\u001b[38;5;241m.\u001b[39mclear()  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:1500\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_point \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstruction_pointer\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1501\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:1348\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_block_stack(inst)\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43minst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopcode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mshould_exit\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m TensorifyScalarRestartAnalysis:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:4103\u001b[0m, in \u001b[0;36mInstructionTranslator.RETURN_VALUE\u001b[0;34m(self, inst)\u001b[0m\n\u001b[1;32m   4102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mRETURN_VALUE\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: Instruction) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4103\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:4081\u001b[0m, in \u001b[0;36mInstructionTranslator._return\u001b[0;34m(self, inst)\u001b[0m\n\u001b[1;32m   4076\u001b[0m _step_logger()(\n\u001b[1;32m   4077\u001b[0m     logging\u001b[38;5;241m.\u001b[39mINFO,\n\u001b[1;32m   4078\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchdynamo done tracing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_code\u001b[38;5;241m.\u001b[39mco_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minst\u001b[38;5;241m.\u001b[39mopname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4079\u001b[0m )\n\u001b[1;32m   4080\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m triggered compile\u001b[39m\u001b[38;5;124m\"\u001b[39m, inst\u001b[38;5;241m.\u001b[39mopname)\n\u001b[0;32m-> 4081\u001b[0m all_stack_locals_metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_subgraph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4082\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreason\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGraphCompileReason\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4084\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreturn_value\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mframe_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_break\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   4085\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4086\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# the value to be returned\u001b[39;49;00m\n\u001b[1;32m   4087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack_pops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRETURN_VALUE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4088\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4089\u001b[0m \u001b[38;5;66;03m# check that our stack/locals meta are correct:\u001b[39;00m\n\u001b[1;32m   4090\u001b[0m \u001b[38;5;66;03m# we should only be tracing 1 frame, and there should not be any NULLs on the stack\u001b[39;00m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(all_stack_locals_metadata) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/output_graph.py:1568\u001b[0m, in \u001b[0;36mOutputGraph.compile_subgraph\u001b[0;34m(self, tx, reason, partial_convert, stack_pops)\u001b[0m\n\u001b[1;32m   1565\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m count_calls(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pass2\u001b[38;5;241m.\u001b[39mgraph_outputs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1567\u001b[0m     output\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m-> 1568\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_and_call_fx_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpass2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_output_vars\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1569\u001b[0m     )\n\u001b[1;32m   1571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pass2\u001b[38;5;241m.\u001b[39mgraph_outputs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1572\u001b[0m         output\u001b[38;5;241m.\u001b[39mappend(pass2\u001b[38;5;241m.\u001b[39mcreate_store(graph_output_var))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/output_graph.py:2013\u001b[0m, in \u001b[0;36mOutputGraph.compile_and_call_fx_graph\u001b[0;34m(self, tx, rv, root)\u001b[0m\n\u001b[1;32m   2010\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracing_context\u001b[38;5;241m.\u001b[39mfake_mode \u001b[38;5;241m=\u001b[39m backend_fake_mode\n\u001b[1;32m   2012\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestore_global_state():\n\u001b[0;32m-> 2013\u001b[0m     compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_user_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexample_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2015\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lazy_graph_module\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _LazyGraphModule\n\u001b[1;32m   2017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(compiled_fn, _LazyGraphModule) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   2018\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(compiled_fn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), _LazyGraphModule)\n\u001b[1;32m   2019\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m compiled_fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_lazy_forward\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2023\u001b[0m     \u001b[38;5;66;03m# this is a _LazyGraphModule. This makes it easier for dynamo to\u001b[39;00m\n\u001b[1;32m   2024\u001b[0m     \u001b[38;5;66;03m# optimize a _LazyGraphModule.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/output_graph.py:2136\u001b[0m, in \u001b[0;36mOutputGraph.call_user_compiler\u001b[0;34m(self, gm, example_inputs)\u001b[0m\n\u001b[1;32m   2125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_user_compiler\u001b[39m(\n\u001b[1;32m   2126\u001b[0m     \u001b[38;5;28mself\u001b[39m, gm: fx\u001b[38;5;241m.\u001b[39mGraphModule, example_inputs: \u001b[38;5;28mlist\u001b[39m[Tensor]\n\u001b[1;32m   2127\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CompiledFn:\n\u001b[1;32m   2128\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\n\u001b[1;32m   2129\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutputGraph.call_user_compiler\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2130\u001b[0m         phase_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackend_compile\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2134\u001b[0m         dynamo_compile_column_us\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maot_autograd_cumulative_compile_time_us\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2135\u001b[0m     ):\n\u001b[0;32m-> 2136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_user_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/output_graph.py:2171\u001b[0m, in \u001b[0;36mOutputGraph._call_user_compiler\u001b[0;34m(self, gm, example_inputs)\u001b[0m\n\u001b[1;32m   2169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mverify_correctness:\n\u001b[1;32m   2170\u001b[0m     compiler_fn \u001b[38;5;241m=\u001b[39m WrapperBackend(compiler_fn)\n\u001b[0;32m-> 2171\u001b[0m compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2172\u001b[0m _step_logger()(logging\u001b[38;5;241m.\u001b[39mINFO, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone compiler function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2173\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(compiled_fn), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiler_fn did not return callable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/repro/after_dynamo.py:156\u001b[0m, in \u001b[0;36mWrapBackendDebug.__call__\u001b[0;34m(self, gm, example_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     compiled_gm \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_gm\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/__init__.py:2392\u001b[0m, in \u001b[0;36m_TorchCompileInductorWrapper.__call__\u001b[0;34m(self, model_, inputs_)\u001b[0m\n\u001b[1;32m   2389\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_, inputs_):\n\u001b[1;32m   2390\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inductor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompile_fx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compile_fx\n\u001b[0;32m-> 2392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompile_fx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_patches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:2681\u001b[0m, in \u001b[0;36mcompile_fx\u001b[0;34m(model_, example_inputs_, inner_compile, config_patches, decompositions, ignore_shape_env)\u001b[0m\n\u001b[1;32m   2674\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (\n\u001b[1;32m   2675\u001b[0m     V\u001b[38;5;241m.\u001b[39mset_fake_mode(fake_mode),\n\u001b[1;32m   2676\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_guards\u001b[38;5;241m.\u001b[39mtracing(tracing_context),\n\u001b[1;32m   2677\u001b[0m     compiled_autograd\u001b[38;5;241m.\u001b[39m_disable(),\n\u001b[1;32m   2678\u001b[0m     functorch_config\u001b[38;5;241m.\u001b[39mpatch(unlift_effect_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m   2679\u001b[0m ):\n\u001b[1;32m   2680\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2681\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43maot_autograd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2682\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfw_compiler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfw_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2683\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbw_compiler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbw_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2684\u001b[0m \u001b[43m            \u001b[49m\u001b[43minference_compiler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2685\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecompositions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecompositions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2686\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpartition_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2687\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_inference_input_mutations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2688\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompiler_config_extra\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudagraphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2689\u001b[0m \u001b[43m            \u001b[49m\u001b[43mboxed_forward_device_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompiler_config_extra\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2690\u001b[0m \u001b[43m            \u001b[49m\u001b[43mignore_shape_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_shape_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2691\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2692\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ShortenTraceback \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2693\u001b[0m         \u001b[38;5;66;03m# We will also shorten the traceback inside dynamo.\u001b[39;00m\n\u001b[1;32m   2694\u001b[0m         \u001b[38;5;66;03m# This is only useful if inductor is called directly with an FX graph.\u001b[39;00m\n\u001b[1;32m   2695\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mremove_dynamo_frames() \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/backends/common.py:117\u001b[0m, in \u001b[0;36mAotAutograd.__call__\u001b[0;34m(self, gm, example_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# NB: NOT cloned!\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m enable_aot_logging(), patch_config:\n\u001b[0;32m--> 117\u001b[0m         cg \u001b[38;5;241m=\u001b[39m \u001b[43maot_module_simplified\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m         counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maot_autograd\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m disable(cg, reason\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo not trace AOT-compiled graph\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:1106\u001b[0m, in \u001b[0;36maot_module_simplified\u001b[0;34m(mod, args, fw_compiler, bw_compiler, partition_fn, decompositions, keep_inference_input_mutations, inference_compiler, cudagraphs, boxed_forward_device_index, ignore_shape_env)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         aot_state \u001b[38;5;241m=\u001b[39m create_aot_state(\n\u001b[1;32m   1097\u001b[0m             stack,\n\u001b[1;32m   1098\u001b[0m             functional_call,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1103\u001b[0m             shape_env,\n\u001b[1;32m   1104\u001b[0m         )\n\u001b[1;32m   1105\u001b[0m         aot_graph_capture \u001b[38;5;241m=\u001b[39m aot_stage1_graph_capture(aot_state, functional_call)\n\u001b[0;32m-> 1106\u001b[0m         compiled_fn, _ \u001b[38;5;241m=\u001b[39m \u001b[43maot_stage2_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43maot_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maot_graph_capture\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mod, torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mGmWrapper):\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;66;03m# This function is called by the flatten_graph_inputs wrapper, which boxes\u001b[39;00m\n\u001b[1;32m   1110\u001b[0m     \u001b[38;5;66;03m# the inputs so that they can be freed before the end of this scope.\u001b[39;00m\n\u001b[1;32m   1111\u001b[0m     \u001b[38;5;66;03m# For overhead reasons, this is not the default wrapper, see comment:\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m     \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/pull/122535/files#r1560096481\u001b[39;00m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(runtime_args: \u001b[38;5;28mlist\u001b[39m[Any]):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/graph_compile.py:240\u001b[0m, in \u001b[0;36maot_stage2_compile\u001b[0;34m(aot_state, aot_graph_capture)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maot_stage2_compile\u001b[39m(\n\u001b[1;32m    236\u001b[0m     aot_state: AOTState,\n\u001b[1;32m    237\u001b[0m     aot_graph_capture: AOTGraphCapture,\n\u001b[1;32m    238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DispatchReturn:\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m aot_state\u001b[38;5;241m.\u001b[39mneeds_autograd \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m aot_state\u001b[38;5;241m.\u001b[39maot_config\u001b[38;5;241m.\u001b[39mpre_dispatch:\n\u001b[0;32m--> 240\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43maot_stage2_autograd\u001b[49m\u001b[43m(\u001b[49m\u001b[43maot_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maot_graph_capture\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m aot_stage2_inference(aot_state, aot_graph_capture)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/graph_compile.py:1675\u001b[0m, in \u001b[0;36maot_stage2_autograd\u001b[0;34m(aot_state, aot_graph_capture)\u001b[0m\n\u001b[1;32m   1672\u001b[0m     tracing_context\u001b[38;5;241m.\u001b[39mfw_metadata \u001b[38;5;241m=\u001b[39m inner_meta\n\u001b[1;32m   1674\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m TracingContext\u001b[38;5;241m.\u001b[39mreport_output_strides() \u001b[38;5;28;01mas\u001b[39;00m fwd_output_strides:\n\u001b[0;32m-> 1675\u001b[0m     compiled_fw_func \u001b[38;5;241m=\u001b[39m \u001b[43maot_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfw_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfw_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjusted_flat_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(compiled_fw_func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_boxed_call\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1678\u001b[0m     compiled_fw_func \u001b[38;5;241m=\u001b[39m make_boxed_func(compiled_fw_func)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/schemas.py:1251\u001b[0m, in \u001b[0;36mSerializableAOTDispatchCompiler.__call__\u001b[0;34m(self, gm, example_inputs)\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1248\u001b[0m     gm: torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39mGraphModule,\n\u001b[1;32m   1249\u001b[0m     example_inputs: Sequence[InputType],\n\u001b[1;32m   1250\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutputCode:\n\u001b[0;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:2558\u001b[0m, in \u001b[0;36mcompile_fx.<locals>.fw_compiler_base\u001b[0;34m(gm, example_inputs, is_inference)\u001b[0m\n\u001b[1;32m   2556\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2557\u001b[0m     num_orig_model_outputs \u001b[38;5;241m=\u001b[39m get_num_model_outputs(gm)\n\u001b[0;32m-> 2558\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompile_fx_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_orig_model_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_orig_model_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_example_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_example_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiler_config_extra\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompiler_config_extra\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2564\u001b[0m \u001b[43m    \u001b[49m\u001b[43minner_compile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_compile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_inference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_inference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2566\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:2275\u001b[0m, in \u001b[0;36mcompile_fx_forward\u001b[0;34m(gm, example_inputs, num_orig_model_outputs, num_example_inputs, compiler_config_extra, inner_compile, is_inference)\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[38;5;66;03m# We also mark the invoke_subgraph outputs as user_visible to\u001b[39;00m\n\u001b[1;32m   2271\u001b[0m \u001b[38;5;66;03m# force the outputs of invoke_subgraph subgraph to follow the\u001b[39;00m\n\u001b[1;32m   2272\u001b[0m \u001b[38;5;66;03m# original strides\u001b[39;00m\n\u001b[1;32m   2273\u001b[0m _recursive_record_user_visible_output_idxs(gm)\n\u001b[0;32m-> 2275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_input_idxs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_static_input_idxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfixed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompiler_config_extra\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudagraphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompiler_config_extra\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_inference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_inference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mboxed_forward_device_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompiler_config_extra\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:782\u001b[0m, in \u001b[0;36mcompile_fx_inner\u001b[0;34m(gm, example_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m stack\u001b[38;5;241m.\u001b[39menter_context(DebugContext())\n\u001b[1;32m    778\u001b[0m CompileEventLogger\u001b[38;5;241m.\u001b[39mpt2_compile(\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minductor_compile\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    780\u001b[0m     is_backward\u001b[38;5;241m=\u001b[39mkwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_backward\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    781\u001b[0m )\n\u001b[0;32m--> 782\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrap_compiler_debug\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_compile_fx_inner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompiler_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minductor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/repro/after_aot.py:144\u001b[0m, in \u001b[0;36mwrap_compiler_debug.<locals>.debug_wrapper\u001b[0;34m(gm, example_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m config\u001b[38;5;241m.\u001b[39mrepro_after \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdynamo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maot\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;66;03m# Call the compiler_fn - which is either aot_autograd or inductor\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# with fake inputs\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     inner_compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# TODO: Failures here are troublesome because no real inputs,\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;66;03m# need a different serialization strategy\u001b[39;00m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mrepro_after \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maot\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:974\u001b[0m, in \u001b[0;36m_compile_fx_inner\u001b[0;34m(gm, example_inputs, **graph_kwargs)\u001b[0m\n\u001b[1;32m    972\u001b[0m TritonBundler\u001b[38;5;241m.\u001b[39mbegin_compile()\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 974\u001b[0m     mb_compiled_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfx_codegen_and_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_to_check\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgraph_kwargs\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m mb_compiled_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    978\u001b[0m     mb_compiled_graph\u001b[38;5;241m.\u001b[39m_time_taken_ns \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime_ns() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:1695\u001b[0m, in \u001b[0;36mfx_codegen_and_compile\u001b[0;34m(gm, example_inputs, inputs_to_check, **graph_kwargs)\u001b[0m\n\u001b[1;32m   1691\u001b[0m     fast_scheme \u001b[38;5;241m=\u001b[39m _InProcessFxCompile()\n\u001b[1;32m   1693\u001b[0m     scheme \u001b[38;5;241m=\u001b[39m _ProgressiveFxCompile(fast_scheme, scheme, progression_configs)\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscheme\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodegen_and_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_to_check\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:1505\u001b[0m, in \u001b[0;36m_InProcessFxCompile.codegen_and_compile\u001b[0;34m(self, gm, example_inputs, inputs_to_check, graph_kwargs)\u001b[0m\n\u001b[1;32m   1487\u001b[0m         compiled_fn \u001b[38;5;241m=\u001b[39m AotCodeCompiler\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m   1488\u001b[0m             graph,\n\u001b[1;32m   1489\u001b[0m             wrapper_code\u001b[38;5;241m.\u001b[39mvalue,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1502\u001b[0m             ],\n\u001b[1;32m   1503\u001b[0m         )\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1505\u001b[0m     compiled_module \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_to_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1506\u001b[0m     compiled_fn \u001b[38;5;241m=\u001b[39m compiled_module\u001b[38;5;241m.\u001b[39mcall\n\u001b[1;32m   1507\u001b[0m     compiled_fn_runner \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[1;32m   1508\u001b[0m         compiled_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrunner\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_inductor/graph.py:2319\u001b[0m, in \u001b[0;36mGraphLowering.compile_to_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompile_to_module\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CompiledModule:\n\u001b[1;32m   2313\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\n\u001b[1;32m   2314\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraphLowering.compile_to_module\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2315\u001b[0m         phase_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_gen\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2316\u001b[0m         log_pt2_compile_event\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2317\u001b[0m         dynamo_compile_column_us\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minductor_code_gen_cumulative_compile_time_us\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2318\u001b[0m     ):\n\u001b[0;32m-> 2319\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compile_to_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_inductor/graph.py:2325\u001b[0m, in \u001b[0;36mGraphLowering._compile_to_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compile_to_module\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CompiledModule:\n\u001b[1;32m   2322\u001b[0m     \u001b[38;5;66;03m# If we're here, we don't have to worry about the kernel code, which is only\u001b[39;00m\n\u001b[1;32m   2323\u001b[0m     \u001b[38;5;66;03m# returned separately in AOTInductor mode.\u001b[39;00m\n\u001b[1;32m   2324\u001b[0m     wrapper_code, _ \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 2325\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodegen_with_cpp_wrapper() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcpp_wrapper \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodegen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2326\u001b[0m     )\n\u001b[1;32m   2328\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(wrapper_code, ValueWithLineMap):\n\u001b[1;32m   2329\u001b[0m         mod \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compile_to_module_lines(wrapper_code)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_inductor/graph.py:2260\u001b[0m, in \u001b[0;36mGraphLowering.codegen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2257\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraphLowering.codegen\u001b[39m\u001b[38;5;124m\"\u001b[39m, log_pt2_compile_event\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   2258\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_wrapper_code()\n\u001b[0;32m-> 2260\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_scheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2261\u001b[0m     V\u001b[38;5;241m.\u001b[39mdebug\u001b[38;5;241m.\u001b[39mdraw_orig_fx_graph(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_gm, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mnodes)\n\u001b[1;32m   2263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapper_code\u001b[38;5;241m.\u001b[39mpush_codegened_graph(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_inductor/graph.py:2254\u001b[0m, in \u001b[0;36mGraphLowering._update_scheduler\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2251\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscheduler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Scheduler\n\u001b[1;32m   2253\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config\u001b[38;5;241m.\u001b[39mpatch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtriton.store_cubin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 2254\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler \u001b[38;5;241m=\u001b[39m \u001b[43mScheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperations\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_inductor/scheduler.py:2226\u001b[0m, in \u001b[0;36mScheduler.__init__\u001b[0;34m(self, nodes)\u001b[0m\n\u001b[1;32m   2224\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, nodes: \u001b[38;5;28mlist\u001b[39m[ir\u001b[38;5;241m.\u001b[39mOperation]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2225\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScheduler.__init__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 2226\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_inductor/scheduler.py:2244\u001b[0m, in \u001b[0;36mScheduler._init\u001b[0;34m(self, nodes)\u001b[0m\n\u001b[1;32m   2235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompleted_operations: OrderedSet[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m OrderedSet()\n\u001b[1;32m   2236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavailable_buffer_names \u001b[38;5;241m=\u001b[39m OrderedSet(\n\u001b[1;32m   2237\u001b[0m     [\n\u001b[1;32m   2238\u001b[0m         \u001b[38;5;241m*\u001b[39mV\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mgraph_inputs\u001b[38;5;241m.\u001b[39mkeys(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2241\u001b[0m     ]\n\u001b[1;32m   2242\u001b[0m )\n\u001b[0;32m-> 2244\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_scheduler_node(n) \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m nodes]\n\u001b[1;32m   2245\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_node: Optional[BaseSchedulerNode] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2246\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_zero_dim_cpu_tensor()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_inductor/scheduler.py:2244\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompleted_operations: OrderedSet[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m OrderedSet()\n\u001b[1;32m   2236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavailable_buffer_names \u001b[38;5;241m=\u001b[39m OrderedSet(\n\u001b[1;32m   2237\u001b[0m     [\n\u001b[1;32m   2238\u001b[0m         \u001b[38;5;241m*\u001b[39mV\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mgraph_inputs\u001b[38;5;241m.\u001b[39mkeys(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2241\u001b[0m     ]\n\u001b[1;32m   2242\u001b[0m )\n\u001b[0;32m-> 2244\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_scheduler_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m nodes]\n\u001b[1;32m   2245\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_node: Optional[BaseSchedulerNode] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2246\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_zero_dim_cpu_tensor()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_inductor/scheduler.py:2442\u001b[0m, in \u001b[0;36mScheduler.create_scheduler_node\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m   2440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NopKernelSchedulerNode(\u001b[38;5;28mself\u001b[39m, node)\n\u001b[1;32m   2441\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, (ir\u001b[38;5;241m.\u001b[39mComputedBuffer, ir\u001b[38;5;241m.\u001b[39mTemplateBuffer)):\n\u001b[0;32m-> 2442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSchedulerNode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2443\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, ir\u001b[38;5;241m.\u001b[39mExternKernel):\n\u001b[1;32m   2444\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ExternKernelSchedulerNode(\u001b[38;5;28mself\u001b[39m, node)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_inductor/scheduler.py:1149\u001b[0m, in \u001b[0;36mSchedulerNode.__init__\u001b[0;34m(self, scheduler, node)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(scheduler)\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_from_node(node)\n\u001b[0;32m-> 1149\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_attrs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_inductor/scheduler.py:1157\u001b[0m, in \u001b[0;36mSchedulerNode._compute_attrs\u001b[0;34m(self, extra_indexing_constraints, recompute_sizes_body_func)\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute_attrs\u001b[39m(\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1153\u001b[0m     extra_indexing_constraints: Optional[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mdict\u001b[39m[Any, Any], \u001b[38;5;28mlist\u001b[39m[Any]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1154\u001b[0m     recompute_sizes_body_func: Optional[Callable[_P, _T]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1155\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode, (ir\u001b[38;5;241m.\u001b[39mComputedBuffer, ir\u001b[38;5;241m.\u001b[39mTemplateBuffer))\n\u001b[0;32m-> 1157\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sizes, body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimplify_and_reorder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_indexing_constraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_indexing_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrecompute_sizes_body_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecompute_sizes_body_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_body \u001b[38;5;241m=\u001b[39m body  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m   1163\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode\u001b[38;5;241m.\u001b[39mget_device_or_error()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_inductor/ir.py:4735\u001b[0m, in \u001b[0;36mComputedBuffer.simplify_and_reorder\u001b[0;34m(self, extra_indexing_constraints, recompute_sizes_body_func)\u001b[0m\n\u001b[1;32m   4709\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimplify_and_reorder\u001b[39m(\n\u001b[1;32m   4710\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4711\u001b[0m     extra_indexing_constraints: Optional[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mdict\u001b[39m[Any, Any], \u001b[38;5;28mlist\u001b[39m[Any]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4712\u001b[0m     recompute_sizes_body_func: Optional[Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4713\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mlist\u001b[39m[Expr], \u001b[38;5;28mlist\u001b[39m[Expr]], Optional[LoopBody]]:\n\u001b[1;32m   4714\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4715\u001b[0m \u001b[38;5;124;03m    This is a main place where we do loop transformations in a\u001b[39;00m\n\u001b[1;32m   4716\u001b[0m \u001b[38;5;124;03m    backend-agnostic way.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4729\u001b[0m \u001b[38;5;124;03m    on the default body. This can be useful to append additional loop transformations.\u001b[39;00m\n\u001b[1;32m   4730\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4731\u001b[0m     (\n\u001b[1;32m   4732\u001b[0m         (index_size, reduce_size),\n\u001b[1;32m   4733\u001b[0m         body,\n\u001b[1;32m   4734\u001b[0m         (index_vars, reduce_vars),\n\u001b[0;32m-> 4735\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default_sizes_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4737\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recompute_sizes_body_func:\n\u001b[1;32m   4738\u001b[0m         (\n\u001b[1;32m   4739\u001b[0m             (index_size, reduce_size),\n\u001b[1;32m   4740\u001b[0m             body,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4743\u001b[0m             (index_size, reduce_size), body, (index_vars, reduce_vars)\n\u001b[1;32m   4744\u001b[0m         )\n",
      "File \u001b[0;32m<string>:6\u001b[0m, in \u001b[0;36mget_default_sizes_body_cache_on_self\u001b[0;34m(self)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_inductor/ir.py:4688\u001b[0m, in \u001b[0;36mComputedBuffer.get_default_sizes_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4684\u001b[0m args, var_ranges \u001b[38;5;241m=\u001b[39m dependencies\u001b[38;5;241m.\u001b[39mindex_vars_squeeze(\n\u001b[1;32m   4685\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mget_pointwise_size(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mget_reduction_size(), prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4686\u001b[0m )\n\u001b[1;32m   4687\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m patch\u001b[38;5;241m.\u001b[39mobject(ConstantBuffer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverride_device\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_device()):\n\u001b[0;32m-> 4688\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[43mLoopBody\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4689\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_store_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4690\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_reduction_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar_ranges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4692\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4693\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4694\u001b[0m index_vars \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   4695\u001b[0m reduce_vars: \u001b[38;5;28mlist\u001b[39m[Any] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_inductor/loop_body.py:122\u001b[0m, in \u001b[0;36mLoopBody.__init__\u001b[0;34m(self, fn, args, var_ranges, iter_vars, reduce_vars)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_with_copy(fn, args)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_with_tracing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindexing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_inductor/loop_body.py:136\u001b[0m, in \u001b[0;36mLoopBody._init_with_tracing\u001b[0;34m(self, fn, args)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory_usage \u001b[38;5;241m=\u001b[39m {t: [] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m MemoryUsageType}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mop_counts \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mCounter()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_block \u001b[38;5;241m=\u001b[39m \u001b[43mLoopBodyBlock\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# traces\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindexing_exprs_name\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_inductor/loop_body.py:527\u001b[0m, in \u001b[0;36mLoopBodyBlock.__init__\u001b[0;34m(self, body, fn, args)\u001b[0m\n\u001b[1;32m    522\u001b[0m handler: Any \u001b[38;5;241m=\u001b[39m CountOps(\n\u001b[1;32m    523\u001b[0m     CaptureIndexing(proxy_ops, body, tracer),\n\u001b[1;32m    524\u001b[0m     body\u001b[38;5;241m.\u001b[39mop_counts,\n\u001b[1;32m    525\u001b[0m )\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mconstant_and_index_propagation:\n\u001b[0;32m--> 527\u001b[0m     handler \u001b[38;5;241m=\u001b[39m \u001b[43mIndexPropagation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_ranges\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindirect_var_ranges\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m V\u001b[38;5;241m.\u001b[39mset_ops_handler(handler):\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;66;03m# This indirection is just a cute way to get IndexPropagation to\u001b[39;00m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;66;03m# unwrap the return value.\u001b[39;00m\n\u001b[1;32m    534\u001b[0m     ops\u001b[38;5;241m.\u001b[39moutput(fn(\u001b[38;5;241m*\u001b[39margs))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_inductor/index_propagation.py:219\u001b[0m, in \u001b[0;36mIndexPropagation.__init__\u001b[0;34m(self, inner, iter_ranges, indirect_var_ranges)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner \u001b[38;5;241m=\u001b[39m inner\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_env \u001b[38;5;241m=\u001b[39m V\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39msizevars\u001b[38;5;241m.\u001b[39mshape_env\n\u001b[0;32m--> 219\u001b[0m var_to_range \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    220\u001b[0m     k: ValueRanges(\u001b[38;5;241m0\u001b[39m, upper_bound(v) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m iter_ranges\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    221\u001b[0m }\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_to_range \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    223\u001b[0m     itertools\u001b[38;5;241m.\u001b[39mchain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_env\u001b[38;5;241m.\u001b[39mvar_to_range\u001b[38;5;241m.\u001b[39mitems(), var_to_range\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m    224\u001b[0m )\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# NOTE: this is intentionally kept as a reference so the caller can\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# update it in-place\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_inductor/index_propagation.py:220\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner \u001b[38;5;241m=\u001b[39m inner\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_env \u001b[38;5;241m=\u001b[39m V\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39msizevars\u001b[38;5;241m.\u001b[39mshape_env\n\u001b[1;32m    219\u001b[0m var_to_range \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m--> 220\u001b[0m     k: ValueRanges(\u001b[38;5;241m0\u001b[39m, \u001b[43mupper_bound\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m iter_ranges\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    221\u001b[0m }\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_to_range \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    223\u001b[0m     itertools\u001b[38;5;241m.\u001b[39mchain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_env\u001b[38;5;241m.\u001b[39mvar_to_range\u001b[38;5;241m.\u001b[39mitems(), var_to_range\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m    224\u001b[0m )\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# NOTE: this is intentionally kept as a reference so the caller can\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# update it in-place\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_inductor/index_propagation.py:53\u001b[0m, in \u001b[0;36mupper_bound\u001b[0;34m(val)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupper_bound\u001b[39m(val: _ExprType):\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound_sympy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mupper \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, sympy\u001b[38;5;241m.\u001b[39mExpr) \u001b[38;5;28;01melse\u001b[39;00m val\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_sympy/value_ranges.py:1016\u001b[0m, in \u001b[0;36mbound_sympy\u001b[0;34m(expr, ranges)\u001b[0m\n\u001b[1;32m   1001\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m   1002\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbound_sympy(\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1003\u001b[0m     expr,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     ),\n\u001b[1;32m   1014\u001b[0m )\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(expr, sympy\u001b[38;5;241m.\u001b[39mNumber):\n\u001b[0;32m-> 1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mValueRanges\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1018\u001b[0m ranges \u001b[38;5;241m=\u001b[39m ranges \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;66;03m# If there's a tracing context, augment available constrained ranges.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_sympy/value_ranges.py:330\u001b[0m, in \u001b[0;36mValueRanges.wrap\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ValueRanges\u001b[38;5;241m.\u001b[39munknown()\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# arg is either ExprIn or BoolIn, but we don't know it here\u001b[39;00m\n\u001b[0;32m--> 330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mValueRanges\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_sympy/value_ranges.py:162\u001b[0m, in \u001b[0;36mValueRanges.__init__\u001b[0;34m(self, lower, upper)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# TODO: when the bounds have free variables, this may be\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# nontrivial to actually verify\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43msympy_generic_le\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupper\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ValueRangeError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid ranges [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlower\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mupper\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_sympy/value_ranges.py:93\u001b[0m, in \u001b[0;36msympy_generic_le\u001b[0;34m(lower, upper)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(upper, sympy\u001b[38;5;241m.\u001b[39mExpr)\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# instead of lower <= upper, we do upper >= lower since upper is mostly int_oo\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;66;03m# and we have better code paths there.\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mupper\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlower\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# only negative condition is True > False\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(lower, SympyBoolean) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(upper, SympyBoolean), (\n\u001b[1;32m     97\u001b[0m         lower,\n\u001b[1;32m     98\u001b[0m         upper,\n\u001b[1;32m     99\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sympy/core/numbers.py:1999\u001b[0m, in \u001b[0;36mInteger.__ge__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1997\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mis_Integer:\n\u001b[0;32m-> 1999\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sympify\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2000\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Rational\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__ge__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sympy/core/sympify.py:540\u001b[0m, in \u001b[0;36m_sympify\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sympify\u001b[39m(a):\n\u001b[1;32m    515\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;124;03m    Short version of :func:`~.sympify` for internal usage for ``__add__`` and\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;124;03m    ``__eq__`` methods where it is ok to allow some things (like Python\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m \n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msympify\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sympy/core/sympify.py:420\u001b[0m, in \u001b[0;36msympify\u001b[0;34m(a, locals, convert_xor, strict, rational, evaluate)\u001b[0m\n\u001b[1;32m    417\u001b[0m conv \u001b[38;5;241m=\u001b[39m _external_converter\u001b[38;5;241m.\u001b[39mget(superclass)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;66;03m#if none exists, check for SymPy defined converters\u001b[39;00m\n\u001b[0;32m--> 420\u001b[0m     conv \u001b[38;5;241m=\u001b[39m \u001b[43m_sympy_converter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43msuperclass\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m conv(a)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(model=model, \n",
    "            optimizer=optimizer, \n",
    "            criterion=criterion, \n",
    "            device=device, \n",
    "            train_loader=train_loader, \n",
    "            validation_loader=validation_loader, \n",
    "            accum_steps=accum_steps,\n",
    "            checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482a1d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(model, encoder: tiktoken.Encoding, device: torch.device, prompt: str):\n",
    "    sequence = encoder.encode(prompt)\n",
    "    with torch.no_grad():\n",
    "        num_chars = 0\n",
    "        end_sequence = False\n",
    "        while end_sequence == False:\n",
    "            input = torch.tensor(sequence, dtype=torch.int64).unsqueeze(0).to(device)\n",
    "            output = model(input)\n",
    "            output = output[0,-1,:].argmax().item()\n",
    "\n",
    "            num_chars += 1\n",
    "            if num_chars >= 1000:\n",
    "                end_sequence = True\n",
    "                \n",
    "            if output == n_vocab + 1:\n",
    "                end_sequence = True\n",
    "            else:\n",
    "                sequence = sequence + [output]\n",
    "                \n",
    "        response = encoder.decode(sequence)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a0324ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15339]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.encode(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6150ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Invalid token for decoding: 100277'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint\u001b[38;5;241m.\u001b[39mmodel_state)\n\u001b[1;32m      4\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTell me a story about a hungry man\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "Cell \u001b[0;32mIn[23], line 20\u001b[0m, in \u001b[0;36mgenerate_response\u001b[0;34m(model, encoder, device, prompt)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m         sequence \u001b[38;5;241m=\u001b[39m sequence \u001b[38;5;241m+\u001b[39m [output]\n\u001b[0;32m---> 20\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tiktoken/core.py:284\u001b[0m, in \u001b[0;36mEncoding.decode\u001b[0;34m(self, tokens, errors)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokens: Sequence[\u001b[38;5;28mint\u001b[39m], errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    273\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decodes a list of tokens into a string.\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m    WARNING: the default behaviour of this function is lossy, since decoded bytes are not\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_core_bpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m, errors\u001b[38;5;241m=\u001b[39merrors)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Invalid token for decoding: 100277'"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint.load(\"checkpoint.pt\")\n",
    "model.load_state_dict(checkpoint.model_state)\n",
    "\n",
    "prompt = \"Tell me a story about a hungry man!\"\n",
    "\n",
    "response = generate_response(model, encoder=encoder, device=device, prompt=prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "290fcfba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100277"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d82d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(encoder.encode(\"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
