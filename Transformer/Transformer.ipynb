{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "956cde40-5eaa-4466-a6be-0a4f10b22222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchvision.transforms import v2\n",
    "from datasets import load_dataset\n",
    "import tiktoken\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac2d5eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from https://pytorch-tutorials-preview.netlify.app/beginner/transformer_tutorial.html\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 d_model: int, \n",
    "                 dropout: float = 0.1, \n",
    "                 max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(1, max_len, d_model)\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[batch_size, seq_len, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0ae2853",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, \n",
    "                 d_model: int, \n",
    "                 d_query: int = 128, \n",
    "                 n_heads: int = 8,\n",
    "                 device: torch.device = torch.device(\"cpu\")):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_query)\n",
    "        self.W_k = nn.Linear(d_model, d_query)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.scaling_factor = math.sqrt(d_query)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        q = self.W_q(x)\n",
    "        k = self.W_k(x)\n",
    "        v = self.W_v(x)\n",
    "\n",
    "        attention_pattern = torch.matmul(q, torch.transpose(k, 1, 2)) / self.scaling_factor\n",
    "        \n",
    "        seq_len = attention_pattern.shape[-1]\n",
    "        mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool().to(self.device)\n",
    "        attention_pattern = torch.masked_fill(attention_pattern, mask, float(\"-inf\"))\n",
    "\n",
    "        attention_pattern = self.softmax(attention_pattern)\n",
    "\n",
    "        output = torch.matmul(attention_pattern, v)\n",
    "        \n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd25bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron(nn.Module):\n",
    "    def __init__(self, \n",
    "                 d_model: int, \n",
    "                 d_up: int = 256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.Linear(d_model, d_up)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.down = nn.Linear(d_up, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        output = self.up(x)\n",
    "        output = self.relu(output)\n",
    "        output = self.down(output)\n",
    "\n",
    "        output = output + x\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7cbf8aa-4165-4b6f-963d-f1bbb138d0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 n_vocab: int, \n",
    "                 d_model: int = 128, \n",
    "                 d_query: int = 128, \n",
    "                 n_heads: int = 8, \n",
    "                 n_layers: int = 4, \n",
    "                 d_up: int = 256,\n",
    "                 device: torch.device = torch.device(\"cpu\")):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(n_vocab, d_model)\n",
    "        self.pe = PositionalEncoding(d_model, max_len=50000)\n",
    "\n",
    "        self.attention_layers = nn.ModuleList([layer for _ in range(n_layers) for layer in \n",
    "                                               (SelfAttention(d_model, d_query, n_heads, device), \n",
    "                                                nn.LayerNorm(d_model),\n",
    "                                                MultilayerPerceptron(d_model, d_up))])\n",
    "\n",
    "        # self.self_attention = SelfAttention(d_model, d_query, n_heads, device)\n",
    "        # self.mlp = MultilayerPerceptron(d_model, d_up)\n",
    "\n",
    "        self.unembedding = nn.Linear(d_model, n_vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.pe(x)\n",
    "\n",
    "        for layer in self.attention_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        x = self.unembedding(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa09e45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelCheckpoint():\n",
    "    def __init__(self, model_state, optim_state, epoch: int, batch: int, rng_state: torch.Tensor):\n",
    "        self.model_state = model_state\n",
    "        self.optim_state = optim_state\n",
    "        self.epoch       = epoch\n",
    "        self.batch       = batch\n",
    "        self.rng_state   = rng_state\n",
    "    def save(self, file_path):\n",
    "        torch.save({\n",
    "            \"model_state\": self.model_state,\n",
    "            \"optim_state\": self.optim_state,\n",
    "            \"epoch\"      : self.epoch,\n",
    "            \"batch\"      : self.batch,\n",
    "            \"rng_state\"  : self.rng_state\n",
    "        }, file_path)\n",
    "        print(f\"Model checkpoint saved at {file_path} at epoch {self.epoch} batch {self.batch}\")\n",
    "    @staticmethod\n",
    "    def load(file_path):\n",
    "        checkpoint = torch.load(file_path)\n",
    "        return ModelCheckpoint(checkpoint[\"model_state\"], \n",
    "                               checkpoint[\"optim_state\"], \n",
    "                               checkpoint[\"epoch\"], \n",
    "                               checkpoint[\"batch\"], \n",
    "                               checkpoint[\"rng_state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec3c36a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, \n",
    "                   device, \n",
    "                   criterion, \n",
    "                   test_loader):\n",
    "    with torch.no_grad():\n",
    "        avg_loss = 0\n",
    "        for idx, inputs in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = inputs[:,1:]\n",
    "            outputs = model(inputs)[:,:-1,:]\n",
    "\n",
    "            targets = targets.reshape(-1)\n",
    "            outputs = outputs.reshape(-1, outputs.shape[-1])\n",
    "            \n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            avg_loss += loss\n",
    "\n",
    "        avg_loss /= len(test_loader)\n",
    "        print(f\"VALIDATE: Average Loss: {avg_loss}\")\n",
    "\n",
    "def train_model(model: nn.Module, \n",
    "                optimizer, \n",
    "                criterion, \n",
    "                device, \n",
    "                train_loader, \n",
    "                validation_loader, \n",
    "                accum_steps,\n",
    "                num_epochs: int = 4,\n",
    "                checkpoint: ModelCheckpoint = None):\n",
    "    \n",
    "    epoch = 0\n",
    "    start_batch = 0\n",
    "\n",
    "    if checkpoint != None:\n",
    "        model.load_state_dict(checkpoint.model_state)\n",
    "        optimizer.load_state_dict(checkpoint.optim_state)\n",
    "        epoch = checkpoint.epoch\n",
    "        start_batch = checkpoint.batch\n",
    "        torch.set_rng_state(checkpoint.rng_state)\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epoch, num_epochs):\n",
    "        start_time = time.time()\n",
    "        for idx, inputs in enumerate(train_loader):\n",
    "            if idx > start_batch:\n",
    "                inputs = inputs.to(device)\n",
    "                targets = inputs[:,1:]\n",
    "                outputs = model(inputs)[:,:-1,:]\n",
    "\n",
    "                targets = targets.reshape(-1)\n",
    "                outputs = outputs.reshape(-1, outputs.shape[-1])\n",
    "                \n",
    "                loss = criterion(outputs, targets) / accum_steps\n",
    "                loss.backward()\n",
    "\n",
    "                if (idx + 1) % accum_steps == 0:\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                if (idx + 1) % (accum_steps * 4) == 0:\n",
    "                    print(f\"Epoch [{epoch}].[{idx}] Loss: {loss * accum_steps}\")\n",
    "\n",
    "                if (idx + 1) % (accum_steps * 16) == 0:\n",
    "                    elapsed_time = time.time() - start_time\n",
    "                    print(f\"TIME: {elapsed_time / (accum_steps * 16)} seconds per batch\")\n",
    "                    start_time = time.time()\n",
    "\n",
    "                    allocated = torch.cuda.memory_allocated() / 1e9\n",
    "                    reserved = torch.cuda.memory_reserved() / 1e9\n",
    "                    peak = torch.cuda.max_memory_allocated() / 1e9\n",
    "                    print(f\"USAGE: Allocated {allocated:.2f}GB, Reserved {reserved:.2f}GB, Peak: {peak:.2f}GB\")\n",
    "\n",
    "                if (idx + 1) % (accum_steps * 32) == 0:\n",
    "                    validate_model(model, device, criterion, validation_loader)\n",
    "                    checkpoint = ModelCheckpoint(model.state_dict(), \n",
    "                                                optimizer.state_dict(), \n",
    "                                                epoch, \n",
    "                                                idx, \n",
    "                                                torch.get_rng_state())\n",
    "                    checkpoint.save(\"checkpoint.pt\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81cedc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.set_float32_matmul_precision('high')\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86c0e410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 2141709\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train+validation\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca7d5ead-bd78-46a6-82cd-cdcec26fe137",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38761c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sequence):\n",
    "    sequence[\"text\"] = torch.tensor(encoder.encode(sequence[\"text\"]), dtype=torch.int64)\n",
    "    return sequence\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, num_proc=8).with_format(\"torch\")\n",
    "tokenized_dataset = tokenized_dataset.train_test_split(test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c17f5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tokenized_dataset[\"train\"][\"text\"]\n",
    "\n",
    "test_set = tokenized_dataset[\"test\"].train_test_split(test_size=0.001, shuffle=True)\n",
    "test = test_set[\"train\"][\"text\"]\n",
    "validation = test_set[\"test\"][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edf5859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 2\n",
    "accum_steps = 32\n",
    "d_model  = 256\n",
    "d_query  = 64\n",
    "d_up = 512\n",
    "n_heads  = 4\n",
    "n_layers = 4\n",
    "\n",
    "n_vocab  = encoder.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7887f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100277\n"
     ]
    }
   ],
   "source": [
    "print(n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29143c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_padding(batch):\n",
    "    batch = pad_sequence(batch, batch_first=True)\n",
    "    return batch\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn_padding)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=True, collate_fn=collate_fn_padding)\n",
    "validation_loader = DataLoader(validation, batch_size=batch_size, shuffle=True, collate_fn=collate_fn_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "417bc5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(n_vocab=n_vocab, \n",
    "                    d_model=d_model, \n",
    "                    d_query=d_query, \n",
    "                    n_heads=n_heads, \n",
    "                    n_layers=n_layers, \n",
    "                    d_up=d_up, \n",
    "                    device=device).to(device)\n",
    "model = torch.compile(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9788985c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0].[6271] Loss: 3.968843698501587\n",
      "Epoch [0].[6399] Loss: 5.545017719268799\n",
      "Epoch [0].[6527] Loss: 5.470775127410889\n",
      "Epoch [0].[6655] Loss: 4.749324798583984\n",
      "TIME: 0.08149514114484191 seconds per batch\n",
      "USAGE: Allocated 1.89GB, Reserved 5.91GB, Peak: 5.45GB\n",
      "Epoch [0].[6783] Loss: 5.411537170410156\n",
      "Epoch [0].[6911] Loss: 5.906325340270996\n",
      "Epoch [0].[7039] Loss: 5.466499328613281\n",
      "Epoch [0].[7167] Loss: 5.661989212036133\n",
      "TIME: 0.02241235040128231 seconds per batch\n",
      "USAGE: Allocated 1.73GB, Reserved 6.63GB, Peak: 5.45GB\n",
      "VALIDATE: Average Loss: 5.112195014953613\n",
      "Model checkpoint saved at checkpoint.pt at epoch 0 batch 7167\n",
      "Epoch [0].[7295] Loss: 4.02065372467041\n",
      "Epoch [0].[7423] Loss: 6.000678062438965\n",
      "Epoch [0].[7551] Loss: 4.811922550201416\n",
      "Epoch [0].[7679] Loss: 3.8300883769989014\n",
      "TIME: 0.02843808103352785 seconds per batch\n",
      "USAGE: Allocated 2.15GB, Reserved 6.63GB, Peak: 5.45GB\n",
      "Epoch [0].[7807] Loss: 3.9811999797821045\n",
      "Epoch [0].[7935] Loss: 4.687188625335693\n",
      "Epoch [0].[8063] Loss: 4.727855682373047\n",
      "Epoch [0].[8191] Loss: 5.998194217681885\n",
      "TIME: 0.023283546324819326 seconds per batch\n",
      "USAGE: Allocated 1.74GB, Reserved 6.61GB, Peak: 5.45GB\n",
      "VALIDATE: Average Loss: 5.125064849853516\n",
      "Model checkpoint saved at checkpoint.pt at epoch 0 batch 8191\n",
      "Epoch [0].[8319] Loss: 5.203520774841309\n",
      "Epoch [0].[8447] Loss: 5.5681257247924805\n",
      "Epoch [0].[8575] Loss: 4.903116703033447\n",
      "Epoch [0].[8703] Loss: 5.267915725708008\n",
      "TIME: 0.028927383478730917 seconds per batch\n",
      "USAGE: Allocated 1.70GB, Reserved 6.61GB, Peak: 5.45GB\n",
      "Epoch [0].[8831] Loss: 5.11449670791626\n",
      "Epoch [0].[8959] Loss: 4.834847927093506\n",
      "Epoch [0].[9087] Loss: 4.965170383453369\n",
      "Epoch [0].[9215] Loss: 5.517618656158447\n",
      "TIME: 0.02314679976552725 seconds per batch\n",
      "USAGE: Allocated 1.74GB, Reserved 6.61GB, Peak: 5.45GB\n",
      "VALIDATE: Average Loss: 5.131080150604248\n",
      "Model checkpoint saved at checkpoint.pt at epoch 0 batch 9215\n",
      "Epoch [0].[9343] Loss: 5.528404235839844\n",
      "Epoch [0].[9471] Loss: 5.270763397216797\n",
      "Epoch [0].[9599] Loss: 5.778079032897949\n",
      "Epoch [0].[9727] Loss: 6.057694435119629\n",
      "TIME: 0.029794945381581783 seconds per batch\n",
      "USAGE: Allocated 1.75GB, Reserved 6.61GB, Peak: 5.45GB\n",
      "Epoch [0].[9855] Loss: 5.301196575164795\n",
      "Epoch [0].[9983] Loss: 5.502077579498291\n",
      "Epoch [0].[10111] Loss: 4.057480335235596\n",
      "Epoch [0].[10239] Loss: 3.787531614303589\n",
      "TIME: 0.02286831382662058 seconds per batch\n",
      "USAGE: Allocated 1.88GB, Reserved 6.61GB, Peak: 5.45GB\n",
      "VALIDATE: Average Loss: 5.087350845336914\n",
      "Model checkpoint saved at checkpoint.pt at epoch 0 batch 10239\n",
      "Epoch [0].[10367] Loss: 5.81483268737793\n",
      "Epoch [0].[10495] Loss: 5.436479568481445\n",
      "Epoch [0].[10623] Loss: 5.587639331817627\n",
      "Epoch [0].[10751] Loss: 5.143956661224365\n",
      "TIME: 0.028462851885706186 seconds per batch\n",
      "USAGE: Allocated 1.73GB, Reserved 6.61GB, Peak: 5.45GB\n",
      "Epoch [0].[10879] Loss: 5.960358142852783\n",
      "Epoch [0].[11007] Loss: 6.358857154846191\n",
      "Epoch [0].[11135] Loss: 4.807750701904297\n",
      "Epoch [0].[11263] Loss: 3.830169200897217\n",
      "TIME: 0.023725053295493126 seconds per batch\n",
      "USAGE: Allocated 1.91GB, Reserved 6.61GB, Peak: 5.45GB\n",
      "VALIDATE: Average Loss: 5.076841354370117\n",
      "Model checkpoint saved at checkpoint.pt at epoch 0 batch 11263\n",
      "Epoch [0].[11391] Loss: 5.1485114097595215\n",
      "Epoch [0].[11519] Loss: 5.556273937225342\n",
      "Epoch [0].[11647] Loss: 5.333870887756348\n",
      "Epoch [0].[11775] Loss: 5.172703742980957\n",
      "TIME: 0.02808190928772092 seconds per batch\n",
      "USAGE: Allocated 1.76GB, Reserved 6.61GB, Peak: 5.45GB\n",
      "Epoch [0].[11903] Loss: 5.576941013336182\n",
      "Epoch [0].[12031] Loss: 5.4717326164245605\n",
      "Epoch [0].[12159] Loss: 5.484132766723633\n",
      "Epoch [0].[12287] Loss: 6.332091808319092\n",
      "TIME: 0.02301396895200014 seconds per batch\n",
      "USAGE: Allocated 1.71GB, Reserved 6.61GB, Peak: 5.45GB\n",
      "VALIDATE: Average Loss: 5.095080852508545\n",
      "Model checkpoint saved at checkpoint.pt at epoch 0 batch 12287\n",
      "Epoch [0].[12415] Loss: 4.525984764099121\n",
      "Epoch [0].[12543] Loss: 6.137443542480469\n",
      "Epoch [0].[12671] Loss: 5.784754276275635\n",
      "Epoch [0].[12799] Loss: 4.368476390838623\n",
      "TIME: 0.028403807897120714 seconds per batch\n",
      "USAGE: Allocated 1.74GB, Reserved 6.61GB, Peak: 5.45GB\n",
      "Epoch [0].[12927] Loss: 4.965813636779785\n",
      "Epoch [0].[13055] Loss: 4.493414402008057\n",
      "Epoch [0].[13183] Loss: 3.7736430168151855\n",
      "Epoch [0].[13311] Loss: 5.605949878692627\n",
      "TIME: 0.022400307469069958 seconds per batch\n",
      "USAGE: Allocated 1.73GB, Reserved 6.61GB, Peak: 5.45GB\n",
      "VALIDATE: Average Loss: 5.061931133270264\n",
      "Model checkpoint saved at checkpoint.pt at epoch 0 batch 13311\n",
      "Epoch [0].[13439] Loss: 4.789821624755859\n",
      "Epoch [0].[13567] Loss: 5.024768829345703\n",
      "Epoch [0].[13695] Loss: 4.945722579956055\n",
      "Epoch [0].[13823] Loss: 5.5304365158081055\n",
      "TIME: 0.029303404968231916 seconds per batch\n",
      "USAGE: Allocated 1.73GB, Reserved 6.61GB, Peak: 5.45GB\n",
      "Epoch [0].[13951] Loss: 4.727111339569092\n",
      "Epoch [0].[14079] Loss: 5.926839828491211\n",
      "Epoch [0].[14207] Loss: 4.778958797454834\n",
      "Epoch [0].[14335] Loss: 4.64954948425293\n",
      "TIME: 0.022923212964087725 seconds per batch\n",
      "USAGE: Allocated 1.93GB, Reserved 6.61GB, Peak: 5.45GB\n",
      "VALIDATE: Average Loss: 5.044897079467773\n",
      "Model checkpoint saved at checkpoint.pt at epoch 0 batch 14335\n",
      "Epoch [0].[14463] Loss: 5.130832195281982\n",
      "Epoch [0].[14591] Loss: 3.876528739929199\n",
      "Epoch [0].[14719] Loss: 5.322944641113281\n",
      "Epoch [0].[14847] Loss: 4.573700904846191\n",
      "TIME: 0.02882715594023466 seconds per batch\n",
      "USAGE: Allocated 1.91GB, Reserved 6.61GB, Peak: 5.45GB\n",
      "Epoch [0].[14975] Loss: 5.385692119598389\n",
      "Epoch [0].[15103] Loss: 4.861133575439453\n",
      "Epoch [0].[15231] Loss: 5.396390438079834\n",
      "Epoch [0].[15359] Loss: 4.615839004516602\n",
      "TIME: 0.023580210283398628 seconds per batch\n",
      "USAGE: Allocated 1.74GB, Reserved 6.61GB, Peak: 5.45GB\n",
      "VALIDATE: Average Loss: 5.0261383056640625\n",
      "Model checkpoint saved at checkpoint.pt at epoch 0 batch 15359\n",
      "Epoch [0].[15487] Loss: 5.768505096435547\n",
      "Epoch [0].[15615] Loss: 4.687294960021973\n",
      "Epoch [0].[15743] Loss: 4.910130977630615\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m checkpoint = ModelCheckpoint.load(\u001b[33m\"\u001b[39m\u001b[33mcheckpoint.pt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvalidation_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m            \u001b[49m\u001b[43maccum_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccum_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, optimizer, criterion, device, train_loader, validation_loader, accum_steps, num_epochs, checkpoint)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epoch, num_epochs):\n\u001b[32m     46\u001b[39m     start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_batch\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m            \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:788\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    787\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    790\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/datasets/arrow_dataset.py:681\u001b[39m, in \u001b[36mColumn.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    679\u001b[39m         source = \u001b[38;5;28mself\u001b[39m.source\n\u001b[32m    680\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m681\u001b[39m         source = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fast_select_column\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m source[key][\u001b[38;5;28mself\u001b[39m.column_name]\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mint\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/datasets/arrow_dataset.py:562\u001b[39m, in \u001b[36mtransmit_format.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    555\u001b[39m self_format = {\n\u001b[32m    556\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_type,\n\u001b[32m    557\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mformat_kwargs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_kwargs,\n\u001b[32m    558\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_columns,\n\u001b[32m    559\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33moutput_all_columns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._output_all_columns,\n\u001b[32m    560\u001b[39m }\n\u001b[32m    561\u001b[39m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m562\u001b[39m out: Union[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDatasetDict\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    563\u001b[39m datasets: \u001b[38;5;28mlist\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlist\u001b[39m(out.values()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/datasets/arrow_dataset.py:2449\u001b[39m, in \u001b[36mDataset._fast_select_column\u001b[39m\u001b[34m(self, column_name)\u001b[39m\n\u001b[32m   2446\u001b[39m \u001b[38;5;129m@transmit_format\u001b[39m\n\u001b[32m   2447\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_fast_select_column\u001b[39m(\u001b[38;5;28mself\u001b[39m, column_name: \u001b[38;5;28mstr\u001b[39m) -> \u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2448\u001b[39m     dataset = copy.copy(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2449\u001b[39m     dataset._data = \u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2450\u001b[39m     dataset._info = DatasetInfo(features=Features({column_name: \u001b[38;5;28mself\u001b[39m._info.features[column_name]}))\n\u001b[32m   2451\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/datasets/table.py:1743\u001b[39m, in \u001b[36mConcatenationTable.select\u001b[39m\u001b[34m(self, columns, *args, **kwargs)\u001b[39m\n\u001b[32m   1741\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tables \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.blocks:\n\u001b[32m   1742\u001b[39m     blocks.append([t.select([c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m columns \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m t.column_names], *args, **kwargs) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tables])\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mConcatenationTable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/datasets/table.py:1300\u001b[39m, in \u001b[36mConcatenationTable.__init__\u001b[39m\u001b[34m(self, table, blocks)\u001b[39m\n\u001b[32m   1299\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, table: pa.Table, blocks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[TableBlock]]):\n\u001b[32m-> \u001b[39m\u001b[32m1300\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1301\u001b[39m     \u001b[38;5;28mself\u001b[39m.blocks = blocks\n\u001b[32m   1302\u001b[39m     \u001b[38;5;66;03m# Check that all the blocks have the right type.\u001b[39;00m\n\u001b[32m   1303\u001b[39m     \u001b[38;5;66;03m# Only InMemoryTable and MemoryMappedTable are allowed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/datasets/table.py:166\u001b[39m, in \u001b[36mTable.__init__\u001b[39m\u001b[34m(self, table)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, table: pa.Table):\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28mself\u001b[39m.table = table\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/source/repos/notebooks/.venv/lib/python3.13/site-packages/datasets/table.py:108\u001b[39m, in \u001b[36mIndexedTableMixin.__init__\u001b[39m\u001b[34m(self, table)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, table: pa.Table):\n\u001b[32m    106\u001b[39m     \u001b[38;5;28mself\u001b[39m._schema: pa.Schema = table.schema\n\u001b[32m    107\u001b[39m     \u001b[38;5;28mself\u001b[39m._batches: \u001b[38;5;28mlist\u001b[39m[pa.RecordBatch] = [\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m         recordbatch \u001b[38;5;28;01mfor\u001b[39;00m recordbatch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(recordbatch) > \u001b[32m0\u001b[39m\n\u001b[32m    109\u001b[39m     ]\n\u001b[32m    110\u001b[39m     \u001b[38;5;28mself\u001b[39m._offsets: np.ndarray = np.cumsum([\u001b[32m0\u001b[39m] + [\u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._batches], dtype=np.int64)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint.load(\"checkpoint.pt\")\n",
    "\n",
    "train_model(model=model, \n",
    "            optimizer=optimizer, \n",
    "            criterion=criterion, \n",
    "            device=device, \n",
    "            train_loader=train_loader, \n",
    "            validation_loader=validation_loader, \n",
    "            accum_steps=accum_steps,\n",
    "            checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482a1d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(model, encoder: tiktoken.Encoding, device: torch.device, prompt: str):\n",
    "    sequence = encoder.encode(prompt)\n",
    "    with torch.no_grad():\n",
    "        for _ in range(100):\n",
    "            input = torch.tensor(sequence, dtype=torch.int64).unsqueeze(0).to(device)\n",
    "            output = model(input)\n",
    "            output = output[0,-1,:].argmax().item()\n",
    "            sequence = sequence + [output]\n",
    "\n",
    "        response = encoder.decode(sequence)\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1e6150ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me a story about a hungry man............................................................!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint.load(\"checkpoint.pt\")\n",
    "model.load_state_dict(checkpoint.model_state)\n",
    "\n",
    "prompt = \"Tell me a story about a hungry man.\"\n",
    "\n",
    "response = generate_response(model, encoder=encoder, device=device, prompt=prompt)\n",
    "print(response)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
